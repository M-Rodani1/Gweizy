{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gweizy Model Training Notebook\n",
    "\n",
    "Train all gas prediction models for Gweizy.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload your `gas_data.db` file (from `backend/gas_data.db`)\n",
    "2. Run all cells\n",
    "3. Download the trained models zip file\n",
    "4. Extract to `backend/models/saved_models/` and push to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q scikit-learn pandas numpy joblib lightgbm xgboost matplotlib seaborn optuna"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your gas_data.db file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your gas_data.db file from backend/gas_data.db\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'gas_data.db' in uploaded:\n",
    "    print(f\"\\n\u2705 Uploaded gas_data.db ({len(uploaded['gas_data.db']) / 1024 / 1024:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\u274c Please upload gas_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data from database\n",
    "conn = sqlite3.connect('gas_data.db')\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT timestamp, current_gas as gas, base_fee, priority_fee, \n",
    "           block_number, gas_used, gas_limit, utilization\n",
    "    FROM gas_prices ORDER BY timestamp ASC\n",
    "\"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('timestamp').sort_index()\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "\n",
    "# === IMPROVED: Resample to 30-second intervals (was 1-min, losing too much data) ===\n",
    "print(\"\\nResampling to 30-second intervals (preserves more data)...\")\n",
    "df = df.resample('30s').mean().dropna(subset=['gas'])\n",
    "print(f\"After resample: {len(df):,} records\")\n",
    "\n",
    "# Find segments (gap > 30 min = new segment)\n",
    "df['time_diff'] = df.index.to_series().diff()\n",
    "df['segment'] = (df['time_diff'] > pd.Timedelta(minutes=30)).cumsum()\n",
    "\n",
    "segment_sizes = df.groupby('segment').size()\n",
    "print(f\"\\nSegments found: {len(segment_sizes)}\")\n",
    "print(f\"Segment sizes: {segment_sizes.sort_values(ascending=False).head(10).tolist()}\")\n",
    "\n",
    "# === IMPROVED: Lower threshold from 120 to 30 minutes (keeps more segments) ===\n",
    "MIN_SEGMENT_SIZE = 60  # 30 minutes at 30-sec intervals = 60 records\n",
    "good_segments = segment_sizes[segment_sizes >= MIN_SEGMENT_SIZE].index.tolist()\n",
    "df = df[df['segment'].isin(good_segments)]\n",
    "print(f\"\\nKeeping {len(good_segments)} segments with >= 30 minutes of data\")\n",
    "print(f\"Total usable records: {len(df):,}\")\n",
    "\n",
    "# === DATA SUFFICIENCY CHECK ===\n",
    "MIN_REQUIRED_SAMPLES = 10000\n",
    "if len(df) < MIN_REQUIRED_SAMPLES:\n",
    "    print(f\"\\n\u26a0\ufe0f  WARNING: Only {len(df):,} samples. Recommend at least {MIN_REQUIRED_SAMPLES:,}\")\n",
    "    print(\"   Models may underperform. Consider collecting more data.\")\n",
    "else:\n",
    "    print(f\"\\n\u2713 Data sufficiency check passed: {len(df):,} samples\")\n",
    "\n",
    "RECORDS_PER_HOUR = 120  # 30-sec intervals = 120 records per hour"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Fetch ETH Price Data - IMPROVED with Binance (1-minute data)\nimport requests\n\nprint(\"=\"*60)\nprint(\"FETCHING EXTERNAL DATA\")\nprint(\"=\"*60)\n\ndef fetch_eth_price_binance(start_date, end_date):\n    \"\"\"Fetch ETH price from Binance API (1-minute candles, much better than CoinGecko hourly)\"\"\"\n    try:\n        start_ts = int(start_date.timestamp() * 1000)\n        end_ts = int(end_date.timestamp() * 1000)\n        \n        all_prices = []\n        current_ts = start_ts\n        \n        print(f\"Fetching ETH prices from Binance (1-min candles)...\")\n        \n        while current_ts < end_ts:\n            url = \"https://api.binance.com/api/v3/klines\"\n            params = {\n                'symbol': 'ETHUSDT',\n                'interval': '1m',\n                'startTime': current_ts,\n                'endTime': min(current_ts + 1000 * 60 * 1000, end_ts),  # Max 1000 candles\n                'limit': 1000\n            }\n            \n            response = requests.get(url, params=params, timeout=30)\n            \n            if response.status_code == 200:\n                data = response.json()\n                if not data:\n                    break\n                    \n                for candle in data:\n                    all_prices.append({\n                        'timestamp': pd.to_datetime(candle[0], unit='ms'),\n                        'eth_price': float(candle[4]),  # Close price\n                        'eth_volume': float(candle[5]),  # Volume\n                        'eth_high': float(candle[2]),\n                        'eth_low': float(candle[3])\n                    })\n                \n                current_ts = data[-1][0] + 60000  # Next minute\n                \n                if len(all_prices) % 5000 == 0:\n                    print(f\"  Fetched {len(all_prices):,} candles...\")\n            else:\n                print(f\"  Binance API error: {response.status_code}\")\n                break\n        \n        if all_prices:\n            eth_df = pd.DataFrame(all_prices)\n            eth_df = eth_df.set_index('timestamp')\n            print(f\"  Total: {len(eth_df):,} 1-minute ETH candles\")\n            return eth_df\n        return None\n        \n    except Exception as e:\n        print(f\"  Failed to fetch from Binance: {e}\")\n        return None\n\ndef fetch_eth_price_coingecko(start_date, end_date):\n    \"\"\"Fallback: CoinGecko API (hourly data)\"\"\"\n    try:\n        start_ts = int(start_date.timestamp())\n        end_ts = int(end_date.timestamp())\n        \n        url = \"https://api.coingecko.com/api/v3/coins/ethereum/market_chart/range\"\n        params = {'vs_currency': 'usd', 'from': start_ts, 'to': end_ts}\n        \n        print(f\"Fallback: Fetching from CoinGecko (hourly)...\")\n        response = requests.get(url, params=params, timeout=30)\n        \n        if response.status_code == 200:\n            data = response.json()\n            prices = data.get('prices', [])\n            \n            eth_df = pd.DataFrame(prices, columns=['timestamp', 'eth_price'])\n            eth_df['timestamp'] = pd.to_datetime(eth_df['timestamp'], unit='ms')\n            eth_df = eth_df.set_index('timestamp')\n            eth_df['eth_volume'] = np.nan\n            eth_df['eth_high'] = eth_df['eth_price']\n            eth_df['eth_low'] = eth_df['eth_price']\n            \n            print(f\"  Fetched {len(eth_df)} hourly ETH prices\")\n            return eth_df\n        return None\n    except Exception as e:\n        print(f\"  CoinGecko failed: {e}\")\n        return None\n\n# Try Binance first, fallback to CoinGecko\neth_data = fetch_eth_price_binance(df.index.min(), df.index.max())\nif eth_data is None or len(eth_data) < 100:\n    eth_data = fetch_eth_price_coingecko(df.index.min(), df.index.max())\n\nhas_eth_data = False\nif eth_data is not None and len(eth_data) > 0:\n    # Resample to 30-second intervals\n    eth_data = eth_data.resample('30s').ffill()\n    \n    # Merge with gas data\n    df = df.join(eth_data, how='left')\n    df['eth_price'] = df['eth_price'].ffill().bfill()\n    \n    # Fill other ETH columns\n    for col in ['eth_volume', 'eth_high', 'eth_low']:\n        if col in df.columns:\n            df[col] = df[col].ffill().bfill()\n    \n    eth_coverage = df['eth_price'].notna().mean()\n    print(f\"  ETH price coverage: {eth_coverage:.1%}\")\n    \n    if eth_coverage > 0.5:\n        has_eth_data = True\n        print(\"  \u2713 ETH price data integrated (1-min resolution)\")\nelse:\n    print(\"  \u26a0\ufe0f No ETH price data available\")\n    df['eth_price'] = np.nan\n    df['eth_volume'] = np.nan\n    df['eth_high'] = np.nan\n    df['eth_low'] = np.nan\n\nHAS_ETH_PRICE = has_eth_data"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - SIMPLIFIED v3 + SPIKE-ADJUSTED TARGETS\n# Focus: 15-20 high-value features to prevent overfitting\n# NEW: Option for log-transformed or winsorized targets\n\nprint(\"Engineering SIMPLIFIED feature set (15-20 features)...\")\n\n# === CONFIGURATION ===\nTARGET_TRANSFORM = \"log\"  # Options: \"none\", \"log\", \"winsorize\"\nWINSORIZE_PERCENTILE = 0.95  # For winsorize: cap at this percentile\n\ndef engineer_features_for_segment(seg_df, has_eth=False, horizon='all'):\n    \"\"\"Engineer focused feature set - quality over quantity\"\"\"\n    df = seg_df.copy()\n    rph = 120  # records per hour (30-sec intervals)\n    \n    # === TIME FEATURES (3 features) ===\n    df['hour'] = df.index.hour\n    hour_of_day = df.index.hour + df.index.minute / 60\n    df['hour_sin'] = np.sin(2 * np.pi * hour_of_day / 24)\n    df['hour_cos'] = np.cos(2 * np.pi * hour_of_day / 24)\n    \n    # === ETH FEATURES (2 features) ===\n    if has_eth and 'eth_price' in df.columns and df['eth_price'].notna().any():\n        df['eth_log'] = np.log1p(df['eth_price'])\n        eth_mean = df['eth_price'].rolling(4*rph, min_periods=rph).mean()\n        eth_std = df['eth_price'].rolling(4*rph, min_periods=rph).std()\n        df['eth_zscore_4h'] = np.where(eth_std > 0.01, (df['eth_price'] - eth_mean) / eth_std, 0)\n        df['gas_eth_corr_1h'] = df['gas'].rolling(rph, min_periods=rph//2).corr(df['eth_price']).fillna(0)\n    \n    # === NETWORK UTILIZATION (2 features) ===\n    if 'utilization' in df.columns:\n        df['util_mean_1h'] = df['utilization'].rolling(rph, min_periods=rph//2).mean()\n        df['util_mean_2h'] = df['utilization'].rolling(2*rph, min_periods=rph).mean()\n    \n    # === GAS LAG FEATURES (5 features) ===\n    df['gas_lag_5min'] = df['gas'].shift(10)\n    df['gas_lag_15min'] = df['gas'].shift(30)\n    df['gas_lag_30min'] = df['gas'].shift(60)\n    df['gas_lag_1h'] = df['gas'].shift(rph)\n    df['gas_lag_4h'] = df['gas'].shift(4*rph)\n    \n    # === ROLLING STATS (6 features) ===\n    df['gas_mean_1h'] = df['gas'].rolling(rph, min_periods=rph//2).mean()\n    df['gas_std_1h'] = df['gas'].rolling(rph, min_periods=rph//2).std()\n    df['gas_cv_1h'] = np.where(df['gas_mean_1h'] > 0.01, \n                                df['gas_std_1h'] / df['gas_mean_1h'], 0)\n    df['gas_mean_2h'] = df['gas'].rolling(2*rph, min_periods=rph).mean()\n    df['gas_mean_4h'] = df['gas'].rolling(4*rph, min_periods=rph).mean()\n    \n    # === MOMENTUM (3 features) ===\n    df['momentum_1h'] = df['gas'] - df['gas'].shift(rph)\n    shift_2h = df['gas'].shift(2*rph)\n    df['momentum_pct_2h'] = np.where(shift_2h > 0.01, (df['gas'] - shift_2h) / shift_2h, 0)\n    df['trend_1h_4h'] = np.where(df['gas_mean_4h'] > 0.01, df['gas_mean_1h'] / df['gas_mean_4h'], 1.0)\n    \n    # === Z-SCORE AND REGIME (3 features) ===\n    df['gas_zscore_1h'] = np.where(df['gas_std_1h'] > 0.001, \n        (df['gas'] - df['gas_mean_1h']) / df['gas_std_1h'], 0)\n    df['is_spike'] = (df['gas'] > df['gas_mean_1h'] + 2 * df['gas_std_1h']).astype(int)\n    df['is_high_gas'] = (df['gas'] > df['gas'].rolling(4*rph, min_periods=rph).quantile(0.9)).astype(int)\n    \n    return df\n\n# Process each segment\nprint(\"\\n",
    "Processing segments...\")\nsegments = df['segment'].unique()\nprocessed_segments = []\n\nfor seg_id in segments:\n    seg_df = df[df['segment'] == seg_id].copy()\n    processed = engineer_features_for_segment(seg_df, has_eth=has_eth_data, horizon='all')\n    processed_segments.append(processed)\n\ndf_features = pd.concat(processed_segments, axis=0)\nprint(f\"After feature engineering: {len(df_features):,} records\")\n\n# Create targets\nprint(\"\\n",
    "Creating prediction targets...\")\n\ndef create_targets_for_segment(seg_df, transform=\"none\", winsorize_pct=0.95):\n    \"\"\"Create target variables with optional transformation\"\"\"\n    df = seg_df.copy()\n    rph = 120\n    \n    # Raw future prices\n    raw_1h = df['gas'].shift(-rph)\n    raw_4h = df['gas'].shift(-4*rph)\n    raw_24h = df['gas'].shift(-24*rph)\n    \n    # Apply transformation\n    if transform == \"log\":\n        # Log transform - better for multiplicative changes\n        df['target_1h'] = np.log1p(raw_1h)\n        df['target_4h'] = np.log1p(raw_4h)\n        df['target_24h'] = np.log1p(raw_24h)\n        # Also store raw for evaluation\n        df['target_1h_raw'] = raw_1h\n        df['target_4h_raw'] = raw_4h\n        df['target_24h_raw'] = raw_24h\n    elif transform == \"winsorize\":\n        # Winsorize - cap extreme values\n        cap_1h = raw_1h.quantile(winsorize_pct)\n        cap_4h = raw_4h.quantile(winsorize_pct)\n        cap_24h = raw_24h.quantile(winsorize_pct) if raw_24h.notna().sum() > 100 else cap_4h\n        df['target_1h'] = raw_1h.clip(upper=cap_1h)\n        df['target_4h'] = raw_4h.clip(upper=cap_4h)\n        df['target_24h'] = raw_24h.clip(upper=cap_24h)\n        df['target_1h_raw'] = raw_1h\n        df['target_4h_raw'] = raw_4h\n        df['target_24h_raw'] = raw_24h\n        print(f\"  Winsorized caps: 1h={cap_1h:.2f}, 4h={cap_4h:.2f}\")\n    else:\n        # No transform\n        df['target_1h'] = raw_1h\n        df['target_4h'] = raw_4h\n        df['target_24h'] = raw_24h\n    \n    # Direction classification (always on raw)\n    threshold = 0.02\n    for horizon in ['1h', '4h']:\n        raw_target = raw_1h if horizon == '1h' else raw_4h\n        pct_change = np.where(df['gas'] > 0.001, \n            (raw_target - df['gas']) / df['gas'], 0)\n        df[f'direction_class_{horizon}'] = pd.cut(\n            pct_change,\n            bins=[-float('inf'), -threshold, threshold, float('inf')],\n            labels=['down', 'stable', 'up']\n        )\n    \n    return df\n\nprint(f\"Target transform: {TARGET_TRANSFORM}\")\nprocessed_with_targets = []\nfor seg_id in df_features['segment'].unique():\n    seg_df = df_features[df_features['segment'] == seg_id].copy()\n    processed = create_targets_for_segment(seg_df, transform=TARGET_TRANSFORM, winsorize_pct=WINSORIZE_PERCENTILE)\n    processed_with_targets.append(processed)\n\ndf_features = pd.concat(processed_with_targets, axis=0)\n\n# Store transform info for later use\nTARGET_TRANSFORM_USED = TARGET_TRANSFORM\n\n# === CLEAN INF/NAN VALUES ===\nprint(\"\\n",
    "Cleaning inf/nan values...\")\nnumeric_cols = df_features.select_dtypes(include=[np.number]).columns\n\nfor col in numeric_cols:\n    df_features[col] = df_features[col].replace([np.inf, -np.inf], np.nan)\n    if df_features[col].notna().sum() > 0:\n        q_low = df_features[col].quantile(0.001)\n        q_high = df_features[col].quantile(0.999)\n        df_features[col] = df_features[col].clip(q_low, q_high)\n\ndf_features = df_features.ffill().bfill()\n\nfor col in numeric_cols:\n    if df_features[col].isna().any():\n        median_val = df_features[col].median()\n        if pd.isna(median_val):\n            median_val = 0\n        df_features[col] = df_features[col].fillna(median_val)\n\ninf_count = np.isinf(df_features.select_dtypes(include=[np.number])).sum().sum()\nnan_count = df_features.select_dtypes(include=[np.number]).isna().sum().sum()\nprint(f\"  After cleaning: {inf_count} inf, {nan_count} nan values\")\n\n# === DEFINE FOCUSED FEATURE SET ===\nCORE_FEATURES = [\n    'hour', 'hour_sin', 'hour_cos',\n    'eth_log', 'eth_zscore_4h', 'gas_eth_corr_1h',\n    'util_mean_1h', 'util_mean_2h',\n    'gas_lag_5min', 'gas_lag_15min', 'gas_lag_30min', 'gas_lag_1h', 'gas_lag_4h',\n    'gas_mean_1h', 'gas_std_1h', 'gas_cv_1h', 'gas_mean_2h', 'gas_mean_4h',\n    'momentum_1h', 'momentum_pct_2h', 'trend_1h_4h',\n    'gas_zscore_1h', 'is_spike', 'is_high_gas'\n]\n\navailable_features = [f for f in CORE_FEATURES if f in df_features.columns]\nfeatures_1h = available_features\nfeatures_4h = available_features  \nfeatures_24h = available_features\n\nprint(f\"\\n",
    "\u2713 Focused feature set: {len(available_features)} features\")\nprint(f\"  Features: {', '.join(available_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data - with AUTO-ADAPT to distribution shift\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "USE_ROLLING_WINDOW = False  # Set True to use only recent data (AUTO-ENABLED if shift detected)\n",
    "ROLLING_WINDOW_DAYS = 7     # Days of data to use if rolling window enabled\n",
    "HOLDOUT_HOURS = 48          # Hours to reserve for holdout\n",
    "AUTO_ADAPT_ON_SHIFT = True  # Automatically adapt when distribution shift detected\n",
    "\n",
    "# Only keep numeric columns\n",
    "numeric_features_1h = df_features[features_1h].select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features_4h = df_features[features_4h].select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features_24h = df_features[features_24h].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: 1h={len(numeric_features_1h)}, 4h={len(numeric_features_4h)}, 24h={len(numeric_features_24h)}\")\n",
    "\n",
    "# Drop rows only where TARGET columns are NaN\n",
    "target_cols = ['target_1h', 'target_4h']\n",
    "df_clean = df_features.dropna(subset=target_cols)\n",
    "print(f\"Clean samples (with valid 1h/4h targets): {len(df_clean):,}\")\n",
    "\n",
    "valid_24h = df_features['target_24h'].notna().sum()\n",
    "print(f\"Samples with valid 24h target: {valid_24h:,}\")\n",
    "\n",
    "# === OUT-OF-TIME HOLDOUT (do this FIRST to detect shift) ===\n",
    "rph = 120  # records per hour\n",
    "holdout_size = HOLDOUT_HOURS * rph\n",
    "\n",
    "if len(df_clean) > holdout_size + 5000:\n",
    "    df_train_val_initial = df_clean.iloc[:-holdout_size]\n",
    "    df_holdout = df_clean.iloc[-holdout_size:]\n",
    "    print(f\"\\n\u2713 Out-of-time holdout: {len(df_holdout):,} samples (last {HOLDOUT_HOURS}h)\")\n",
    "    HAS_HOLDOUT = True\n",
    "else:\n",
    "    df_train_val_initial = df_clean\n",
    "    df_holdout = None\n",
    "    print(f\"\\n\u26a0\ufe0f Not enough data for holdout, using all for training\")\n",
    "    HAS_HOLDOUT = False\n",
    "\n",
    "# === DISTRIBUTION SHIFT DETECTION ===\n",
    "def detect_distribution_shift(train_data, holdout_data, name=\"\"):\n",
    "    \"\"\"Detect distribution shift between train and holdout\"\"\"\n",
    "    results = {'name': name, 'warnings': [], 'passed': True, 'shift_magnitude': 0}\n",
    "    \n",
    "    train_mean, train_std = train_data.mean(), train_data.std()\n",
    "    holdout_mean = holdout_data.mean()\n",
    "    mean_shift = abs(holdout_mean - train_mean) / (train_std + 1e-8)\n",
    "    results['mean_shift_std'] = mean_shift\n",
    "    \n",
    "    if mean_shift > 1.0:\n",
    "        results['warnings'].append(f\"Large mean shift: {mean_shift:.2f} std devs\")\n",
    "        results['passed'] = False\n",
    "        results['shift_magnitude'] = max(results['shift_magnitude'], mean_shift)\n",
    "    elif mean_shift > 0.5:\n",
    "        results['warnings'].append(f\"Moderate mean shift: {mean_shift:.2f} std devs\")\n",
    "    \n",
    "    var_ratio = holdout_data.var() / (train_data.var() + 1e-8)\n",
    "    results['var_ratio'] = var_ratio\n",
    "    \n",
    "    if var_ratio > 4 or var_ratio < 0.25:\n",
    "        results['warnings'].append(f\"Large variance change: {var_ratio:.2f}x\")\n",
    "        results['passed'] = False\n",
    "        results['shift_magnitude'] = max(results['shift_magnitude'], abs(np.log(var_ratio)))\n",
    "    \n",
    "    ks_stat, ks_pval = stats.ks_2samp(train_data.values[:5000], holdout_data.values[:5000])\n",
    "    results['ks_statistic'] = ks_stat\n",
    "    results['ks_pvalue'] = ks_pval\n",
    "    \n",
    "    if ks_pval < 0.001 and ks_stat > 0.3:\n",
    "        results['warnings'].append(f\"KS test: distributions differ significantly\")\n",
    "        results['passed'] = False\n",
    "        results['shift_magnitude'] = max(results['shift_magnitude'], ks_stat * 3)\n",
    "    \n",
    "    train_spikes = (train_data > train_data.quantile(0.95)).mean()\n",
    "    holdout_spikes = (holdout_data > train_data.quantile(0.95)).mean()\n",
    "    spike_ratio = holdout_spikes / (train_spikes + 1e-8)\n",
    "    results['spike_ratio'] = spike_ratio\n",
    "    \n",
    "    if spike_ratio > 3:\n",
    "        results['warnings'].append(f\"Spike frequency {spike_ratio:.1f}x higher in holdout\")\n",
    "        results['passed'] = False\n",
    "        results['shift_magnitude'] = max(results['shift_magnitude'], spike_ratio / 2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "DISTRIBUTION_SHIFT_DETECTED = False\n",
    "SHIFT_MAGNITUDE = 0\n",
    "\n",
    "if HAS_HOLDOUT:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DISTRIBUTION SHIFT DETECTION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for horizon in ['1h', '4h']:\n",
    "        target_col = f'target_{horizon}'\n",
    "        train_targets = df_train_val_initial[target_col].dropna()\n",
    "        holdout_targets = df_holdout[target_col].dropna()\n",
    "        \n",
    "        shift_result = detect_distribution_shift(train_targets, holdout_targets, f\"{horizon} target\")\n",
    "        \n",
    "        status = \"\u2713 OK\" if shift_result['passed'] else \"\u26a0\ufe0f SHIFT DETECTED\"\n",
    "        print(f\"\\n{horizon}: {status}\")\n",
    "        print(f\"  Train:   mean={train_targets.mean():.4f}, std={train_targets.std():.4f}\")\n",
    "        print(f\"  Holdout: mean={holdout_targets.mean():.4f}, std={holdout_targets.std():.4f}\")\n",
    "        print(f\"  Mean shift: {shift_result['mean_shift_std']:.2f} std, Var ratio: {shift_result['var_ratio']:.2f}x\")\n",
    "        \n",
    "        if shift_result['warnings']:\n",
    "            for w in shift_result['warnings']:\n",
    "                print(f\"  \u26a0\ufe0f {w}\")\n",
    "            DISTRIBUTION_SHIFT_DETECTED = True\n",
    "            SHIFT_MAGNITUDE = max(SHIFT_MAGNITUDE, shift_result['shift_magnitude'])\n",
    "\n",
    "# === AUTO-ADAPT TO DISTRIBUTION SHIFT ===\n",
    "if DISTRIBUTION_SHIFT_DETECTED and AUTO_ADAPT_ON_SHIFT:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"AUTO-ADAPTING TO DISTRIBUTION SHIFT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Calculate adaptive window based on shift magnitude\n",
    "    if SHIFT_MAGNITUDE > 2:\n",
    "        adaptive_days = 3  # Severe shift - use very recent data\n",
    "    elif SHIFT_MAGNITUDE > 1:\n",
    "        adaptive_days = 5  # Moderate shift\n",
    "    else:\n",
    "        adaptive_days = 7  # Mild shift\n",
    "    \n",
    "    window_samples = adaptive_days * 24 * rph\n",
    "    \n",
    "    if len(df_train_val_initial) > window_samples:\n",
    "        df_train_val = df_train_val_initial.iloc[-window_samples:]\n",
    "        print(f\"\u2713 Auto-enabled rolling window: {adaptive_days} days ({len(df_train_val):,} samples)\")\n",
    "        print(f\"  Shift magnitude: {SHIFT_MAGNITUDE:.2f} \u2192 window: {adaptive_days} days\")\n",
    "        USE_ROLLING_WINDOW = True\n",
    "        ROLLING_WINDOW_DAYS = adaptive_days\n",
    "    else:\n",
    "        df_train_val = df_train_val_initial\n",
    "        print(f\"\u26a0\ufe0f Not enough data for adaptive window, using all training data\")\n",
    "elif USE_ROLLING_WINDOW:\n",
    "    # Manual rolling window\n",
    "    window_samples = ROLLING_WINDOW_DAYS * 24 * rph\n",
    "    if len(df_train_val_initial) > window_samples:\n",
    "        df_train_val = df_train_val_initial.iloc[-window_samples:]\n",
    "        print(f\"\\n\u2713 Rolling window: Using last {ROLLING_WINDOW_DAYS} days ({len(df_train_val):,} samples)\")\n",
    "    else:\n",
    "        df_train_val = df_train_val_initial\n",
    "else:\n",
    "    df_train_val = df_train_val_initial\n",
    "\n",
    "print(f\"\\nFinal training set: {len(df_train_val):,} samples\")\n",
    "\n",
    "# Final safety check\n",
    "for col in df_train_val.select_dtypes(include=[np.float64, np.float32, float]).columns:\n",
    "    df_train_val[col] = df_train_val[col].replace([np.inf, -np.inf], np.nan)\n",
    "    if df_train_val[col].isna().any():\n",
    "        df_train_val[col] = df_train_val[col].fillna(df_train_val[col].median())\n",
    "\n",
    "float_cols = df_train_val.select_dtypes(include=[np.float64, np.float32, float]).columns\n",
    "has_inf = any(np.isinf(df_train_val[col]).any() for col in float_cols)\n",
    "has_nan = any(np.isnan(df_train_val[col]).any() for col in float_cols)\n",
    "assert not has_inf, \"Data still contains inf!\"\n",
    "assert not has_nan, \"Data still contains nan!\"\n",
    "print(\"\u2713 Data validated: no inf/nan values\")\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_1h = df_train_val[numeric_features_1h]\n",
    "X_4h = df_train_val[numeric_features_4h]\n",
    "X_24h = df_train_val[numeric_features_24h]\n",
    "\n",
    "y_1h = df_train_val['target_1h']\n",
    "y_4h = df_train_val['target_4h']\n",
    "y_24h = df_train_val['target_24h']\n",
    "\n",
    "y_dir_1h = df_train_val['direction_class_1h']\n",
    "y_dir_4h = df_train_val['direction_class_4h']\n",
    "\n",
    "current_gas = df_train_val['gas']\n",
    "\n",
    "# === BASELINE MODELS (on both train AND holdout) ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BASELINE COMPARISONS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "naive_mae_1h = np.mean(np.abs(y_1h.values - current_gas.values))\n",
    "naive_mae_4h = np.mean(np.abs(y_4h.values - current_gas.values))\n",
    "\n",
    "mean_pred = np.full_like(y_1h.values, y_1h.mean())\n",
    "mean_mae_1h = np.mean(np.abs(y_1h.values - mean_pred))\n",
    "mean_mae_4h = np.mean(np.abs(y_4h.values - mean_pred))\n",
    "\n",
    "print(f\"\\nTRAINING SET Baseline MAEs:\")\n",
    "print(f\"  Naive (current price):     MAE_1h={naive_mae_1h:.6f}, MAE_4h={naive_mae_4h:.6f}\")\n",
    "print(f\"  Mean (historical average): MAE_1h={mean_mae_1h:.6f}, MAE_4h={mean_mae_4h:.6f}\")\n",
    "\n",
    "best_baseline_1h = min(naive_mae_1h, mean_mae_1h)\n",
    "best_baseline_4h = min(naive_mae_4h, mean_mae_4h)\n",
    "\n",
    "BASELINES = {\n",
    "    '1h': {'naive_mae': naive_mae_1h, 'mean_mae': mean_mae_1h, 'best': best_baseline_1h},\n",
    "    '4h': {'naive_mae': naive_mae_4h, 'mean_mae': mean_mae_4h, 'best': best_baseline_4h}\n",
    "}\n",
    "\n",
    "# === HOLDOUT BASELINES ===\n",
    "if HAS_HOLDOUT:\n",
    "    print(f\"\\nHOLDOUT SET Baseline MAEs:\")\n",
    "    holdout_gas = df_holdout['gas']\n",
    "    \n",
    "    for horizon in ['1h', '4h']:\n",
    "        holdout_target = df_holdout[f'target_{horizon}'].dropna()\n",
    "        holdout_current = holdout_gas.loc[holdout_target.index]\n",
    "        \n",
    "        holdout_naive_mae = np.mean(np.abs(holdout_target.values - holdout_current.values))\n",
    "        train_mean = df_train_val[f'target_{horizon}'].mean()\n",
    "        holdout_mean_mae = np.mean(np.abs(holdout_target.values - train_mean))\n",
    "        \n",
    "        holdout_best = min(holdout_naive_mae, holdout_mean_mae)\n",
    "        BASELINES[horizon]['holdout_naive_mae'] = holdout_naive_mae\n",
    "        BASELINES[horizon]['holdout_mean_mae'] = holdout_mean_mae\n",
    "        BASELINES[horizon]['holdout_best'] = holdout_best\n",
    "        \n",
    "        print(f\"  {horizon}: Naive={holdout_naive_mae:.6f}, Mean={holdout_mean_mae:.6f}, Best={holdout_best:.6f}\")\n",
    "    \n",
    "    for horizon in ['1h', '4h']:\n",
    "        train_best = BASELINES[horizon]['best']\n",
    "        holdout_best = BASELINES[horizon]['holdout_best']\n",
    "        ratio = holdout_best / (train_best + 1e-8)\n",
    "        if ratio > 2:\n",
    "            print(f\"\\n  \u26a0\ufe0f {horizon}: Holdout baseline {ratio:.1f}x worse than train - regime change!\")\n",
    "\n",
    "FEATURE_IMPORTANCE = {}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING DATA SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training samples: {len(df_train_val):,}\")\n",
    "print(f\"Holdout samples: {len(df_holdout) if df_holdout is not None else 0:,}\")\n",
    "print(f\"Features: {len(numeric_features_1h)}\")\n",
    "print(f\"Distribution shift: {DISTRIBUTION_SHIFT_DETECTED} (magnitude: {SHIFT_MAGNITUDE:.2f})\")\n",
    "print(f\"Auto-adapt enabled: {AUTO_ADAPT_ON_SHIFT}\")\n",
    "if USE_ROLLING_WINDOW:\n",
    "    print(f\"Rolling window: {ROLLING_WINDOW_DAYS} days\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training - WITH PERMUTATION IMPORTANCE, FEATURE PRUNING & ASYMMETRIC LOSS\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "TRAIN_REGIME_MODELS = True\n",
    "MINIMUM_IMPROVEMENT = 0.05\n",
    "HOLDOUT_DEGRADATION_LIMIT = 0.30\n",
    "COMPUTE_PERMUTATION_IMPORTANCE = True\n",
    "ENABLE_FEATURE_PRUNING = True  # NEW: Auto-prune features with negative importance\n",
    "FEATURE_PRUNING_THRESHOLD = 0.0  # Remove features with importance below this\n",
    "USE_ASYMMETRIC_LOSS = True  # NEW: Use asymmetric loss (penalize under-prediction more)\n",
    "ASYMMETRIC_ALPHA = 0.6  # Weight for under-prediction (0.5 = symmetric, >0.5 = penalize under-prediction)\n",
    "\n",
    "def check_baseline_gate(model_mae, baseline_mae, model_name):\n",
    "    \"\"\"Check if model beats baseline by minimum threshold\"\"\"\n",
    "    improvement = (baseline_mae - model_mae) / baseline_mae\n",
    "    passed = improvement >= MINIMUM_IMPROVEMENT\n",
    "    if passed:\n",
    "        print(f\"  \u2713 PASSED baseline gate: {improvement*100:.1f}% improvement\")\n",
    "    else:\n",
    "        print(f\"  \u2717 FAILED baseline gate: {improvement*100:.1f}% (need {MINIMUM_IMPROVEMENT*100:.0f}%+)\")\n",
    "    return passed, improvement\n",
    "\n",
    "def check_holdout_gate(cv_mae, holdout_mae, model_name, holdout_baseline=None):\n",
    "    \"\"\"Check if holdout performance is acceptable\"\"\"\n",
    "    if cv_mae <= 0:\n",
    "        return False, 0\n",
    "    degradation = (holdout_mae - cv_mae) / cv_mae\n",
    "    \n",
    "    if holdout_baseline is not None:\n",
    "        holdout_improvement = (holdout_baseline - holdout_mae) / holdout_baseline\n",
    "        if holdout_improvement >= 0:\n",
    "            print(f\"  \u2713 Beats holdout baseline by {holdout_improvement*100:.1f}%\")\n",
    "            return True, degradation\n",
    "    \n",
    "    passed = degradation < HOLDOUT_DEGRADATION_LIMIT\n",
    "    if passed:\n",
    "        print(f\"  \u2713 PASSED holdout gate: {degradation*100:+.1f}% degradation\")\n",
    "    else:\n",
    "        print(f\"  \u2717 FAILED holdout gate: {degradation*100:+.1f}% degradation (limit: {HOLDOUT_DEGRADATION_LIMIT*100}%)\")\n",
    "    return passed, degradation\n",
    "\n",
    "def asymmetric_loss(y_true, y_pred, alpha=0.6):\n",
    "    \"\"\"\n",
    "    Asymmetric loss function (pinball/quantile loss variant).\n",
    "    alpha > 0.5 penalizes under-prediction more (y_true > y_pred)\n",
    "    alpha < 0.5 penalizes over-prediction more (y_true < y_pred)\n",
    "    \"\"\"\n",
    "    errors = y_true - y_pred\n",
    "    loss = np.where(errors >= 0, alpha * np.abs(errors), (1 - alpha) * np.abs(errors))\n",
    "    return np.mean(loss)\n",
    "\n",
    "def walk_forward_validate(model_class, model_params, X, y, baseline_mae, n_splits=5, purge_gap=120):\n",
    "    \"\"\"Walk-forward validation with purge gap\"\"\"\n",
    "    n = len(X)\n",
    "    fold_size = n // (n_splits + 1)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        train_end = fold_size * (fold + 1)\n",
    "        test_start = train_end + purge_gap\n",
    "        test_end = test_start + fold_size\n",
    "        \n",
    "        if test_end > n:\n",
    "            break\n",
    "            \n",
    "        X_train = X.iloc[:train_end]\n",
    "        X_test = X.iloc[test_start:test_end]\n",
    "        y_train = y.iloc[:train_end]\n",
    "        y_test = y.iloc[test_start:test_end]\n",
    "        \n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        fold_results.append(mae)\n",
    "    \n",
    "    if not fold_results:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        'avg_mae': np.mean(fold_results),\n",
    "        'std_mae': np.std(fold_results),\n",
    "        'improvement': (baseline_mae - np.mean(fold_results)) / baseline_mae\n",
    "    }\n",
    "\n",
    "def get_models_to_try(use_asymmetric=False):\n",
    "    \"\"\"Get list of simple, robust models\"\"\"\n",
    "    models = [\n",
    "        ('Ridge', Ridge, {'alpha': 1.0, 'random_state': 42}),\n",
    "        ('Huber', HuberRegressor, {'epsilon': 1.35, 'alpha': 0.1, 'max_iter': 1000}),\n",
    "        ('RF', RandomForestRegressor, {\n",
    "            'n_estimators': 30, 'max_depth': 4, 'min_samples_leaf': 20,\n",
    "            'random_state': 42, 'n_jobs': -1\n",
    "        }),\n",
    "        ('GBM', GradientBoostingRegressor, {\n",
    "            'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1,\n",
    "            'min_samples_leaf': 20, 'random_state': 42\n",
    "        }),\n",
    "    ]\n",
    "    \n",
    "    # Add asymmetric (quantile) models if enabled\n",
    "    if use_asymmetric:\n",
    "        models.append(('GBM-Asym', GradientBoostingRegressor, {\n",
    "            'loss': 'quantile', 'alpha': ASYMMETRIC_ALPHA,\n",
    "            'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1,\n",
    "            'min_samples_leaf': 20, 'random_state': 42\n",
    "        }))\n",
    "    \n",
    "    return models\n",
    "\n",
    "def compute_permutation_importance(model, X, y, scaler, feature_names, n_repeats=5):\n",
    "    \"\"\"Compute permutation importance for any model type\"\"\"\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Use sklearn's permutation_importance\n",
    "    result = permutation_importance(\n",
    "        model, X_scaled, y,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=42,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Convert to dictionary (higher = more important)\n",
    "    importance_dict = {}\n",
    "    for i, feat in enumerate(feature_names):\n",
    "        # Negative because we use neg_mae, so more negative = worse = more important\n",
    "        importance_dict[feat] = -result.importances_mean[i]\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    total = sum(importance_dict.values())\n",
    "    if total > 0:\n",
    "        importance_dict = {k: v/total for k, v in importance_dict.items()}\n",
    "    \n",
    "    return importance_dict\n",
    "\n",
    "def prune_features_by_importance(X_train, X_holdout, feature_names, importance_dict, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Remove features with importance below threshold.\n",
    "    Returns pruned dataframes and updated feature list.\n",
    "    \"\"\"\n",
    "    features_to_keep = [f for f in feature_names if importance_dict.get(f, 0) >= threshold]\n",
    "    features_to_remove = [f for f in feature_names if f not in features_to_keep]\n",
    "    \n",
    "    if not features_to_remove:\n",
    "        return X_train, X_holdout, feature_names, []\n",
    "    \n",
    "    print(f\"  Feature pruning: removing {len(features_to_remove)} features with importance < {threshold}\")\n",
    "    for f in features_to_remove:\n",
    "        print(f\"    - {f}: {importance_dict.get(f, 0):.4f}\")\n",
    "    \n",
    "    X_train_pruned = X_train[features_to_keep]\n",
    "    X_holdout_pruned = X_holdout[features_to_keep]\n",
    "    \n",
    "    return X_train_pruned, X_holdout_pruned, features_to_keep, features_to_remove\n",
    "\n",
    "def train_model_with_holdout(X_train, y_train, X_holdout, y_holdout, baseline_mae, \n",
    "                             horizon_name, feature_names, holdout_baseline=None):\n",
    "    \"\"\"Train model and select based on HOLDOUT performance\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {horizon_name} model\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train: {len(X_train):,}, Holdout: {len(X_holdout):,}, Features: {X_train.shape[1]}\")\n",
    "    print(f\"Train baseline: {baseline_mae:.6f}\", end=\"\")\n",
    "    if holdout_baseline:\n",
    "        print(f\", Holdout baseline: {holdout_baseline:.6f}\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    models_to_try = get_models_to_try(use_asymmetric=USE_ASYMMETRIC_LOSS)\n",
    "    results = []\n",
    "    \n",
    "    for name, model_class, params in models_to_try:\n",
    "        print(f\"\\n[{name}]\")\n",
    "        try:\n",
    "            wf_result = walk_forward_validate(model_class, params, X_train, y_train, baseline_mae, n_splits=4, purge_gap=120)\n",
    "            if not wf_result:\n",
    "                continue\n",
    "                \n",
    "            cv_mae = wf_result['avg_mae']\n",
    "            print(f\"  CV MAE: {cv_mae:.6f} \u00b1 {wf_result['std_mae']:.6f}\")\n",
    "            \n",
    "            scaler = RobustScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_holdout_scaled = scaler.transform(X_holdout)\n",
    "            \n",
    "            model = model_class(**params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            y_holdout_pred = model.predict(X_holdout_scaled)\n",
    "            holdout_mae = mean_absolute_error(y_holdout, y_holdout_pred)\n",
    "            holdout_improvement = (baseline_mae - holdout_mae) / baseline_mae\n",
    "            \n",
    "            # Also compute asymmetric loss for comparison\n",
    "            asym_loss = asymmetric_loss(y_holdout.values, y_holdout_pred, ASYMMETRIC_ALPHA)\n",
    "            \n",
    "            # Calculate vs holdout baseline\n",
    "            if holdout_baseline:\n",
    "                vs_holdout = (holdout_baseline - holdout_mae) / holdout_baseline\n",
    "                print(f\"  HOLDOUT MAE: {holdout_mae:.6f} ({vs_holdout*100:+.1f}% vs holdout baseline)\")\n",
    "            else:\n",
    "                print(f\"  HOLDOUT MAE: {holdout_mae:.6f} ({holdout_improvement*100:+.1f}% vs train baseline)\")\n",
    "            print(f\"  Asymmetric loss (\u03b1={ASYMMETRIC_ALPHA}): {asym_loss:.6f}\")\n",
    "            \n",
    "            use_baseline = holdout_baseline if holdout_baseline else baseline_mae\n",
    "            passed_baseline, _ = check_baseline_gate(holdout_mae, use_baseline, name)\n",
    "            passed_holdout, degradation = check_holdout_gate(cv_mae, holdout_mae, name, holdout_baseline)\n",
    "            \n",
    "            if passed_baseline or (passed_holdout and holdout_improvement > 0):\n",
    "                results.append({\n",
    "                    'name': name, 'model_class': model_class, 'params': params,\n",
    "                    'cv_mae': cv_mae, 'holdout_mae': holdout_mae,\n",
    "                    'asymmetric_loss': asym_loss,\n",
    "                    'holdout_improvement': holdout_improvement,\n",
    "                    'vs_holdout_baseline': (holdout_baseline - holdout_mae) / holdout_baseline if holdout_baseline else None,\n",
    "                    'model': model, 'scaler': scaler\n",
    "                })\n",
    "                print(f\"  \u2192 Accepted\")\n",
    "            else:\n",
    "                print(f\"  \u2192 Rejected\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed: {e}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"\\n\u26a0\ufe0f All models failed! Using Huber fallback...\")\n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        model = HuberRegressor(epsilon=1.35, alpha=0.1, max_iter=1000)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_holdout_pred = model.predict(scaler.transform(X_holdout))\n",
    "        holdout_mae = mean_absolute_error(y_holdout, y_holdout_pred)\n",
    "        \n",
    "        importance = {}\n",
    "        if COMPUTE_PERMUTATION_IMPORTANCE:\n",
    "            print(\"  Computing permutation importance...\")\n",
    "            importance = compute_permutation_importance(model, X_holdout, y_holdout, scaler, feature_names)\n",
    "        \n",
    "        return model, scaler, {\n",
    "            'name': 'Huber (fallback)',\n",
    "            'mae': holdout_mae,\n",
    "            'improvement': (baseline_mae - holdout_mae) / baseline_mae,\n",
    "            'vs_holdout_baseline': (holdout_baseline - holdout_mae) / holdout_baseline if holdout_baseline else None,\n",
    "            'passed_baseline': False,\n",
    "            'is_fallback': True\n",
    "        }, importance, feature_names\n",
    "    \n",
    "    best = min(results, key=lambda x: x['holdout_mae'])\n",
    "    print(f\"\\n>>> Best: {best['name']} (Holdout MAE: {best['holdout_mae']:.6f})\")\n",
    "    \n",
    "    # Compute permutation importance for the best model\n",
    "    importance = {}\n",
    "    if COMPUTE_PERMUTATION_IMPORTANCE:\n",
    "        print(\"  Computing permutation importance...\")\n",
    "        importance = compute_permutation_importance(best['model'], X_holdout, y_holdout, best['scaler'], list(feature_names))\n",
    "        top_3 = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        print(f\"  Top features: {', '.join([f'{f[0]}({f[1]:.2f})' for f in top_3])}\")\n",
    "        \n",
    "        # === FEATURE PRUNING ===\n",
    "        if ENABLE_FEATURE_PRUNING:\n",
    "            negative_features = [f for f, v in importance.items() if v < FEATURE_PRUNING_THRESHOLD]\n",
    "            if negative_features:\n",
    "                print(f\"\\n  Feature Pruning: {len(negative_features)} features have negative importance\")\n",
    "                \n",
    "                # Re-train with pruned features to see if it improves\n",
    "                X_train_pruned, X_holdout_pruned, pruned_features, removed = prune_features_by_importance(\n",
    "                    X_train, X_holdout, list(feature_names), importance, FEATURE_PRUNING_THRESHOLD\n",
    "                )\n",
    "                \n",
    "                if len(pruned_features) >= 5:  # Keep at least 5 features\n",
    "                    print(f\"  Re-training {best['name']} with {len(pruned_features)} features...\")\n",
    "                    \n",
    "                    scaler_pruned = RobustScaler()\n",
    "                    X_train_pruned_scaled = scaler_pruned.fit_transform(X_train_pruned)\n",
    "                    X_holdout_pruned_scaled = scaler_pruned.transform(X_holdout_pruned)\n",
    "                    \n",
    "                    model_pruned = best['model_class'](**best['params'])\n",
    "                    model_pruned.fit(X_train_pruned_scaled, y_train)\n",
    "                    \n",
    "                    y_holdout_pred_pruned = model_pruned.predict(X_holdout_pruned_scaled)\n",
    "                    holdout_mae_pruned = mean_absolute_error(y_holdout, y_holdout_pred_pruned)\n",
    "                    \n",
    "                    print(f\"  Pruned model MAE: {holdout_mae_pruned:.6f} (original: {best['holdout_mae']:.6f})\")\n",
    "                    \n",
    "                    # Use pruned model if it's better or within 2% of original\n",
    "                    if holdout_mae_pruned <= best['holdout_mae'] * 1.02:\n",
    "                        print(f\"  \u2713 Using pruned model ({len(pruned_features)} features)\")\n",
    "                        best['model'] = model_pruned\n",
    "                        best['scaler'] = scaler_pruned\n",
    "                        best['holdout_mae'] = holdout_mae_pruned\n",
    "                        feature_names = pruned_features\n",
    "                        importance = {f: importance[f] for f in pruned_features}\n",
    "                    else:\n",
    "                        print(f\"  \u2717 Keeping original model (pruned was worse)\")\n",
    "    \n",
    "    elif hasattr(best['model'], 'feature_importances_'):\n",
    "        importance = dict(zip(feature_names, best['model'].feature_importances_))\n",
    "    elif hasattr(best['model'], 'coef_'):\n",
    "        importance = dict(zip(feature_names, np.abs(best['model'].coef_)))\n",
    "    \n",
    "    return best['model'], best['scaler'], {\n",
    "        'name': best['name'],\n",
    "        'mae': best['holdout_mae'],\n",
    "        'cv_mae': best['cv_mae'],\n",
    "        'asymmetric_loss': best.get('asymmetric_loss'),\n",
    "        'improvement': best['holdout_improvement'],\n",
    "        'vs_holdout_baseline': best['vs_holdout_baseline'],\n",
    "        'passed_baseline': True,\n",
    "        'is_fallback': False\n",
    "    }, importance, list(feature_names)\n",
    "\n",
    "def train_regime_models(X_train, y_train, X_holdout, y_holdout, regime_train, regime_holdout,\n",
    "                        baseline_mae, horizon_name, feature_names, holdout_baseline=None):\n",
    "    \"\"\"Train separate models for each regime\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training REGIME-SPECIFIC {horizon_name} models\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    regime_models = {}\n",
    "    \n",
    "    for regime_val, regime_name in [(0, 'normal'), (1, 'elevated'), (2, 'spike')]:\n",
    "        train_mask = regime_train == regime_val\n",
    "        holdout_mask = regime_holdout == regime_val\n",
    "        \n",
    "        n_train = train_mask.sum()\n",
    "        n_holdout = holdout_mask.sum()\n",
    "        \n",
    "        print(f\"\\n[{regime_name.upper()}] Train: {n_train}, Holdout: {n_holdout}\")\n",
    "        \n",
    "        if n_train < 500 or n_holdout < 100:\n",
    "            print(f\"  Insufficient data, skipping\")\n",
    "            continue\n",
    "        \n",
    "        X_r_train = X_train[train_mask]\n",
    "        y_r_train = y_train[train_mask]\n",
    "        X_r_holdout = X_holdout[holdout_mask]\n",
    "        y_r_holdout = y_holdout[holdout_mask]\n",
    "        \n",
    "        model, scaler, metrics, importance, final_features = train_model_with_holdout(\n",
    "            X_r_train, y_r_train, X_r_holdout, y_r_holdout,\n",
    "            baseline_mae, f\"{horizon_name}_{regime_name}\", feature_names, holdout_baseline\n",
    "        )\n",
    "        \n",
    "        if model:\n",
    "            regime_models[regime_val] = {\n",
    "                'model': model, 'scaler': scaler, 'metrics': metrics,\n",
    "                'regime_name': regime_name, 'n_samples': n_train,\n",
    "                'features': final_features\n",
    "            }\n",
    "    \n",
    "    return regime_models\n",
    "\n",
    "def print_distribution_diagnostics(y_train, y_holdout, name=\"\"):\n",
    "    \"\"\"Print diagnostics\"\"\"\n",
    "    print(f\"\\n[Distribution - {name}]\")\n",
    "    print(f\"  Train:   mean={y_train.mean():.4f}, std={y_train.std():.4f}\")\n",
    "    print(f\"  Holdout: mean={y_holdout.mean():.4f}, std={y_holdout.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models with ENSEMBLE REGIME SWITCHING\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING ALL PREDICTION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trained_models = {}\n",
    "regime_specific_models = {}\n",
    "all_feature_importance = {}\n",
    "pruned_features_log = {}  # NEW: Track which features were pruned\n",
    "\n",
    "if not HAS_HOLDOUT or df_holdout is None or len(df_holdout) < 1000:\n",
    "    print(\"\\n\u26a0\ufe0f WARNING: Limited holdout data\")\n",
    "\n",
    "print(f\"\\nTraining set: {len(df_train_val):,} samples\")\n",
    "print(f\"Holdout set:  {len(df_holdout) if df_holdout is not None else 0:,} samples\")\n",
    "if DISTRIBUTION_SHIFT_DETECTED:\n",
    "    print(f\"\u26a0\ufe0f Distribution shift detected (magnitude: {SHIFT_MAGNITUDE:.2f})\")\n",
    "    if USE_ROLLING_WINDOW:\n",
    "        print(f\"   Auto-adapted to {ROLLING_WINDOW_DAYS}-day rolling window\")\n",
    "\n",
    "# === CREATE REGIME LABELS ===\n",
    "print(\"\\nCreating regime labels...\")\n",
    "regime_train = pd.Series(0, index=df_train_val.index)\n",
    "if 'gas_zscore_1h' in df_train_val.columns:\n",
    "    regime_train[df_train_val['gas_zscore_1h'] > 1] = 1\n",
    "if 'is_spike' in df_train_val.columns:\n",
    "    regime_train[df_train_val['is_spike'] == 1] = 2\n",
    "\n",
    "regime_holdout = None\n",
    "if HAS_HOLDOUT:\n",
    "    regime_holdout = pd.Series(0, index=df_holdout.index)\n",
    "    if 'gas_zscore_1h' in df_holdout.columns:\n",
    "        regime_holdout[df_holdout['gas_zscore_1h'] > 1] = 1\n",
    "    if 'is_spike' in df_holdout.columns:\n",
    "        regime_holdout[df_holdout['is_spike'] == 1] = 2\n",
    "\n",
    "print(f\"Regime distribution (train): {dict(regime_train.value_counts().sort_index())}\")\n",
    "if regime_holdout is not None:\n",
    "    print(f\"Regime distribution (holdout): {dict(regime_holdout.value_counts().sort_index())}\")\n",
    "\n",
    "# === ENSEMBLE PREDICTION FUNCTION ===\n",
    "def create_ensemble_predictor(global_model, global_scaler, regime_models, features):\n",
    "    \"\"\"Create a predictor that uses regime-specific models when available.\n",
    "    Handles feature mismatches when regime models use different (pruned) features.\n",
    "    \"\"\"\n",
    "    def predict(X, current_regime=None):\n",
    "        # Handle both DataFrame and array inputs\n",
    "        if hasattr(X, 'columns'):\n",
    "            # DataFrame input - select features by name\n",
    "            X_global = X[features] if all(f in X.columns for f in features) else X\n",
    "            X_scaled = global_scaler.transform(X_global)\n",
    "        else:\n",
    "            # Array input - assume correct feature order\n",
    "            X_scaled = global_scaler.transform(X)\n",
    "        \n",
    "        global_pred = global_model.predict(X_scaled)\n",
    "        \n",
    "        if current_regime is not None and regime_models and current_regime in regime_models:\n",
    "            regime_data = regime_models[current_regime]\n",
    "            regime_features = regime_data.get('features', features)\n",
    "            \n",
    "            if hasattr(X, 'columns'):\n",
    "                # DataFrame - select regime-specific features\n",
    "                available_features = [f for f in regime_features if f in X.columns]\n",
    "                if len(available_features) == len(regime_features):\n",
    "                    X_regime = X[regime_features]\n",
    "                    X_regime_scaled = regime_data['scaler'].transform(X_regime)\n",
    "                    regime_pred = regime_data['model'].predict(X_regime_scaled)\n",
    "                    # Weighted average: 70% regime, 30% global\n",
    "                    return 0.7 * regime_pred + 0.3 * global_pred\n",
    "            else:\n",
    "                # Array input - only use if feature counts match\n",
    "                if X.shape[1] == len(regime_features):\n",
    "                    X_regime_scaled = regime_data['scaler'].transform(X)\n",
    "                    regime_pred = regime_data['model'].predict(X_regime_scaled)\n",
    "                    return 0.7 * regime_pred + 0.3 * global_pred\n",
    "        \n",
    "        return global_pred\n",
    "    \n",
    "    return predict\n",
    "\n",
    "# === 1H MODEL ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1-HOUR MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_holdout_1h = df_holdout[numeric_features_1h] if HAS_HOLDOUT else X_1h.iloc[-1000:]\n",
    "y_holdout_1h = df_holdout['target_1h'] if HAS_HOLDOUT else y_1h.iloc[-1000:]\n",
    "mask_1h = y_holdout_1h.notna()\n",
    "X_holdout_1h = X_holdout_1h[mask_1h]\n",
    "y_holdout_1h = y_holdout_1h[mask_1h]\n",
    "\n",
    "print_distribution_diagnostics(y_1h, y_holdout_1h, \"1h targets\")\n",
    "\n",
    "holdout_baseline_1h = BASELINES['1h'].get('holdout_best', None)\n",
    "\n",
    "# Updated: now returns 5 values (model, scaler, metrics, importance, final_features)\n",
    "model_1h, scaler_1h, metrics_1h, importance_1h, features_1h = train_model_with_holdout(\n",
    "    X_1h, y_1h, X_holdout_1h, y_holdout_1h,\n",
    "    BASELINES['1h']['best'], '1h', list(numeric_features_1h), holdout_baseline_1h\n",
    ")\n",
    "if model_1h:\n",
    "    trained_models['1h'] = {\n",
    "        'model': model_1h, 'scaler': scaler_1h, \n",
    "        'metrics': metrics_1h, 'features': features_1h  # Use possibly-pruned features\n",
    "    }\n",
    "    if importance_1h:\n",
    "        all_feature_importance['1h'] = importance_1h\n",
    "    \n",
    "    # Log if features were pruned\n",
    "    if len(features_1h) < len(numeric_features_1h):\n",
    "        pruned_features_log['1h'] = {\n",
    "            'original_count': len(numeric_features_1h),\n",
    "            'pruned_count': len(features_1h),\n",
    "            'removed': list(set(numeric_features_1h) - set(features_1h))\n",
    "        }\n",
    "        print(f\"  \u2713 Features pruned: {len(numeric_features_1h)} \u2192 {len(features_1h)}\")\n",
    "\n",
    "# Train regime-specific models\n",
    "if TRAIN_REGIME_MODELS and regime_holdout is not None:\n",
    "    regime_holdout_1h = regime_holdout[mask_1h]\n",
    "    regime_models_1h = train_regime_models(\n",
    "        X_1h, y_1h, X_holdout_1h, y_holdout_1h,\n",
    "        regime_train, regime_holdout_1h,\n",
    "        BASELINES['1h']['best'], '1h', list(numeric_features_1h), holdout_baseline_1h\n",
    "    )\n",
    "    if regime_models_1h:\n",
    "        regime_specific_models['1h'] = regime_models_1h\n",
    "        # Create ensemble predictor with the actual features used\n",
    "        trained_models['1h']['ensemble_predict'] = create_ensemble_predictor(\n",
    "            model_1h, scaler_1h, regime_models_1h, features_1h\n",
    "        )\n",
    "\n",
    "# === 4H MODEL ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4-HOUR MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_holdout_4h = df_holdout[numeric_features_4h] if HAS_HOLDOUT else X_4h.iloc[-1000:]\n",
    "y_holdout_4h = df_holdout['target_4h'] if HAS_HOLDOUT else y_4h.iloc[-1000:]\n",
    "mask_4h = y_holdout_4h.notna()\n",
    "X_holdout_4h = X_holdout_4h[mask_4h]\n",
    "y_holdout_4h = y_holdout_4h[mask_4h]\n",
    "\n",
    "print_distribution_diagnostics(y_4h, y_holdout_4h, \"4h targets\")\n",
    "\n",
    "holdout_baseline_4h = BASELINES['4h'].get('holdout_best', None)\n",
    "\n",
    "model_4h, scaler_4h, metrics_4h, importance_4h, features_4h = train_model_with_holdout(\n",
    "    X_4h, y_4h, X_holdout_4h, y_holdout_4h,\n",
    "    BASELINES['4h']['best'], '4h', list(numeric_features_4h), holdout_baseline_4h\n",
    ")\n",
    "if model_4h:\n",
    "    trained_models['4h'] = {\n",
    "        'model': model_4h, 'scaler': scaler_4h,\n",
    "        'metrics': metrics_4h, 'features': features_4h\n",
    "    }\n",
    "    if importance_4h:\n",
    "        all_feature_importance['4h'] = importance_4h\n",
    "    \n",
    "    if len(features_4h) < len(numeric_features_4h):\n",
    "        pruned_features_log['4h'] = {\n",
    "            'original_count': len(numeric_features_4h),\n",
    "            'pruned_count': len(features_4h),\n",
    "            'removed': list(set(numeric_features_4h) - set(features_4h))\n",
    "        }\n",
    "        print(f\"  \u2713 Features pruned: {len(numeric_features_4h)} \u2192 {len(features_4h)}\")\n",
    "\n",
    "if TRAIN_REGIME_MODELS and regime_holdout is not None:\n",
    "    regime_holdout_4h = regime_holdout[mask_4h]\n",
    "    regime_models_4h = train_regime_models(\n",
    "        X_4h, y_4h, X_holdout_4h, y_holdout_4h,\n",
    "        regime_train, regime_holdout_4h,\n",
    "        BASELINES['4h']['best'], '4h', list(numeric_features_4h), holdout_baseline_4h\n",
    "    )\n",
    "    if regime_models_4h:\n",
    "        regime_specific_models['4h'] = regime_models_4h\n",
    "        trained_models['4h']['ensemble_predict'] = create_ensemble_predictor(\n",
    "            model_4h, scaler_4h, regime_models_4h, features_4h\n",
    "        )\n",
    "\n",
    "# === 24H MODEL ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"24-HOUR MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rph = 120\n",
    "total_hours = len(df_clean) / rph\n",
    "total_days = total_hours / 24\n",
    "print(f\"Total data: {total_days:.1f} days\")\n",
    "\n",
    "if total_days >= 30:\n",
    "    mask_24h_train = y_24h.notna()\n",
    "    X_24h_valid = X_24h[mask_24h_train]\n",
    "    y_24h_valid = y_24h[mask_24h_train]\n",
    "    \n",
    "    if HAS_HOLDOUT:\n",
    "        y_holdout_24h = df_holdout['target_24h']\n",
    "        mask_24h_holdout = y_holdout_24h.notna()\n",
    "        X_holdout_24h = df_holdout[numeric_features_24h][mask_24h_holdout]\n",
    "        y_holdout_24h = y_holdout_24h[mask_24h_holdout]\n",
    "    else:\n",
    "        X_holdout_24h = X_24h_valid.iloc[-500:]\n",
    "        y_holdout_24h = y_24h_valid.iloc[-500:]\n",
    "    \n",
    "    if len(y_holdout_24h) > 100:\n",
    "        model_24h, scaler_24h, metrics_24h, _, features_24h = train_model_with_holdout(\n",
    "            X_24h_valid, y_24h_valid, X_holdout_24h, y_holdout_24h,\n",
    "            BASELINES['4h']['best'], '24h', list(numeric_features_24h)\n",
    "        )\n",
    "        if model_24h:\n",
    "            trained_models['24h'] = {\n",
    "                'model': model_24h, 'scaler': scaler_24h,\n",
    "                'metrics': metrics_24h, 'features': features_24h,\n",
    "                'is_fallback': False\n",
    "            }\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f Using 4h model as 24h fallback\")\n",
    "        if model_4h:\n",
    "            trained_models['24h'] = {\n",
    "                'model': model_4h, 'scaler': scaler_4h,\n",
    "                'metrics': {'name': metrics_4h['name'] + ' (4h fallback)', 'mae': metrics_4h['mae'],\n",
    "                           'improvement': metrics_4h['improvement'], \n",
    "                           'vs_holdout_baseline': metrics_4h.get('vs_holdout_baseline'),\n",
    "                           'passed_baseline': metrics_4h.get('passed_baseline', False)},\n",
    "                'features': features_4h,\n",
    "                'is_fallback': True\n",
    "            }\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f Using 4h model as 24h fallback ({total_days:.1f} days < 30)\")\n",
    "    if model_4h:\n",
    "        trained_models['24h'] = {\n",
    "            'model': model_4h, 'scaler': scaler_4h,\n",
    "            'metrics': {'name': metrics_4h['name'] + ' (4h fallback)', 'mae': metrics_4h['mae'],\n",
    "                       'improvement': metrics_4h['improvement'],\n",
    "                       'vs_holdout_baseline': metrics_4h.get('vs_holdout_baseline'),\n",
    "                       'passed_baseline': metrics_4h.get('passed_baseline', False)},\n",
    "            'features': features_4h,\n",
    "            'is_fallback': True\n",
    "        }\n",
    "\n",
    "# === SUMMARY ===\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for horizon, data in trained_models.items():\n",
    "    m = data['metrics']\n",
    "    status = \"\u2713\" if m.get('passed_baseline', False) else \"\u26a0\"\n",
    "    fallback = \" (fallback)\" if data.get('is_fallback') else \"\"\n",
    "    \n",
    "    # Show vs holdout baseline if available\n",
    "    if m.get('vs_holdout_baseline') is not None:\n",
    "        vs_baseline = f\"{m['vs_holdout_baseline']*100:+.1f}% vs holdout baseline\"\n",
    "    else:\n",
    "        vs_baseline = f\"{m['improvement']*100:+.1f}% vs train baseline\"\n",
    "    \n",
    "    has_ensemble = \" [+ensemble]\" if 'ensemble_predict' in data else \"\"\n",
    "    n_features = len(data.get('features', []))\n",
    "    print(f\"{status} {horizon}: {m['name']}{fallback} | MAE: {m['mae']:.4f} | {vs_baseline} | {n_features} features{has_ensemble}\")\n",
    "\n",
    "if regime_specific_models:\n",
    "    print(f\"\\nRegime-specific models:\")\n",
    "    for horizon, regime_dict in regime_specific_models.items():\n",
    "        for regime_val, regime_data in regime_dict.items():\n",
    "            print(f\"  {horizon}_{regime_data['regime_name']}: MAE={regime_data['metrics']['mae']:.4f}\")\n",
    "\n",
    "if pruned_features_log:\n",
    "    print(f\"\\nFeature pruning summary:\")\n",
    "    for horizon, log in pruned_features_log.items():\n",
    "        print(f\"  {horizon}: {log['original_count']} \u2192 {log['pruned_count']} features\")\n",
    "\n",
    "FEATURE_IMPORTANCE = all_feature_importance.get('4h', all_feature_importance.get('1h', {}))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# PREDICTION INTERVALS - WITH UNCERTAINTY SCALING + TIME-OF-DAY ADAPTATION\n",
    "from sklearn.ensemble import GradientBoostingRegressor, IsolationForest\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING PREDICTION INTERVALS (Conformal + Time-Adaptive Uncertainty)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "quantile_models = {}\n",
    "conformal_residuals = {}\n",
    "uncertainty_scalers = {}\n",
    "time_period_calibration = {}  # NEW: Store time-of-day calibration factors\n",
    "\n",
    "def train_conformal_intervals(X, y, model, scaler, horizon, alpha=0.2):\n",
    "    \"\"\"Conformal prediction for guaranteed coverage. alpha=0.2 means 80% interval\"\"\"\n",
    "    cal_size = int(len(X) * 0.2)\n",
    "    X_train, X_cal = X.iloc[:-cal_size], X.iloc[-cal_size:]\n",
    "    y_train, y_cal = y.iloc[:-cal_size], y.iloc[-cal_size:]\n",
    "    \n",
    "    X_cal_scaled = scaler.transform(X_cal)\n",
    "    y_pred_cal = model.predict(X_cal_scaled)\n",
    "    \n",
    "    residuals = np.abs(y_cal.values - y_pred_cal)\n",
    "    q = np.quantile(residuals, 1 - alpha)\n",
    "    \n",
    "    return {\n",
    "        'quantile': q,\n",
    "        'residuals': residuals,\n",
    "        'coverage_target': 1 - alpha\n",
    "    }\n",
    "\n",
    "def compute_time_period_calibration(X, y, model, scaler, base_interval):\n",
    "    \"\"\"\n",
    "    Compute calibration factors for each time period.\n",
    "    Returns multipliers to apply to prediction intervals.\n",
    "    \"\"\"\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    abs_errors = np.abs(y.values - y_pred)\n",
    "    \n",
    "    # Define time periods\n",
    "    hours = X.index.hour\n",
    "    time_periods = {\n",
    "        'night': (0, 6),\n",
    "        'morning': (6, 12),\n",
    "        'afternoon': (12, 18),\n",
    "        'evening': (18, 24)\n",
    "    }\n",
    "    \n",
    "    # Calculate MAE and multiplier for each period\n",
    "    overall_mae = np.mean(abs_errors)\n",
    "    calibration = {}\n",
    "    \n",
    "    for period_name, (start, end) in time_periods.items():\n",
    "        mask = (hours >= start) & (hours < end)\n",
    "        if mask.sum() > 50:  # Minimum samples\n",
    "            period_mae = np.mean(abs_errors[mask])\n",
    "            period_std = np.std(abs_errors[mask])\n",
    "            \n",
    "            # Multiplier: how much wider should intervals be for this period?\n",
    "            multiplier = max(1.0, period_mae / overall_mae)\n",
    "            \n",
    "            # Also check coverage at base interval\n",
    "            in_interval = abs_errors[mask] <= base_interval\n",
    "            period_coverage = np.mean(in_interval)\n",
    "            \n",
    "            # If coverage is low, increase multiplier\n",
    "            if period_coverage < 0.75:  # Target is 80%\n",
    "                multiplier *= (0.80 / max(period_coverage, 0.5))\n",
    "            \n",
    "            calibration[period_name] = {\n",
    "                'mae': float(period_mae),\n",
    "                'std': float(period_std),\n",
    "                'multiplier': float(min(multiplier, 2.5)),  # Cap at 2.5x\n",
    "                'coverage_at_base': float(period_coverage),\n",
    "                'n_samples': int(mask.sum())\n",
    "            }\n",
    "            print(f\"    {period_name} ({start}-{end}h): MAE={period_mae:.4f}, multiplier={calibration[period_name]['multiplier']:.2f}x\")\n",
    "    \n",
    "    return calibration\n",
    "\n",
    "def train_uncertainty_scaler(X_train, scaler, residuals, features):\n",
    "    \"\"\"\n",
    "    Train a model to predict when uncertainty should be higher.\n",
    "    Uses:\n",
    "    1. Isolation Forest to detect out-of-distribution samples\n",
    "    2. Volatility features to detect high-uncertainty periods\n",
    "    \"\"\"\n",
    "    X_scaled = scaler.transform(X_train)\n",
    "    \n",
    "    # Train Isolation Forest to detect OOD samples\n",
    "    iso_forest = IsolationForest(\n",
    "        n_estimators=50, contamination=0.1,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    iso_forest.fit(X_scaled)\n",
    "    \n",
    "    # Calculate feature statistics for OOD detection\n",
    "    feature_means = X_scaled.mean(axis=0)\n",
    "    feature_stds = X_scaled.std(axis=0) + 1e-8\n",
    "    \n",
    "    # Calculate baseline interval width\n",
    "    base_interval = np.quantile(residuals, 0.8)\n",
    "    \n",
    "    return {\n",
    "        'iso_forest': iso_forest,\n",
    "        'feature_means': feature_means,\n",
    "        'feature_stds': feature_stds,\n",
    "        'base_interval': base_interval,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "def calculate_uncertainty_multiplier(X_sample, uncertainty_scaler, current_volatility=None, hour=None, time_calibration=None):\n",
    "    \"\"\"\n",
    "    Calculate how much to scale the prediction interval.\n",
    "    Returns multiplier >= 1.0\n",
    "    \n",
    "    NEW: Includes time-of-day adjustment\n",
    "    \"\"\"\n",
    "    multiplier = 1.0\n",
    "    \n",
    "    # 1. Out-of-distribution detection (Isolation Forest)\n",
    "    iso_score = uncertainty_scaler['iso_forest'].decision_function(X_sample.reshape(1, -1))[0]\n",
    "    # iso_score < 0 means anomaly (OOD)\n",
    "    if iso_score < -0.1:\n",
    "        ood_multiplier = 1 + abs(iso_score)  # Scale by how anomalous\n",
    "        multiplier *= min(ood_multiplier, 2.0)  # Cap at 2x\n",
    "    \n",
    "    # 2. Distance from training distribution\n",
    "    z_scores = np.abs((X_sample - uncertainty_scaler['feature_means']) / uncertainty_scaler['feature_stds'])\n",
    "    max_z = np.max(z_scores)\n",
    "    if max_z > 3:\n",
    "        dist_multiplier = 1 + (max_z - 3) * 0.2  # 20% increase per std beyond 3\n",
    "        multiplier *= min(dist_multiplier, 2.0)\n",
    "    \n",
    "    # 3. Volatility regime (if provided)\n",
    "    if current_volatility is not None:\n",
    "        if current_volatility == 2:  # Spike regime\n",
    "            multiplier *= 1.5\n",
    "        elif current_volatility == 1:  # Elevated regime\n",
    "            multiplier *= 1.2\n",
    "    \n",
    "    # 4. NEW: Time-of-day adjustment\n",
    "    if hour is not None and time_calibration is not None:\n",
    "        period = None\n",
    "        if 0 <= hour < 6:\n",
    "            period = 'night'\n",
    "        elif 6 <= hour < 12:\n",
    "            period = 'morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            period = 'afternoon'\n",
    "        elif 18 <= hour < 24:\n",
    "            period = 'evening'\n",
    "        \n",
    "        if period and period in time_calibration:\n",
    "            time_mult = time_calibration[period]['multiplier']\n",
    "            multiplier *= time_mult\n",
    "    \n",
    "    return min(multiplier, 4.0)  # Cap total multiplier at 4x\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{horizon} prediction intervals...\")\n",
    "    \n",
    "    data = trained_models[horizon]\n",
    "    features = data['features']\n",
    "    \n",
    "    X_h = df_train_val[features]\n",
    "    y_h = df_train_val[f'target_{horizon}']\n",
    "    \n",
    "    mask = y_h.notna()\n",
    "    X_h = X_h[mask]\n",
    "    y_h = y_h[mask]\n",
    "    \n",
    "    if len(X_h) < 1000:\n",
    "        print(f\"  \u26a0\ufe0f Insufficient data for {horizon} intervals, skipping\")\n",
    "        continue\n",
    "    \n",
    "    split_idx = int(len(X_h) * 0.8)\n",
    "    X_train, X_test = X_h.iloc[:split_idx], X_h.iloc[split_idx:]\n",
    "    y_train, y_test = y_h.iloc[:split_idx], y_h.iloc[split_idx:]\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # === Quantile Regression ===\n",
    "    q_models = {}\n",
    "    for q in [0.1, 0.5, 0.9]:\n",
    "        model = GradientBoostingRegressor(\n",
    "            loss='quantile', alpha=q,\n",
    "            n_estimators=50, max_depth=4,  # Reduced complexity\n",
    "            learning_rate=0.1, random_state=42\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        q_models[q] = model\n",
    "    \n",
    "    quantile_models[horizon] = (q_models, scaler)\n",
    "    print(f\"  \u2713 Quantile models trained (10th, 50th, 90th percentiles)\")\n",
    "    \n",
    "    # === Conformal Prediction ===\n",
    "    conformal = train_conformal_intervals(X_h, y_h, data['model'], data['scaler'], horizon, alpha=0.2)\n",
    "    conformal_residuals[horizon] = conformal\n",
    "    print(f\"  \u2713 Conformal interval: \u00b1{conformal['quantile']:.4f} gwei (80% coverage)\")\n",
    "    \n",
    "    # === Uncertainty Scaler ===\n",
    "    unc_scaler = train_uncertainty_scaler(X_train, scaler, conformal['residuals'], features)\n",
    "    uncertainty_scalers[horizon] = unc_scaler\n",
    "    print(f\"  \u2713 Uncertainty scaler trained (OOD detection + volatility scaling)\")\n",
    "    \n",
    "    # === NEW: Time-of-Day Calibration ===\n",
    "    print(f\"\\n  Computing time-of-day calibration factors...\")\n",
    "    time_cal = compute_time_period_calibration(\n",
    "        X_test, y_test, data['model'], data['scaler'], conformal['quantile']\n",
    "    )\n",
    "    time_period_calibration[horizon] = time_cal\n",
    "    print(f\"  \u2713 Time-of-day calibration computed\")\n",
    "    \n",
    "    # === Calibration Check with All Scaling Factors ===\n",
    "    print(f\"\\n  Calibration check...\")\n",
    "    \n",
    "    y_pred_test = data['model'].predict(data['scaler'].transform(X_test))\n",
    "    \n",
    "    # Standard quantile interval coverage\n",
    "    q_low = q_models[0.1].predict(X_test_scaled)\n",
    "    q_high = q_models[0.9].predict(X_test_scaled)\n",
    "    q_coverage = np.mean((y_test.values >= q_low) & (y_test.values <= q_high))\n",
    "    \n",
    "    # Standard conformal interval coverage\n",
    "    conf_low = y_pred_test - conformal['quantile']\n",
    "    conf_high = y_pred_test + conformal['quantile']\n",
    "    conf_coverage = np.mean((y_test.values >= conf_low) & (y_test.values <= conf_high))\n",
    "    \n",
    "    # Time-adaptive conformal interval coverage\n",
    "    time_adaptive_coverages = []\n",
    "    for i, (idx, row) in enumerate(X_test.iterrows()):\n",
    "        x_scaled = X_test_scaled[i]\n",
    "        hour = idx.hour if hasattr(idx, 'hour') else 12\n",
    "        \n",
    "        # Get multiplier including time-of-day\n",
    "        multiplier = calculate_uncertainty_multiplier(\n",
    "            x_scaled, unc_scaler, \n",
    "            hour=hour, \n",
    "            time_calibration=time_cal\n",
    "        )\n",
    "        scaled_interval = conformal['quantile'] * multiplier\n",
    "        in_interval = (y_test.iloc[i] >= y_pred_test[i] - scaled_interval) and \\\n",
    "                      (y_test.iloc[i] <= y_pred_test[i] + scaled_interval)\n",
    "        time_adaptive_coverages.append(in_interval)\n",
    "    time_adaptive_coverage = np.mean(time_adaptive_coverages)\n",
    "    \n",
    "    print(f\"    Quantile 80% interval: actual coverage = {q_coverage:.1%}\")\n",
    "    print(f\"    Conformal 80% interval: actual coverage = {conf_coverage:.1%}\")\n",
    "    print(f\"    Time-adaptive interval: actual coverage = {time_adaptive_coverage:.1%}\")\n",
    "    \n",
    "    # Store calibration results\n",
    "    trained_models[horizon]['calibration'] = {\n",
    "        'quantile_coverage': q_coverage,\n",
    "        'conformal_coverage': conf_coverage,\n",
    "        'time_adaptive_coverage': time_adaptive_coverage,\n",
    "        'conformal_width': conformal['quantile'],\n",
    "        'time_period_calibration': time_cal\n",
    "    }\n",
    "    \n",
    "    if abs(q_coverage - 0.8) > 0.1:\n",
    "        print(f\"    \u26a0\ufe0f Quantile intervals may be miscalibrated\")\n",
    "    if abs(conf_coverage - 0.8) > 0.1:\n",
    "        print(f\"    \u26a0\ufe0f Conformal intervals may need recalibration\")\n",
    "\n",
    "# Copy 4h to 24h if available\n",
    "if '4h' in quantile_models:\n",
    "    quantile_models['24h'] = quantile_models['4h']\n",
    "    print(\"\\n24h: Using 4h quantile models\")\n",
    "\n",
    "if '4h' in conformal_residuals:\n",
    "    conformal_residuals['24h'] = conformal_residuals['4h']\n",
    "\n",
    "if '4h' in uncertainty_scalers:\n",
    "    uncertainty_scalers['24h'] = uncertainty_scalers['4h']\n",
    "\n",
    "if '4h' in time_period_calibration:\n",
    "    time_period_calibration['24h'] = time_period_calibration['4h']\n",
    "\n",
    "print(f\"\\n\u2713 Prediction intervals with time-adaptive uncertainty ready for: {list(quantile_models.keys())}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-REGIME CALIBRATION VERIFICATION\n",
    "# Verify that prediction intervals are well-calibrated across different conditions\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-REGIME CALIBRATION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "regime_calibration = {}\n",
    "\n",
    "def verify_calibration_by_regime(X, y, model, scaler, conformal_quantile, \n",
    "                                  regime_labels, time_calibration=None, \n",
    "                                  uncertainty_scaler=None):\n",
    "    \"\"\"\n",
    "    Verify prediction interval coverage for each regime and time period.\n",
    "    Returns detailed calibration metrics.\n",
    "    \"\"\"\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    errors = np.abs(y.values - y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'overall': {},\n",
    "        'by_regime': {},\n",
    "        'by_time': {},\n",
    "        'warnings': []\n",
    "    }\n",
    "    \n",
    "    # Overall coverage at different interval widths\n",
    "    for coverage_target in [0.8, 0.9, 0.95]:\n",
    "        interval_width = np.quantile(errors, coverage_target)\n",
    "        actual_coverage = np.mean(errors <= interval_width)\n",
    "        results['overall'][f'coverage_{int(coverage_target*100)}'] = {\n",
    "            'target': coverage_target,\n",
    "            'actual': float(actual_coverage),\n",
    "            'interval_width': float(interval_width),\n",
    "            'calibrated': abs(actual_coverage - coverage_target) < 0.05\n",
    "        }\n",
    "    \n",
    "    # Coverage by regime\n",
    "    for regime_val, regime_name in [(0, 'normal'), (1, 'elevated'), (2, 'spike')]:\n",
    "        mask = regime_labels == regime_val\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        \n",
    "        regime_errors = errors[mask]\n",
    "        regime_y = y.values[mask]\n",
    "        regime_pred = y_pred[mask]\n",
    "        \n",
    "        # Standard conformal coverage\n",
    "        in_interval = regime_errors <= conformal_quantile\n",
    "        regime_coverage = np.mean(in_interval)\n",
    "        \n",
    "        # Adaptive coverage (if time calibration available)\n",
    "        if time_calibration and uncertainty_scaler:\n",
    "            hours = X.index.hour[mask] if hasattr(X.index, 'hour') else np.full(mask.sum(), 12)\n",
    "            adaptive_coverages = []\n",
    "            for i, (h, err) in enumerate(zip(hours, regime_errors)):\n",
    "                period = 'afternoon' if 12 <= h < 18 else ('morning' if 6 <= h < 12 else ('evening' if 18 <= h < 24 else 'night'))\n",
    "                mult = time_calibration.get(period, {}).get('multiplier', 1.0)\n",
    "                adapted_interval = conformal_quantile * mult\n",
    "                adaptive_coverages.append(err <= adapted_interval)\n",
    "            adaptive_coverage = np.mean(adaptive_coverages)\n",
    "        else:\n",
    "            adaptive_coverage = regime_coverage\n",
    "        \n",
    "        results['by_regime'][regime_name] = {\n",
    "            'n_samples': int(mask.sum()),\n",
    "            'mae': float(np.mean(regime_errors)),\n",
    "            'std': float(np.std(regime_errors)),\n",
    "            'conformal_coverage': float(regime_coverage),\n",
    "            'adaptive_coverage': float(adaptive_coverage),\n",
    "            'target_coverage': 0.8,\n",
    "            'calibrated': abs(regime_coverage - 0.8) < 0.1\n",
    "        }\n",
    "        \n",
    "        if regime_coverage < 0.7:\n",
    "            results['warnings'].append(f\"{regime_name} regime under-covered: {regime_coverage:.1%} (target 80%)\")\n",
    "    \n",
    "    # Coverage by time period\n",
    "    hours = X.index.hour if hasattr(X.index, 'hour') else pd.Series(12, index=X.index)\n",
    "    time_periods = {\n",
    "        'night': (0, 6),\n",
    "        'morning': (6, 12),\n",
    "        'afternoon': (12, 18),\n",
    "        'evening': (18, 24)\n",
    "    }\n",
    "    \n",
    "    for period_name, (start, end) in time_periods.items():\n",
    "        mask = (hours >= start) & (hours < end)\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        \n",
    "        period_errors = errors[mask]\n",
    "        \n",
    "        # Standard conformal coverage\n",
    "        in_interval = period_errors <= conformal_quantile\n",
    "        period_coverage = np.mean(in_interval)\n",
    "        \n",
    "        # Adaptive coverage\n",
    "        if time_calibration and period_name in time_calibration:\n",
    "            mult = time_calibration[period_name].get('multiplier', 1.0)\n",
    "            adapted_interval = conformal_quantile * mult\n",
    "            adaptive_coverage = np.mean(period_errors <= adapted_interval)\n",
    "        else:\n",
    "            adaptive_coverage = period_coverage\n",
    "        \n",
    "        results['by_time'][period_name] = {\n",
    "            'n_samples': int(mask.sum()),\n",
    "            'mae': float(np.mean(period_errors)),\n",
    "            'conformal_coverage': float(period_coverage),\n",
    "            'adaptive_coverage': float(adaptive_coverage),\n",
    "            'calibrated': abs(adaptive_coverage - 0.8) < 0.1\n",
    "        }\n",
    "        \n",
    "        if period_coverage < 0.7:\n",
    "            results['warnings'].append(f\"{period_name} period under-covered: {period_coverage:.1%} (target 80%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    if horizon not in conformal_residuals:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{horizon} Calibration Verification\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    data = trained_models[horizon]\n",
    "    model = data['model']\n",
    "    scaler = data['scaler']\n",
    "    features = data['features']\n",
    "    conformal = conformal_residuals[horizon]\n",
    "    time_cal = time_period_calibration.get(horizon, {})\n",
    "    unc_scaler = uncertainty_scalers.get(horizon, None)\n",
    "    \n",
    "    if not HAS_HOLDOUT:\n",
    "        print(\"  \u26a0\ufe0f No holdout data for calibration verification\")\n",
    "        continue\n",
    "    \n",
    "    # Get holdout data\n",
    "    X_test = df_holdout[features]\n",
    "    y_test = df_holdout[f'target_{horizon}']\n",
    "    mask = y_test.notna()\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    # Create regime labels\n",
    "    regime_test = pd.Series(0, index=X_test.index)\n",
    "    if 'gas_zscore_1h' in df_holdout.columns:\n",
    "        regime_test[df_holdout.loc[X_test.index, 'gas_zscore_1h'] > 1] = 1\n",
    "    if 'is_spike' in df_holdout.columns:\n",
    "        regime_test[df_holdout.loc[X_test.index, 'is_spike'] == 1] = 2\n",
    "    \n",
    "    # Verify calibration\n",
    "    cal_results = verify_calibration_by_regime(\n",
    "        X_test, y_test, model, scaler,\n",
    "        conformal['quantile'], regime_test.values,\n",
    "        time_cal, unc_scaler\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n  Overall Calibration:\")\n",
    "    for level, metrics in cal_results['overall'].items():\n",
    "        status = \"\u2713\" if metrics['calibrated'] else \"\u26a0\"\n",
    "        print(f\"    {status} {int(metrics['target']*100)}% target: actual={metrics['actual']:.1%}, width={metrics['interval_width']:.4f}\")\n",
    "    \n",
    "    print(\"\\n  Calibration by Regime:\")\n",
    "    for regime_name, metrics in cal_results['by_regime'].items():\n",
    "        status = \"\u2713\" if metrics['calibrated'] else \"\u26a0\"\n",
    "        print(f\"    {status} {regime_name}: conformal={metrics['conformal_coverage']:.1%}, adaptive={metrics['adaptive_coverage']:.1%} ({metrics['n_samples']} samples)\")\n",
    "    \n",
    "    print(\"\\n  Calibration by Time Period:\")\n",
    "    for period_name, metrics in cal_results['by_time'].items():\n",
    "        status = \"\u2713\" if metrics['calibrated'] else \"\u26a0\"\n",
    "        print(f\"    {status} {period_name}: conformal={metrics['conformal_coverage']:.1%}, adaptive={metrics['adaptive_coverage']:.1%}\")\n",
    "    \n",
    "    if cal_results['warnings']:\n",
    "        print(\"\\n  \u26a0\ufe0f Calibration Warnings:\")\n",
    "        for warning in cal_results['warnings']:\n",
    "            print(f\"    - {warning}\")\n",
    "    \n",
    "    # Store results\n",
    "    regime_calibration[horizon] = cal_results\n",
    "    \n",
    "    # Update trained_models with detailed calibration\n",
    "    if 'calibration' not in trained_models[horizon]:\n",
    "        trained_models[horizon]['calibration'] = {}\n",
    "    trained_models[horizon]['calibration']['regime_breakdown'] = cal_results['by_regime']\n",
    "    trained_models[horizon]['calibration']['time_breakdown'] = cal_results['by_time']\n",
    "    trained_models[horizon]['calibration']['warnings'] = cal_results['warnings']\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CALIBRATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_calibrated = True\n",
    "for horizon, cal in regime_calibration.items():\n",
    "    n_warnings = len(cal['warnings'])\n",
    "    if n_warnings == 0:\n",
    "        print(f\"  \u2713 {horizon}: All regimes and time periods well-calibrated\")\n",
    "    else:\n",
    "        all_calibrated = False\n",
    "        print(f\"  \u26a0 {horizon}: {n_warnings} calibration warning(s)\")\n",
    "\n",
    "if all_calibrated:\n",
    "    print(\"\\n\u2713 Prediction intervals are well-calibrated across all conditions\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f Some conditions show poor calibration - consider regime-specific intervals\")\n",
    "\n",
    "print(f\"\\n\u2713 Multi-regime calibration verification complete\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Direction Prediction - IMPROVED\n",
    "# Changes: Binary up/down, class weights, holdout evaluation, adaptive threshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DIRECTION MODELS (IMPROVED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "direction_models = {}\n",
    "\n",
    "# Configuration\n",
    "USE_BINARY = True  # Binary (up/down) vs 3-class (down/stable/up)\n",
    "DIRECTION_THRESHOLD = 0.01  # 1% threshold for direction change\n",
    "\n",
    "def create_binary_direction(target, current, threshold=0.01):\n",
    "    \"\"\"Create binary direction labels: 1=up, 0=down/stable\"\"\"\n",
    "    pct_change = (target - current) / (current + 1e-8)\n",
    "    return (pct_change > threshold).astype(int)\n",
    "\n",
    "def create_ternary_direction(target, current, threshold=0.02):\n",
    "    \"\"\"Create 3-class direction labels\"\"\"\n",
    "    pct_change = (target - current) / (current + 1e-8)\n",
    "    direction = pd.Series('stable', index=target.index)\n",
    "    direction[pct_change > threshold] = 'up'\n",
    "    direction[pct_change < -threshold] = 'down'\n",
    "    return direction\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{horizon.upper()} DIRECTION MODEL\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get features and targets\n",
    "    X_h = X_1h if horizon == '1h' else X_4h\n",
    "    features = numeric_features_1h if horizon == '1h' else numeric_features_4h\n",
    "    \n",
    "    # Get raw target for direction calculation\n",
    "    if 'target_1h_raw' in df_train_val.columns:\n",
    "        target_raw = df_train_val[f'target_{horizon}_raw']\n",
    "    else:\n",
    "        target_raw = df_train_val[f'target_{horizon}']\n",
    "    \n",
    "    current = df_train_val['gas']\n",
    "    \n",
    "    # Create direction labels\n",
    "    if USE_BINARY:\n",
    "        y_dir = create_binary_direction(target_raw, current, DIRECTION_THRESHOLD)\n",
    "        print(f\"Binary classification (threshold: {DIRECTION_THRESHOLD*100}%)\")\n",
    "    else:\n",
    "        y_dir = create_ternary_direction(target_raw, current)\n",
    "        print(f\"3-class classification (threshold: {DIRECTION_THRESHOLD*100}%)\")\n",
    "    \n",
    "    mask = y_dir.notna() & target_raw.notna()\n",
    "    X_d = X_h[mask]\n",
    "    y_d = y_dir[mask]\n",
    "    \n",
    "    if len(X_d) < 1000:\n",
    "        print(f\"  \u26a0\ufe0f Insufficient data, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = y_d.value_counts()\n",
    "    print(f\"Class distribution: {dict(class_counts)}\")\n",
    "    \n",
    "    # Compute class weights\n",
    "    classes = np.unique(y_d)\n",
    "    weights = compute_class_weight('balanced', classes=classes, y=y_d)\n",
    "    class_weight_dict = dict(zip(classes, weights))\n",
    "    print(f\"Class weights: {class_weight_dict}\")\n",
    "    \n",
    "    # Split - use holdout if available\n",
    "    if HAS_HOLDOUT:\n",
    "        X_train, X_test = X_d, df_holdout[features]\n",
    "        y_train = y_d\n",
    "        \n",
    "        # Create holdout labels\n",
    "        if 'target_1h_raw' in df_holdout.columns:\n",
    "            holdout_target = df_holdout[f'target_{horizon}_raw']\n",
    "        else:\n",
    "            holdout_target = df_holdout[f'target_{horizon}']\n",
    "        holdout_current = df_holdout['gas']\n",
    "        \n",
    "        if USE_BINARY:\n",
    "            y_test = create_binary_direction(holdout_target, holdout_current, DIRECTION_THRESHOLD)\n",
    "        else:\n",
    "            y_test = create_ternary_direction(holdout_target, holdout_current)\n",
    "        \n",
    "        test_mask = y_test.notna() & holdout_target.notna()\n",
    "        X_test = X_test[test_mask]\n",
    "        y_test = y_test[test_mask]\n",
    "        print(f\"Using holdout for evaluation ({len(y_test)} samples)\")\n",
    "    else:\n",
    "        split_idx = int(len(X_d) * 0.8)\n",
    "        X_train, X_test = X_d.iloc[:split_idx], X_d.iloc[split_idx:]\n",
    "        y_train, y_test = y_d.iloc[:split_idx], y_d.iloc[split_idx:]\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Try multiple classifiers\n",
    "    classifiers = [\n",
    "        ('LogReg', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)),\n",
    "        ('RF', RandomForestClassifier(n_estimators=30, max_depth=4, class_weight='balanced', random_state=42, n_jobs=-1)),\n",
    "        ('GBM', GradientBoostingClassifier(n_estimators=30, max_depth=3, learning_rate=0.1, random_state=42)),\n",
    "    ]\n",
    "    \n",
    "    best_clf = None\n",
    "    best_acc = 0\n",
    "    best_name = None\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        try:\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            print(f\"  {name}: Acc={acc:.1%}, F1={f1:.3f}\")\n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_clf = clf\n",
    "                best_name = name\n",
    "                best_f1 = f1\n",
    "        except Exception as e:\n",
    "            print(f\"  {name}: Failed - {e}\")\n",
    "    \n",
    "    if best_clf is None:\n",
    "        print(f\"  \u26a0\ufe0f All classifiers failed\")\n",
    "        continue\n",
    "    \n",
    "    # Baseline: always predict majority class\n",
    "    majority_class = y_train.mode()[0]\n",
    "    baseline_acc = (y_test == majority_class).mean()\n",
    "    improvement = (best_acc - baseline_acc) / baseline_acc * 100\n",
    "    \n",
    "    print(f\"\\n  >>> Best: {best_name} (Acc: {best_acc:.1%}, vs baseline {baseline_acc:.1%}: {improvement:+.1f}%)\")\n",
    "    \n",
    "    direction_models[horizon] = {\n",
    "        'model': best_clf,\n",
    "        'scaler': scaler,\n",
    "        'accuracy': float(best_acc),\n",
    "        'f1_score': float(best_f1),\n",
    "        'baseline_accuracy': float(baseline_acc),\n",
    "        'improvement_vs_baseline': float(improvement),\n",
    "        'model_name': best_name,\n",
    "        'is_binary': USE_BINARY,\n",
    "        'threshold': DIRECTION_THRESHOLD\n",
    "    }\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DIRECTION MODEL SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "for horizon, data in direction_models.items():\n",
    "    imp = data['improvement_vs_baseline']\n",
    "    status = \"\u2713\" if imp > 5 else \"\u26a0\" if imp > 0 else \"\u2717\"\n",
    "    print(f\"{status} {horizon}: {data['model_name']} | Acc: {data['accuracy']:.1%} | vs baseline: {imp:+.1f}%\")\n",
    ""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# REGIME DETECTION\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING REGIME DETECTION MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create regime labels from gas statistics (instead of volatility_regime)\n",
    "# 0 = Normal, 1 = Elevated, 2 = Spike\n",
    "if 'gas_zscore_1h' in df_train_val.columns and 'is_spike' in df_train_val.columns:\n",
    "    # Create regime from z-score: low (<-0.5), normal (-0.5 to 1), elevated (1 to 2), spike (>2)\n",
    "    zscore = df_train_val['gas_zscore_1h']\n",
    "    is_spike = df_train_val['is_spike']\n",
    "    \n",
    "    regime_labels = pd.Series(0, index=df_train_val.index)  # Default: Normal\n",
    "    regime_labels[zscore > 1] = 1  # Elevated\n",
    "    regime_labels[is_spike == 1] = 2  # Spike\n",
    "    \n",
    "    X_r = X_4h.copy()\n",
    "    y_r = regime_labels\n",
    "    \n",
    "    if len(X_r) < 500:\n",
    "        print(\"\u26a0\ufe0f Insufficient data for regime detection\")\n",
    "        regime_clf = None\n",
    "        regime_scaler = None\n",
    "        regime_accuracy = 0\n",
    "    else:\n",
    "        # Train/test split\n",
    "        split_idx = int(len(X_r) * 0.8)\n",
    "        X_train, X_test = X_r.iloc[:split_idx], X_r.iloc[split_idx:]\n",
    "        y_train, y_test = y_r.iloc[:split_idx], y_r.iloc[split_idx:]\n",
    "        \n",
    "        regime_scaler = RobustScaler()\n",
    "        X_train_scaled = regime_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = regime_scaler.transform(X_test)\n",
    "        \n",
    "        # Train classifier (simple, reduced complexity)\n",
    "        regime_clf = RandomForestClassifier(\n",
    "            n_estimators=30, max_depth=4,\n",
    "            min_samples_leaf=20,\n",
    "            random_state=42, n_jobs=-1\n",
    "        )\n",
    "        regime_clf.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = regime_clf.predict(X_test_scaled)\n",
    "        regime_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Regime classes: Normal (0), Elevated (1), Spike (2)\")\n",
    "        print(f\"Class distribution: {dict(y_r.value_counts().sort_index())}\")\n",
    "        print(f\"Accuracy: {regime_accuracy:.1%}\")\n",
    "        \n",
    "        if regime_accuracy > 0.95:\n",
    "            print(\"\u26a0\ufe0f Warning: Very high accuracy may indicate class imbalance or overfitting\")\n",
    "else:\n",
    "    regime_clf = None\n",
    "    regime_scaler = None\n",
    "    regime_accuracy = 0\n",
    "    print(\"\u26a0\ufe0f Missing gas_zscore_1h or is_spike, skipping regime detection\")\n",
    ""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Spike Detectors\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"TRAINING SPIKE DETECTORS\")\nprint(\"=\"*60)\n\nspike_models = {}\n\nfor horizon, X_h, y_target in [('1h', X_1h, y_1h), ('4h', X_4h, y_4h)]:\n    print(f\"\\n",
    "{horizon} spike detector...\")\n    \n    # Create spike labels (>2 std from mean is a spike)\n    mask = y_target.notna()\n    X_s = X_h[mask]\n    y_s = y_target[mask]\n    current = current_gas[mask]\n    \n    # Define spike threshold\n    price_change = y_s - current\n    threshold = price_change.std() * 2\n    spike_labels = (price_change > threshold).astype(int)\n    \n    spike_rate = spike_labels.mean()\n    print(f\"  Spike rate: {spike_rate:.1%}\")\n    \n    if spike_rate < 0.01 or spike_rate > 0.5:\n        print(f\"  \u26a0\ufe0f Unusual spike rate, skipping\")\n        continue\n    \n    if len(X_s) < 1000:\n        print(f\"  \u26a0\ufe0f Insufficient data, skipping\")\n        continue\n    \n    # Train/test split\n    split_idx = int(len(X_s) * 0.8)\n    X_train, X_test = X_s.iloc[:split_idx], X_s.iloc[split_idx:]\n    y_train, y_test = spike_labels.iloc[:split_idx], spike_labels.iloc[split_idx:]\n    \n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train with class weights\n    clf = GradientBoostingClassifier(\n        n_estimators=50, max_depth=4,\n        learning_rate=0.1, random_state=42\n    )\n    clf.fit(X_train_scaled, y_train)\n    \n    # Evaluate\n    y_pred = clf.predict(X_test_scaled)\n    acc = accuracy_score(y_test, y_pred)\n    \n    spike_models[horizon] = (clf, scaler)\n    print(f\"  Accuracy: {acc:.1%}\")\n\n# Copy 4h to 24h if available\nif '4h' in spike_models:\n    spike_models['24h'] = spike_models['4h']\n    print(\"\\n",
    "24h: Using 4h spike detector (fallback)\")\n\nprint(f\"\\n",
    "\u2713 Spike detectors trained for: {list(spike_models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SPIKE FORECASTING MODEL - IMPROVED with percentile-based definition and threshold tuning\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SPIKE FORECASTING MODELS (IMPROVED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if imblearn is available\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    HAS_SMOTE = True\n",
    "    print(\"\u2713 SMOTE available for handling class imbalance\")\n",
    "except ImportError:\n",
    "    HAS_SMOTE = False\n",
    "    print(\"\u26a0\ufe0f imblearn not available, using class weights instead\")\n",
    "\n",
    "spike_forecast_models = {}\n",
    "\n",
    "def create_spike_forecast_target_percentile(df, horizon_hours, percentile=90):\n",
    "    \"\"\"\n",
    "    Create binary target using PERCENTILE-BASED definition.\n",
    "    Spike = gas price in top (100-percentile)% of values.\n",
    "    This ensures balanced classes regardless of market conditions.\n",
    "    \"\"\"\n",
    "    rph = 120  # rows per hour\n",
    "    horizon_periods = horizon_hours * rph\n",
    "    \n",
    "    # Define spike as top percentile of gas prices (using rolling reference)\n",
    "    # Use a rolling percentile to adapt to changing market conditions\n",
    "    rolling_threshold = df['gas'].rolling(\n",
    "        window=rph * 24,  # 24-hour rolling window\n",
    "        min_periods=rph * 4  # minimum 4 hours\n",
    "    ).quantile(percentile / 100)\n",
    "    \n",
    "    # Fall back to global percentile where rolling not available\n",
    "    global_threshold = df['gas'].quantile(percentile / 100)\n",
    "    rolling_threshold = rolling_threshold.fillna(global_threshold)\n",
    "    \n",
    "    # Current point is spike if above threshold\n",
    "    is_spike = (df['gas'] > rolling_threshold).astype(int)\n",
    "    \n",
    "    # Will there be a spike in the next N hours?\n",
    "    # Use forward-looking rolling max\n",
    "    will_spike = is_spike.shift(-1).rolling(horizon_periods, min_periods=1).max()\n",
    "    will_spike = will_spike.shift(-horizon_periods + 1)  # Align properly\n",
    "    \n",
    "    return will_spike.fillna(0).astype(int), rolling_threshold\n",
    "\n",
    "def find_optimal_threshold(y_true, y_prob, target_metric='f1'):\n",
    "    \"\"\"Find optimal classification threshold by maximizing F1 or precision-recall tradeoff\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    \n",
    "    # Calculate F1 for each threshold\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
    "    \n",
    "    if target_metric == 'f1':\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "    elif target_metric == 'balanced':\n",
    "        # Maximize balanced accuracy (equal weight to precision and recall)\n",
    "        balanced = (precision[:-1] + recall[:-1]) / 2\n",
    "        best_idx = np.argmax(balanced)\n",
    "    else:\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "    \n",
    "    return thresholds[best_idx], f1_scores[best_idx]\n",
    "\n",
    "# Try different percentile definitions to find the best\n",
    "PERCENTILES_TO_TRY = [90, 85, 80, 75]  # Top 10%, 15%, 20%, 25%\n",
    "\n",
    "for horizon_name, horizon_hours in [('1h', 1), ('4h', 4)]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{horizon_name} Spike Forecast Model\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    best_model_result = None\n",
    "    best_auc = 0\n",
    "    \n",
    "    for percentile in PERCENTILES_TO_TRY:\n",
    "        print(f\"\\n  Testing percentile={percentile} (top {100-percentile}% = spike)...\")\n",
    "        \n",
    "        # Create spike forecast target with percentile definition\n",
    "        will_spike, spike_threshold = create_spike_forecast_target_percentile(\n",
    "            df_train_val, horizon_hours, percentile=percentile\n",
    "        )\n",
    "        \n",
    "        # Use features\n",
    "        features = numeric_features_4h\n",
    "        X_sf = df_train_val[features]\n",
    "        y_sf = will_spike\n",
    "        \n",
    "        # Remove NaN\n",
    "        mask = y_sf.notna() & (y_sf.index.isin(X_sf.index))\n",
    "        X_sf = X_sf[mask]\n",
    "        y_sf = y_sf[mask]\n",
    "        \n",
    "        if len(X_sf) < 1000:\n",
    "            print(f\"    \u26a0\ufe0f Insufficient data, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Class distribution\n",
    "        spike_rate = y_sf.mean()\n",
    "        print(f\"    Spike rate: {spike_rate:.1%} ({y_sf.sum():.0f} spikes in {len(y_sf)} samples)\")\n",
    "        \n",
    "        # Skip if still too imbalanced (>80% or <5% spikes)\n",
    "        if spike_rate > 0.8 or spike_rate < 0.05:\n",
    "            print(f\"    \u26a0\ufe0f Class imbalance too severe, trying next percentile\")\n",
    "            continue\n",
    "        \n",
    "        # Split\n",
    "        if HAS_HOLDOUT:\n",
    "            X_train, X_test = X_sf, df_holdout[features]\n",
    "            y_train = y_sf\n",
    "            \n",
    "            # Create holdout target with same percentile\n",
    "            will_spike_holdout, _ = create_spike_forecast_target_percentile(\n",
    "                df_holdout, horizon_hours, percentile=percentile\n",
    "            )\n",
    "            y_test = will_spike_holdout\n",
    "            \n",
    "            test_mask = y_test.notna()\n",
    "            X_test = X_test[test_mask]\n",
    "            y_test = y_test[test_mask]\n",
    "        else:\n",
    "            split_idx = int(len(X_sf) * 0.8)\n",
    "            X_train, X_test = X_sf.iloc[:split_idx], X_sf.iloc[split_idx:]\n",
    "            y_train, y_test = y_sf.iloc[:split_idx], y_sf.iloc[split_idx:]\n",
    "        \n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Handle class imbalance with SMOTE or class weights\n",
    "        use_smote = HAS_SMOTE and y_train.sum() >= 10 and (y_train == 0).sum() >= 10\n",
    "        \n",
    "        if use_smote:\n",
    "            try:\n",
    "                k_neighbors = min(5, int(min(y_train.sum(), (y_train == 0).sum())) - 1)\n",
    "                if k_neighbors < 1:\n",
    "                    k_neighbors = 1\n",
    "                smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "                X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "                print(f\"    SMOTE applied: {len(y_train)} \u2192 {len(y_train_resampled)} samples\")\n",
    "            except Exception as e:\n",
    "                use_smote = False\n",
    "                X_train_resampled, y_train_resampled = X_train_scaled, y_train\n",
    "        else:\n",
    "            X_train_resampled, y_train_resampled = X_train_scaled, y_train\n",
    "        \n",
    "        # Train model with class weights (even with SMOTE for extra balancing)\n",
    "        clf = GradientBoostingClassifier(\n",
    "            n_estimators=100, max_depth=5, learning_rate=0.1,\n",
    "            min_samples_leaf=20, random_state=42\n",
    "        )\n",
    "        \n",
    "        if use_smote:\n",
    "            clf.fit(X_train_resampled, y_train_resampled)\n",
    "        else:\n",
    "            # Calculate sample weights for GBM (doesn't have class_weight)\n",
    "            weight_0 = len(y_train) / (2 * (y_train == 0).sum()) if (y_train == 0).sum() > 0 else 1\n",
    "            weight_1 = len(y_train) / (2 * y_train.sum()) if y_train.sum() > 0 else 1\n",
    "            sample_weights = np.where(y_train == 1, weight_1, weight_0)\n",
    "            clf.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "        \n",
    "        # Get probabilities\n",
    "        y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        try:\n",
    "            optimal_threshold, optimal_f1 = find_optimal_threshold(y_test, y_prob, 'f1')\n",
    "            print(f\"    Optimal threshold: {optimal_threshold:.3f} (F1={optimal_f1:.3f})\")\n",
    "        except:\n",
    "            optimal_threshold = 0.5\n",
    "        \n",
    "        # Evaluate at optimal threshold\n",
    "        y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "        except:\n",
    "            auc = 0.5\n",
    "        \n",
    "        print(f\"    At threshold {optimal_threshold:.2f}: P={precision:.1%}, R={recall:.1%}, F1={f1:.3f}, AUC={auc:.3f}\")\n",
    "        \n",
    "        # Track best model\n",
    "        if auc > best_auc and auc > 0.55:  # Require AUC > 0.55 to be useful\n",
    "            best_auc = auc\n",
    "            best_model_result = {\n",
    "                'model': clf,\n",
    "                'scaler': scaler,\n",
    "                'percentile': percentile,\n",
    "                'optimal_threshold': float(optimal_threshold),\n",
    "                'precision': float(precision),\n",
    "                'recall': float(recall),\n",
    "                'f1_score': float(f1),\n",
    "                'auc': float(auc),\n",
    "                'spike_rate_train': float(spike_rate),\n",
    "                'spike_rate_test': float(y_test.mean()),\n",
    "                'spike_threshold_mean': float(spike_threshold.mean())\n",
    "            }\n",
    "    \n",
    "    # Store best model or report failure\n",
    "    if best_model_result:\n",
    "        spike_forecast_models[horizon_name] = best_model_result\n",
    "        print(f\"\\n  \u2713 Best {horizon_name} model: percentile={best_model_result['percentile']}, AUC={best_model_result['auc']:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n  \u26a0\ufe0f No acceptable {horizon_name} spike forecast model found (AUC > 0.55 required)\")\n",
    "        # Store placeholder with metrics indicating failure\n",
    "        spike_forecast_models[horizon_name] = {\n",
    "            'model': None,\n",
    "            'scaler': None,\n",
    "            'percentile': None,\n",
    "            'optimal_threshold': 0.5,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'auc': 0.5,\n",
    "            'spike_rate_train': 0.0,\n",
    "            'spike_rate_test': 0.0,\n",
    "            'note': 'No model met minimum AUC threshold of 0.55'\n",
    "        }\n",
    "\n",
    "print(f\"\\n\u2713 Spike forecast models trained for: {list(spike_forecast_models.keys())}\")\n",
    "for h, data in spike_forecast_models.items():\n",
    "    if data.get('model') is not None:\n",
    "        print(f\"  {h}: AUC={data['auc']:.3f}, threshold={data['optimal_threshold']:.2f}, spike_rate={data['spike_rate_test']:.1%}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DYNAMIC ENSEMBLE WEIGHTING - Adjust weights based on recent performance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DYNAMIC ENSEMBLE WEIGHTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_dynamic_weights(global_errors, regime_errors, decay=0.9):\n",
    "    \"\"\"Calculate dynamic weights based on exponentially weighted recent errors\"\"\"\n",
    "    if len(global_errors) == 0 or len(regime_errors) == 0:\n",
    "        return 0.5, 0.5  # Default equal weights\n",
    "    \n",
    "    # Exponential weights (more recent = higher weight)\n",
    "    n = len(global_errors)\n",
    "    exp_weights = np.array([decay ** (n - i - 1) for i in range(n)])\n",
    "    exp_weights = exp_weights / exp_weights.sum()\n",
    "    \n",
    "    global_weighted_error = np.sum(global_errors * exp_weights)\n",
    "    regime_weighted_error = np.sum(regime_errors * exp_weights)\n",
    "    \n",
    "    # Inverse error weighting\n",
    "    total_inv_error = 1/(global_weighted_error + 1e-8) + 1/(regime_weighted_error + 1e-8)\n",
    "    global_weight = (1/(global_weighted_error + 1e-8)) / total_inv_error\n",
    "    regime_weight = (1/(regime_weighted_error + 1e-8)) / total_inv_error\n",
    "    \n",
    "    return global_weight, regime_weight\n",
    "\n",
    "def create_dynamic_ensemble_predictor(global_model, global_scaler, regime_models, features, decay=0.9):\n",
    "    \"\"\"Create ensemble predictor with dynamic weighting.\n",
    "    Handles feature mismatches when regime models use different (pruned) features.\n",
    "    \"\"\"\n",
    "    # Track recent errors\n",
    "    recent_errors = {'global': [], 'regime': {}}\n",
    "    \n",
    "    def predict(X, current_regime=None, actual_value=None):\n",
    "        nonlocal recent_errors\n",
    "        \n",
    "        # Handle DataFrame vs array input for global model\n",
    "        if hasattr(X, 'columns'):\n",
    "            X_global = X[features] if all(f in X.columns for f in features) else X\n",
    "            X_scaled = global_scaler.transform(X_global)\n",
    "        else:\n",
    "            X_scaled = global_scaler.transform(X)\n",
    "        \n",
    "        global_pred = global_model.predict(X_scaled)\n",
    "        \n",
    "        if current_regime is not None and regime_models and current_regime in regime_models:\n",
    "            regime_data = regime_models[current_regime]\n",
    "            regime_features = regime_data.get('features', features)\n",
    "            \n",
    "            # Handle feature subsetting for regime model\n",
    "            try:\n",
    "                if hasattr(X, 'columns'):\n",
    "                    available_features = [f for f in regime_features if f in X.columns]\n",
    "                    if len(available_features) == len(regime_features):\n",
    "                        X_regime = X[regime_features]\n",
    "                        X_regime_scaled = regime_data['scaler'].transform(X_regime)\n",
    "                        regime_pred = regime_data['model'].predict(X_regime_scaled)\n",
    "                    else:\n",
    "                        # Feature mismatch - use global only\n",
    "                        return global_pred\n",
    "                else:\n",
    "                    # Array input - check if shapes match\n",
    "                    expected_features = regime_data['scaler'].n_features_in_\n",
    "                    if X.shape[1] == expected_features:\n",
    "                        X_regime_scaled = regime_data['scaler'].transform(X)\n",
    "                        regime_pred = regime_data['model'].predict(X_regime_scaled)\n",
    "                    else:\n",
    "                        # Feature mismatch - use global only\n",
    "                        return global_pred\n",
    "                \n",
    "                # Get dynamic weights\n",
    "                if current_regime in recent_errors['regime'] and len(recent_errors['regime'][current_regime]) > 0:\n",
    "                    global_w, regime_w = calculate_dynamic_weights(\n",
    "                        np.array(recent_errors['global'][-100:]),\n",
    "                        np.array(recent_errors['regime'][current_regime][-100:]),\n",
    "                        decay\n",
    "                    )\n",
    "                else:\n",
    "                    global_w, regime_w = 0.3, 0.7  # Default weights\n",
    "                \n",
    "                return global_w * global_pred + regime_w * regime_pred\n",
    "            except Exception as e:\n",
    "                # On any error, fall back to global prediction\n",
    "                return global_pred\n",
    "        \n",
    "        return global_pred\n",
    "    \n",
    "    return predict, recent_errors\n",
    "\n",
    "# Create dynamic ensemble for each horizon\n",
    "dynamic_ensembles = {}\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    if horizon not in regime_specific_models:\n",
    "        print(f\"\\n{horizon}: No regime models, skipping dynamic ensemble\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{horizon}: Creating dynamic ensemble...\")\n",
    "    \n",
    "    predict_fn, error_tracker = create_dynamic_ensemble_predictor(\n",
    "        trained_models[horizon]['model'],\n",
    "        trained_models[horizon]['scaler'],\n",
    "        regime_specific_models[horizon],\n",
    "        trained_models[horizon]['features']\n",
    "    )\n",
    "    \n",
    "    dynamic_ensembles[horizon] = {\n",
    "        'predict': predict_fn,\n",
    "        'error_tracker': error_tracker\n",
    "    }\n",
    "    \n",
    "    # Test on holdout\n",
    "    if HAS_HOLDOUT:\n",
    "        features = trained_models[horizon]['features']\n",
    "        X_test = df_holdout[features]\n",
    "        y_test = df_holdout[f'target_{horizon}']\n",
    "        mask = y_test.notna()\n",
    "        X_test = X_test[mask]\n",
    "        y_test = y_test[mask]\n",
    "        \n",
    "        # Get regime labels\n",
    "        regime_test = pd.Series(0, index=X_test.index)\n",
    "        if 'gas_zscore_1h' in df_holdout.columns:\n",
    "            regime_test[df_holdout.loc[X_test.index, 'gas_zscore_1h'] > 1] = 1\n",
    "        if 'is_spike' in df_holdout.columns:\n",
    "            regime_test[df_holdout.loc[X_test.index, 'is_spike'] == 1] = 2\n",
    "        \n",
    "        # Test ensemble predictions using DataFrame input\n",
    "        preds = []\n",
    "        for idx in X_test.index:\n",
    "            row_df = X_test.loc[[idx]]  # Keep as DataFrame with single row\n",
    "            pred = predict_fn(row_df, regime_test.loc[idx])\n",
    "            preds.append(pred[0])\n",
    "        \n",
    "        ensemble_mae = mean_absolute_error(y_test, preds)\n",
    "        global_mae = trained_models[horizon]['metrics']['mae']\n",
    "        \n",
    "        improvement = (global_mae - ensemble_mae) / global_mae * 100\n",
    "        print(f\"  Global MAE: {global_mae:.4f}\")\n",
    "        print(f\"  Ensemble MAE: {ensemble_mae:.4f} ({improvement:+.1f}%)\")\n",
    "        \n",
    "        trained_models[horizon]['dynamic_ensemble'] = {\n",
    "            'mae': float(ensemble_mae),\n",
    "            'improvement_vs_global': float(improvement)\n",
    "        }\n",
    "\n",
    "print(f\"\\n\u2713 Dynamic ensembles created for: {list(dynamic_ensembles.keys())}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ERROR ANALYSIS & DIAGNOSTICS + ONLINE BIAS TRACKING\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ERROR ANALYSIS & DIAGNOSTICS + BIAS TRACKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "error_analysis = {}\n",
    "bias_correction_factors = {}  # NEW: Store bias correction factors for production use\n",
    "\n",
    "def compute_rolling_bias(y_true, y_pred, window_size=240):\n",
    "    \"\"\"\n",
    "    Compute rolling bias (mean error) over recent predictions.\n",
    "    This can be used to correct predictions in production.\n",
    "    \n",
    "    Returns: bias over the last window_size samples\n",
    "    \"\"\"\n",
    "    errors = y_true - y_pred\n",
    "    \n",
    "    # Overall bias\n",
    "    overall_bias = np.mean(errors)\n",
    "    \n",
    "    # Rolling bias (most recent window)\n",
    "    if len(errors) >= window_size:\n",
    "        recent_bias = np.mean(errors[-window_size:])\n",
    "    else:\n",
    "        recent_bias = overall_bias\n",
    "    \n",
    "    # Bias trend (is bias increasing or decreasing?)\n",
    "    if len(errors) >= window_size * 2:\n",
    "        old_bias = np.mean(errors[-window_size*2:-window_size])\n",
    "        bias_trend = recent_bias - old_bias\n",
    "    else:\n",
    "        bias_trend = 0.0\n",
    "    \n",
    "    return {\n",
    "        'overall_bias': float(overall_bias),\n",
    "        'recent_bias': float(recent_bias),\n",
    "        'bias_trend': float(bias_trend),\n",
    "        'window_size': window_size\n",
    "    }\n",
    "\n",
    "def compute_regime_bias(y_true, y_pred, regime_labels):\n",
    "    \"\"\"Compute bias for each regime separately\"\"\"\n",
    "    errors = y_true - y_pred\n",
    "    regime_bias = {}\n",
    "    \n",
    "    for regime_val, regime_name in [(0, 'normal'), (1, 'elevated'), (2, 'spike')]:\n",
    "        mask = regime_labels == regime_val\n",
    "        if mask.sum() > 10:\n",
    "            regime_bias[regime_name] = {\n",
    "                'bias': float(np.mean(errors[mask])),\n",
    "                'std': float(np.std(errors[mask])),\n",
    "                'n_samples': int(mask.sum())\n",
    "            }\n",
    "    \n",
    "    return regime_bias\n",
    "\n",
    "def compute_time_bias(y_true, y_pred, hours):\n",
    "    \"\"\"Compute bias for each time period\"\"\"\n",
    "    errors = y_true - y_pred\n",
    "    time_bias = {}\n",
    "    \n",
    "    time_periods = {\n",
    "        'night': (0, 6),\n",
    "        'morning': (6, 12),\n",
    "        'afternoon': (12, 18),\n",
    "        'evening': (18, 24)\n",
    "    }\n",
    "    \n",
    "    for period_name, (start, end) in time_periods.items():\n",
    "        mask = (hours >= start) & (hours < end)\n",
    "        if mask.sum() > 10:\n",
    "            time_bias[period_name] = {\n",
    "                'bias': float(np.mean(errors[mask])),\n",
    "                'std': float(np.std(errors[mask])),\n",
    "                'n_samples': int(mask.sum())\n",
    "            }\n",
    "    \n",
    "    return time_bias\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{horizon} Error Analysis...\")\n",
    "    \n",
    "    data = trained_models[horizon]\n",
    "    model = data['model']\n",
    "    scaler = data['scaler']\n",
    "    features = data['features']\n",
    "    \n",
    "    if not HAS_HOLDOUT:\n",
    "        print(\"  \u26a0\ufe0f No holdout data for error analysis\")\n",
    "        continue\n",
    "    \n",
    "    # Get predictions on holdout\n",
    "    X_test = df_holdout[features]\n",
    "    y_test = df_holdout[f'target_{horizon}']\n",
    "    \n",
    "    mask = y_test.notna()\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    errors = y_test.values - y_pred\n",
    "    abs_errors = np.abs(errors)\n",
    "    \n",
    "    analysis = {\n",
    "        'mean_error': float(np.mean(errors)),\n",
    "        'std_error': float(np.std(errors)),\n",
    "        'mae': float(np.mean(abs_errors)),\n",
    "        'median_ae': float(np.median(abs_errors)),\n",
    "        'max_error': float(np.max(abs_errors)),\n",
    "        'p95_error': float(np.percentile(abs_errors, 95)),\n",
    "        'p99_error': float(np.percentile(abs_errors, 99)),\n",
    "    }\n",
    "    \n",
    "    print(f\"  Mean error: {analysis['mean_error']:.4f} (bias)\")\n",
    "    print(f\"  Std error: {analysis['std_error']:.4f}\")\n",
    "    print(f\"  MAE: {analysis['mae']:.4f}, Median AE: {analysis['median_ae']:.4f}\")\n",
    "    print(f\"  P95 error: {analysis['p95_error']:.4f}, P99: {analysis['p99_error']:.4f}\")\n",
    "    \n",
    "    # === NEW: ONLINE BIAS TRACKING ===\n",
    "    print(f\"\\n  Bias Tracking:\")\n",
    "    rolling_bias = compute_rolling_bias(y_test.values, y_pred, window_size=min(240, len(y_test)//4))\n",
    "    \n",
    "    print(f\"    Overall bias: {rolling_bias['overall_bias']:.4f}\")\n",
    "    print(f\"    Recent bias (last {rolling_bias['window_size']} samples): {rolling_bias['recent_bias']:.4f}\")\n",
    "    print(f\"    Bias trend: {rolling_bias['bias_trend']:+.4f}\")\n",
    "    \n",
    "    # Bias by regime\n",
    "    regime_test = pd.Series(0, index=X_test.index)\n",
    "    if 'gas_zscore_1h' in df_holdout.columns:\n",
    "        regime_test[df_holdout.loc[X_test.index, 'gas_zscore_1h'] > 1] = 1\n",
    "    if 'is_spike' in df_holdout.columns:\n",
    "        regime_test[df_holdout.loc[X_test.index, 'is_spike'] == 1] = 2\n",
    "    \n",
    "    regime_bias = compute_regime_bias(y_test.values, y_pred, regime_test.values)\n",
    "    print(f\"\\n  Bias by Regime:\")\n",
    "    for regime_name, rb in regime_bias.items():\n",
    "        print(f\"    {regime_name}: bias={rb['bias']:.4f}, std={rb['std']:.4f} ({rb['n_samples']} samples)\")\n",
    "    \n",
    "    # Bias by time of day\n",
    "    hours = X_test.index.hour\n",
    "    time_bias = compute_time_bias(y_test.values, y_pred, hours)\n",
    "    print(f\"\\n  Bias by Time of Day:\")\n",
    "    for period_name, tb in time_bias.items():\n",
    "        print(f\"    {period_name}: bias={tb['bias']:.4f}, std={tb['std']:.4f}\")\n",
    "    \n",
    "    # Store bias correction factors for production use\n",
    "    bias_correction_factors[horizon] = {\n",
    "        'overall': rolling_bias['overall_bias'],\n",
    "        'recent': rolling_bias['recent_bias'],\n",
    "        'trend': rolling_bias['bias_trend'],\n",
    "        'by_regime': regime_bias,\n",
    "        'by_time': time_bias,\n",
    "        'should_correct': abs(rolling_bias['recent_bias']) > 0.05  # Flag if bias is significant\n",
    "    }\n",
    "    \n",
    "    if abs(rolling_bias['recent_bias']) > 0.05:\n",
    "        direction = \"under-predicting\" if rolling_bias['recent_bias'] > 0 else \"over-predicting\"\n",
    "        print(f\"\\n  \u26a0\ufe0f SIGNIFICANT BIAS DETECTED: Model is {direction} by {abs(rolling_bias['recent_bias']):.4f}\")\n",
    "        print(f\"     Recommended correction: add {rolling_bias['recent_bias']:.4f} to predictions\")\n",
    "    \n",
    "    # Bias detection\n",
    "    if abs(analysis['mean_error']) > 0.1 * analysis['std_error']:\n",
    "        bias_direction = \"underestimates\" if analysis['mean_error'] > 0 else \"overestimates\"\n",
    "        print(f\"  \u26a0\ufe0f Systematic bias detected: model {bias_direction} by {abs(analysis['mean_error']):.4f}\")\n",
    "    \n",
    "    # Error by regime (MAE, for comparison)\n",
    "    print(f\"\\n  MAE by Regime:\")\n",
    "    regime_errors = {}\n",
    "    for regime_val, regime_name in [(0, 'normal'), (1, 'elevated'), (2, 'spike')]:\n",
    "        regime_mask = regime_test == regime_val\n",
    "        if regime_mask.sum() > 10:\n",
    "            regime_mae = np.mean(abs_errors[regime_mask.values])\n",
    "            regime_errors[regime_name] = float(regime_mae)\n",
    "            print(f\"    {regime_name}: MAE={regime_mae:.4f} ({regime_mask.sum()} samples)\")\n",
    "    \n",
    "    analysis['regime_errors'] = regime_errors\n",
    "    analysis['regime_bias'] = regime_bias\n",
    "    \n",
    "    # Error by time of day (MAE)\n",
    "    print(f\"\\n  MAE by Time of Day:\")\n",
    "    time_errors = {}\n",
    "    for period, (start, end) in [('night', (0, 6)), ('morning', (6, 12)), ('afternoon', (12, 18)), ('evening', (18, 24))]:\n",
    "        period_mask = (hours >= start) & (hours < end)\n",
    "        if period_mask.sum() > 10:\n",
    "            period_mae = np.mean(abs_errors[period_mask])\n",
    "            time_errors[period] = float(period_mae)\n",
    "            print(f\"    {period} ({start}-{end}h): MAE={period_mae:.4f}\")\n",
    "    \n",
    "    analysis['time_errors'] = time_errors\n",
    "    analysis['time_bias'] = time_bias\n",
    "    analysis['rolling_bias'] = rolling_bias\n",
    "    \n",
    "    # Worst predictions\n",
    "    worst_idx = np.argsort(abs_errors)[-5:]\n",
    "    print(f\"\\n  Worst 5 predictions:\")\n",
    "    for idx in worst_idx:\n",
    "        actual = y_test.iloc[idx]\n",
    "        pred = y_pred[idx]\n",
    "        err = abs_errors[idx]\n",
    "        print(f\"    Actual={actual:.4f}, Pred={pred:.4f}, Error={err:.4f}\")\n",
    "    \n",
    "    # Correlation of errors with features\n",
    "    print(f\"\\n  Error correlation with features:\")\n",
    "    error_correlations = {}\n",
    "    for feat in features[:5]:  # Top 5 features\n",
    "        if feat in X_test.columns:\n",
    "            corr = np.corrcoef(X_test[feat].values, abs_errors)[0, 1]\n",
    "            if not np.isnan(corr):\n",
    "                error_correlations[feat] = float(corr)\n",
    "                if abs(corr) > 0.1:\n",
    "                    print(f\"    {feat}: r={corr:.3f}\")\n",
    "    \n",
    "    analysis['error_correlations'] = error_correlations\n",
    "    \n",
    "    error_analysis[horizon] = analysis\n",
    "\n",
    "# Summary of bias correction\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BIAS CORRECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for horizon, bcf in bias_correction_factors.items():\n",
    "    print(f\"\\n{horizon}:\")\n",
    "    print(f\"  Overall bias: {bcf['overall']:.4f}\")\n",
    "    print(f\"  Recent bias: {bcf['recent']:.4f}\")\n",
    "    if bcf['should_correct']:\n",
    "        print(f\"  \u2713 CORRECTION RECOMMENDED: Add {bcf['recent']:.4f} to predictions\")\n",
    "    else:\n",
    "        print(f\"  \u2717 No correction needed (bias within tolerance)\")\n",
    "\n",
    "print(f\"\\n\u2713 Error analysis complete for: {list(error_analysis.keys())}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# AUTOMATED RETRAINING TRIGGERS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RETRAINING TRIGGER ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "retraining_recommendations = {}\n",
    "\n",
    "# Thresholds for retraining\n",
    "PERFORMANCE_DEGRADATION_THRESHOLD = 0.20  # 20% worse than baseline\n",
    "DISTRIBUTION_SHIFT_THRESHOLD = 1.5  # 1.5 std dev shift\n",
    "ERROR_INCREASE_THRESHOLD = 0.15  # 15% increase in recent errors\n",
    "\n",
    "def check_retraining_needed(horizon, metrics, baselines, error_analysis_data):\n",
    "    \"\"\"Check if model needs retraining based on multiple signals\"\"\"\n",
    "    signals = []\n",
    "    should_retrain = False\n",
    "    \n",
    "    # 1. Check vs holdout baseline\n",
    "    if 'holdout_best' in baselines.get(horizon.replace('24h', '4h'), {}):\n",
    "        holdout_baseline = baselines[horizon.replace('24h', '4h')]['holdout_best']\n",
    "        model_mae = metrics['mae']\n",
    "        \n",
    "        if model_mae > holdout_baseline:\n",
    "            degradation = (model_mae - holdout_baseline) / holdout_baseline\n",
    "            signals.append(f\"Model worse than baseline by {degradation*100:.1f}%\")\n",
    "            if degradation > PERFORMANCE_DEGRADATION_THRESHOLD:\n",
    "                should_retrain = True\n",
    "    \n",
    "    # 2. Check distribution shift\n",
    "    if DISTRIBUTION_SHIFT_DETECTED:\n",
    "        signals.append(f\"Distribution shift detected (magnitude: {SHIFT_MAGNITUDE:.2f})\")\n",
    "        if SHIFT_MAGNITUDE > DISTRIBUTION_SHIFT_THRESHOLD:\n",
    "            should_retrain = True\n",
    "    \n",
    "    # 3. Check error patterns\n",
    "    if horizon in error_analysis:\n",
    "        ea = error_analysis[horizon]\n",
    "        \n",
    "        # Check for systematic bias\n",
    "        if abs(ea['mean_error']) > 0.1:\n",
    "            signals.append(f\"Systematic bias: {ea['mean_error']:.4f}\")\n",
    "            should_retrain = True\n",
    "        \n",
    "        # Check P99 errors (catastrophic failures)\n",
    "        if ea['p99_error'] > 3 * ea['mae']:\n",
    "            signals.append(f\"High P99 error: {ea['p99_error']:.4f} (3x MAE)\")\n",
    "    \n",
    "    # 4. Check regime-specific degradation\n",
    "    if horizon in error_analysis and 'regime_errors' in error_analysis[horizon]:\n",
    "        regime_errors = error_analysis[horizon]['regime_errors']\n",
    "        if 'spike' in regime_errors and 'normal' in regime_errors:\n",
    "            spike_ratio = regime_errors['spike'] / (regime_errors['normal'] + 1e-8)\n",
    "            if spike_ratio > 3:\n",
    "                signals.append(f\"Spike regime error {spike_ratio:.1f}x worse than normal\")\n",
    "    \n",
    "    return should_retrain, signals\n",
    "\n",
    "for horizon in ['1h', '4h', '24h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{horizon} Retraining Analysis:\")\n",
    "    \n",
    "    metrics = trained_models[horizon]['metrics']\n",
    "    should_retrain, signals = check_retraining_needed(\n",
    "        horizon, metrics, BASELINES, \n",
    "        error_analysis if 'error_analysis' in dir() else {}\n",
    "    )\n",
    "    \n",
    "    retraining_recommendations[horizon] = {\n",
    "        'should_retrain': should_retrain,\n",
    "        'signals': signals,\n",
    "        'urgency': 'high' if should_retrain and len(signals) > 2 else 'medium' if should_retrain else 'low'\n",
    "    }\n",
    "    \n",
    "    if signals:\n",
    "        for signal in signals:\n",
    "            print(f\"  \u26a0\ufe0f {signal}\")\n",
    "    else:\n",
    "        print(f\"  \u2713 No retraining signals detected\")\n",
    "    \n",
    "    if should_retrain:\n",
    "        print(f\"  >>> RECOMMENDATION: Retrain {horizon} model\")\n",
    "    else:\n",
    "        print(f\"  >>> Model OK, no retraining needed\")\n",
    "\n",
    "# Overall recommendation\n",
    "any_retrain = any(r['should_retrain'] for r in retraining_recommendations.values())\n",
    "high_urgency = any(r['urgency'] == 'high' for r in retraining_recommendations.values())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"OVERALL RETRAINING RECOMMENDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if high_urgency:\n",
    "    print(\"\ud83d\udd34 HIGH URGENCY: Models show significant degradation\")\n",
    "    print(\"   Recommendation: Retrain immediately with fresh data\")\n",
    "elif any_retrain:\n",
    "    print(\"\ud83d\udfe1 MEDIUM: Some models could benefit from retraining\")\n",
    "    print(\"   Recommendation: Schedule retraining when convenient\")\n",
    "else:\n",
    "    print(\"\ud83d\udfe2 LOW: Models performing within acceptable parameters\")\n",
    "    print(\"   Recommendation: Continue monitoring, retrain in 1-2 weeks\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# BACKTESTING FRAMEWORK\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTESTING FRAMEWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def run_backtest(model, scaler, features, df, target_col, window_days=3):\n",
    "    \"\"\"Run walk-forward backtest on historical data\"\"\"\n",
    "    rph = 120\n",
    "    window_size = window_days * 24 * rph\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Start after initial window\n",
    "    for i in range(window_size, len(df) - rph, rph):  # Step by 1 hour\n",
    "        # Get current features\n",
    "        X_current = df[features].iloc[i:i+1]\n",
    "        \n",
    "        # Get actual future value\n",
    "        if i + rph < len(df):\n",
    "            y_actual = df[target_col].iloc[i + rph] if target_col in df.columns else np.nan\n",
    "        else:\n",
    "            y_actual = np.nan\n",
    "        \n",
    "        if pd.isna(y_actual) or X_current.isna().any().any():\n",
    "            continue\n",
    "        \n",
    "        # Predict\n",
    "        X_scaled = scaler.transform(X_current)\n",
    "        y_pred = model.predict(X_scaled)[0]\n",
    "        \n",
    "        results.append({\n",
    "            'timestamp': df.index[i],\n",
    "            'actual': y_actual,\n",
    "            'predicted': y_pred,\n",
    "            'error': abs(y_actual - y_pred),\n",
    "            'current_gas': df['gas'].iloc[i] if 'gas' in df.columns else np.nan\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "backtest_results = {}\n",
    "\n",
    "for horizon in ['1h', '4h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{horizon} Backtest...\")\n",
    "    \n",
    "    data = trained_models[horizon]\n",
    "    model = data['model']\n",
    "    scaler = data['scaler']\n",
    "    features = data['features']\n",
    "    \n",
    "    # Run backtest on full clean data\n",
    "    target_col = f'target_{horizon}'\n",
    "    \n",
    "    if target_col not in df_clean.columns:\n",
    "        print(f\"  \u26a0\ufe0f Target column not found\")\n",
    "        continue\n",
    "    \n",
    "    bt_results = run_backtest(model, scaler, features, df_clean, target_col, window_days=3)\n",
    "    \n",
    "    if len(bt_results) < 100:\n",
    "        print(f\"  \u26a0\ufe0f Insufficient backtest data ({len(bt_results)} points)\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = bt_results['error'].mean()\n",
    "    rmse = np.sqrt((bt_results['error'] ** 2).mean())\n",
    "    \n",
    "    # Naive baseline (predict current)\n",
    "    naive_errors = abs(bt_results['actual'] - bt_results['current_gas'])\n",
    "    naive_mae = naive_errors.mean()\n",
    "    \n",
    "    improvement = (naive_mae - mae) / naive_mae * 100\n",
    "    \n",
    "    print(f\"  Backtest samples: {len(bt_results)}\")\n",
    "    print(f\"  Model MAE: {mae:.4f}, Naive MAE: {naive_mae:.4f}\")\n",
    "    print(f\"  Improvement vs naive: {improvement:+.1f}%\")\n",
    "    \n",
    "    # Performance by period\n",
    "    bt_results['date'] = bt_results['timestamp'].dt.date\n",
    "    daily_mae = bt_results.groupby('date')['error'].mean()\n",
    "    \n",
    "    print(f\"  Daily MAE range: {daily_mae.min():.4f} - {daily_mae.max():.4f}\")\n",
    "    \n",
    "    # Identify worst days\n",
    "    worst_days = daily_mae.nlargest(3)\n",
    "    print(f\"  Worst days:\")\n",
    "    for date, err in worst_days.items():\n",
    "        print(f\"    {date}: MAE={err:.4f}\")\n",
    "    \n",
    "    backtest_results[horizon] = {\n",
    "        'n_samples': len(bt_results),\n",
    "        'mae': float(mae),\n",
    "        'rmse': float(rmse),\n",
    "        'naive_mae': float(naive_mae),\n",
    "        'improvement_vs_naive': float(improvement),\n",
    "        'daily_mae_min': float(daily_mae.min()),\n",
    "        'daily_mae_max': float(daily_mae.max()),\n",
    "        'worst_days': {str(k): float(v) for k, v in worst_days.items()}\n",
    "    }\n",
    "\n",
    "print(f\"\\n\u2713 Backtest complete for: {list(backtest_results.keys())}\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SHAP EXPLANATIONS FOR MODEL INTERPRETABILITY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP EXPLANATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if SHAP is available\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "    print(\"\u2713 SHAP library available\")\n",
    "except ImportError:\n",
    "    HAS_SHAP = False\n",
    "    print(\"\u26a0\ufe0f SHAP not available. Install with: pip install shap\")\n",
    "    print(\"   Skipping SHAP analysis\")\n",
    "\n",
    "shap_explainers = {}\n",
    "\n",
    "if HAS_SHAP:\n",
    "    for horizon in ['1h', '4h']:\n",
    "        if horizon not in trained_models:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{horizon} SHAP Analysis...\")\n",
    "        \n",
    "        data = trained_models[horizon]\n",
    "        model = data['model']\n",
    "        scaler = data['scaler']\n",
    "        features = data['features']\n",
    "        \n",
    "        # Get sample of training data for background\n",
    "        X_sample = df_train_val[features].sample(min(500, len(df_train_val)), random_state=42)\n",
    "        X_sample_scaled = scaler.transform(X_sample)\n",
    "        \n",
    "        try:\n",
    "            # Create SHAP explainer based on model type\n",
    "            model_name = data['metrics']['name']\n",
    "            \n",
    "            if 'RF' in model_name or 'GBM' in model_name:\n",
    "                # Tree-based model\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                shap_values = explainer.shap_values(X_sample_scaled[:100])\n",
    "            else:\n",
    "                # Linear or other model - use KernelExplainer\n",
    "                explainer = shap.KernelExplainer(model.predict, X_sample_scaled[:50])\n",
    "                shap_values = explainer.shap_values(X_sample_scaled[:50])\n",
    "            \n",
    "            # Calculate mean absolute SHAP values\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[0]\n",
    "            \n",
    "            mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "            \n",
    "            # Create feature importance from SHAP\n",
    "            shap_importance = dict(zip(features, mean_shap))\n",
    "            sorted_importance = sorted(shap_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            print(f\"  Top 5 features by SHAP importance:\")\n",
    "            for feat, imp in sorted_importance[:5]:\n",
    "                print(f\"    {feat}: {imp:.4f}\")\n",
    "            \n",
    "            shap_explainers[horizon] = {\n",
    "                'explainer': explainer,\n",
    "                'background_data': X_sample_scaled[:50],\n",
    "                'feature_names': features,\n",
    "                'shap_importance': dict(sorted_importance)\n",
    "            }\n",
    "            \n",
    "            # Store in trained_models for later use\n",
    "            trained_models[horizon]['shap_explainer'] = shap_explainers[horizon]\n",
    "            \n",
    "            print(f\"  \u2713 SHAP explainer created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  \u26a0\ufe0f SHAP analysis failed: {e}\")\n",
    "\n",
    "def explain_prediction(horizon, X_single, feature_names):\n",
    "    \"\"\"Generate explanation for a single prediction\"\"\"\n",
    "    if not HAS_SHAP or horizon not in shap_explainers:\n",
    "        return None\n",
    "    \n",
    "    explainer_data = shap_explainers[horizon]\n",
    "    explainer = explainer_data['explainer']\n",
    "    \n",
    "    try:\n",
    "        shap_values = explainer.shap_values(X_single.reshape(1, -1))\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[0]\n",
    "        \n",
    "        # Create explanation\n",
    "        contributions = list(zip(feature_names, shap_values[0]))\n",
    "        contributions = sorted(contributions, key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        explanation = []\n",
    "        for feat, contrib in contributions[:5]:\n",
    "            direction = \"\u2191\" if contrib > 0 else \"\u2193\"\n",
    "            explanation.append(f\"{feat}: {direction}{abs(contrib):.3f}\")\n",
    "        \n",
    "        return explanation\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "if HAS_SHAP and shap_explainers:\n",
    "    # Example explanation\n",
    "    print(f\"\\nExample prediction explanation:\")\n",
    "    for horizon in shap_explainers:\n",
    "        sample_X = df_train_val[trained_models[horizon]['features']].iloc[-1:].values\n",
    "        sample_X_scaled = trained_models[horizon]['scaler'].transform(sample_X)\n",
    "        \n",
    "        explanation = explain_prediction(horizon, sample_X_scaled[0], trained_models[horizon]['features'])\n",
    "        if explanation:\n",
    "            pred = trained_models[horizon]['model'].predict(sample_X_scaled)[0]\n",
    "            print(f\"  {horizon} prediction = {pred:.4f}\")\n",
    "            print(f\"  Top contributors: {', '.join(explanation[:3])}\")\n",
    "\n",
    "print(f\"\\n\u2713 SHAP explainers created for: {list(shap_explainers.keys())}\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# DQN AGENT TRAINING (OPTIONAL)\n",
    "# This trains a reinforcement learning agent for transaction timing\n",
    "# Skip if you just need prediction models\n",
    "\n",
    "TRAIN_DQN = False  # Set to True to train DQN agent\n",
    "\n",
    "if not TRAIN_DQN:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DQN TRAINING SKIPPED (set TRAIN_DQN = True to enable)\")\n",
    "    print(\"=\"*60)\n",
    "    DQN_TRAINED = False"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Training Implementation (runs only if TRAIN_DQN = True)\n",
    "\n",
    "if TRAIN_DQN:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING DQN AGENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.optim as optim\n",
    "        from collections import deque\n",
    "        import random\n",
    "        \n",
    "        class DQNNetwork(nn.Module):\n",
    "            def __init__(self, state_dim, action_dim):\n",
    "                super().__init__()\n",
    "                self.net = nn.Sequential(\n",
    "                    nn.Linear(state_dim, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, action_dim)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return self.net(x)\n",
    "        \n",
    "        class DQNAgent:\n",
    "            def __init__(self, state_dim, action_dim):\n",
    "                self.state_dim = state_dim\n",
    "                self.action_dim = action_dim\n",
    "                self.epsilon = 1.0\n",
    "                self.epsilon_min = 0.05\n",
    "                self.epsilon_decay = 0.995\n",
    "                self.gamma = 0.99\n",
    "                self.lr = 0.001\n",
    "                self.memory = deque(maxlen=10000)\n",
    "                self.batch_size = 32\n",
    "                self.training_steps = 0\n",
    "                \n",
    "                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                self.model = DQNNetwork(state_dim, action_dim).to(self.device)\n",
    "                self.target_model = DQNNetwork(state_dim, action_dim).to(self.device)\n",
    "                self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "                self.update_target()\n",
    "            \n",
    "            def update_target(self):\n",
    "                self.target_model.load_state_dict(self.model.state_dict())\n",
    "            \n",
    "            def act(self, state):\n",
    "                if random.random() < self.epsilon:\n",
    "                    return random.randint(0, self.action_dim - 1)\n",
    "                state_t = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    q_values = self.model(state_t)\n",
    "                return q_values.argmax().item()\n",
    "            \n",
    "            def remember(self, state, action, reward, next_state, done):\n",
    "                self.memory.append((state, action, reward, next_state, done))\n",
    "            \n",
    "            def replay(self):\n",
    "                if len(self.memory) < self.batch_size:\n",
    "                    return\n",
    "                \n",
    "                batch = random.sample(self.memory, self.batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                \n",
    "                states = torch.FloatTensor(states).to(self.device)\n",
    "                actions = torch.LongTensor(actions).to(self.device)\n",
    "                rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "                next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "                dones = torch.FloatTensor(dones).to(self.device)\n",
    "                \n",
    "                current_q = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "                next_q = self.target_model(next_states).max(1)[0].detach()\n",
    "                target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "                \n",
    "                loss = nn.MSELoss()(current_q.squeeze(), target_q)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                self.training_steps += 1\n",
    "                if self.training_steps % 100 == 0:\n",
    "                    self.update_target()\n",
    "                \n",
    "                self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "            \n",
    "            def save(self, path):\n",
    "                torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "        # Create simple environment\n",
    "        state_dim = min(30, len(X.columns))  # Limit state size\n",
    "        action_dim = 2  # 0 = wait, 1 = execute\n",
    "        \n",
    "        DQN_AGENT = DQNAgent(state_dim, action_dim)\n",
    "        \n",
    "        # Train for a few episodes\n",
    "        n_episodes = 500\n",
    "        print(f\"Training DQN for {n_episodes} episodes...\")\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            # Simple training loop\n",
    "            for i in range(min(100, len(X) - 1)):\n",
    "                state = X.iloc[i, :state_dim].values\n",
    "                action = DQN_AGENT.act(state)\n",
    "                \n",
    "                # Simple reward: negative gas price change if executing\n",
    "                next_gas = current_gas.iloc[i + 1] if i + 1 < len(current_gas) else current_gas.iloc[i]\n",
    "                reward = -(next_gas - current_gas.iloc[i]) if action == 1 else -0.001  # Small wait penalty\n",
    "                \n",
    "                next_state = X.iloc[i + 1, :state_dim].values if i + 1 < len(X) else state\n",
    "                done = (i >= min(99, len(X) - 2))\n",
    "                \n",
    "                DQN_AGENT.remember(state, action, reward, next_state, done)\n",
    "                DQN_AGENT.replay()\n",
    "            \n",
    "            if (episode + 1) % 100 == 0:\n",
    "                print(f\"  Episode {episode + 1}/{n_episodes}, Epsilon: {DQN_AGENT.epsilon:.3f}\")\n",
    "        \n",
    "        DQN_TRAINED = True\n",
    "        DQN_METRICS = {\n",
    "            'episodes': n_episodes,\n",
    "            'training_steps': DQN_AGENT.training_steps,\n",
    "            'final_epsilon': float(DQN_AGENT.epsilon)\n",
    "        }\n",
    "        print(f\"\\n\u2713 DQN training complete ({DQN_AGENT.training_steps} steps)\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"\u26a0\ufe0f PyTorch not available, skipping DQN training\")\n",
    "        DQN_TRAINED = False\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f DQN training failed: {e}\")\n",
    "        DQN_TRAINED = False\n",
    "else:\n",
    "    DQN_TRAINED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models + NEW ANALYSIS DATA (EXPANDED)\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json as json_lib\n",
    "\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS AND ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === Save prediction models ===\n",
    "for horizon in ['1h', '4h', '24h']:\n",
    "    if horizon not in trained_models:\n",
    "        continue\n",
    "    \n",
    "    data = trained_models[horizon]\n",
    "    model = data['model']\n",
    "    scaler = data['scaler']\n",
    "    metrics = data['metrics']\n",
    "    features = data.get('features', [])\n",
    "    \n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'model_name': metrics['name'],\n",
    "        'metrics': {\n",
    "            'mae': float(metrics['mae']),\n",
    "            'improvement': float(metrics['improvement']),\n",
    "            'vs_holdout_baseline': float(metrics['vs_holdout_baseline']) if metrics.get('vs_holdout_baseline') else None,\n",
    "            'passed_baseline': bool(metrics.get('passed_baseline', False)),\n",
    "        },\n",
    "        'trained_at': datetime.now().isoformat(),\n",
    "        'feature_names': list(features),\n",
    "        'feature_scaler': scaler,\n",
    "    }\n",
    "    \n",
    "    if 'cv_mae' in metrics:\n",
    "        model_data['cv_mae'] = float(metrics['cv_mae'])\n",
    "    \n",
    "    if 'asymmetric_loss' in metrics and metrics['asymmetric_loss'] is not None:\n",
    "        model_data['asymmetric_loss'] = float(metrics['asymmetric_loss'])\n",
    "    \n",
    "    if 'conformal_residuals' in dir() and horizon in conformal_residuals:\n",
    "        model_data['conformal_interval'] = float(conformal_residuals[horizon]['quantile'])\n",
    "    \n",
    "    if 'uncertainty_scalers' in dir() and horizon in uncertainty_scalers:\n",
    "        model_data['uncertainty_scaler'] = uncertainty_scalers[horizon]\n",
    "    \n",
    "    # NEW: Add time-period calibration\n",
    "    if 'time_period_calibration' in dir() and horizon in time_period_calibration:\n",
    "        model_data['time_period_calibration'] = time_period_calibration[horizon]\n",
    "    \n",
    "    # NEW: Add bias correction factors\n",
    "    if 'bias_correction_factors' in dir() and horizon in bias_correction_factors:\n",
    "        model_data['bias_correction'] = bias_correction_factors[horizon]\n",
    "    \n",
    "    if 'shap_explainer' in data:\n",
    "        model_data['has_shap'] = True\n",
    "    \n",
    "    joblib.dump(model_data, f'saved_models/model_{horizon}.pkl')\n",
    "    print(f\"\u2713 model_{horizon}.pkl ({metrics['name']}, {len(features)} features)\")\n",
    "    joblib.dump(scaler, f'saved_models/scaler_{horizon}.pkl')\n",
    "\n",
    "# === Save regime-specific models ===\n",
    "if 'regime_specific_models' in dir() and regime_specific_models:\n",
    "    os.makedirs('saved_models/regime_models', exist_ok=True)\n",
    "    for horizon, regime_dict in regime_specific_models.items():\n",
    "        for regime_val, regime_data in regime_dict.items():\n",
    "            filename = f'saved_models/regime_models/model_{horizon}_{regime_data[\"regime_name\"]}.pkl'\n",
    "            joblib.dump(regime_data, filename)\n",
    "            print(f\"  \u2192 {horizon}_{regime_data['regime_name']} regime\")\n",
    "\n",
    "# === Save spike forecast models (EXPANDED with threshold and percentile) ===\n",
    "if 'spike_forecast_models' in dir() and spike_forecast_models:\n",
    "    for horizon, sf_data in spike_forecast_models.items():\n",
    "        sf_save = {\n",
    "            'model': sf_data.get('model'),\n",
    "            'scaler': sf_data.get('scaler'),\n",
    "            'optimal_threshold': sf_data.get('optimal_threshold', 0.5),\n",
    "            'percentile': sf_data.get('percentile'),\n",
    "            'metrics': {k: v for k, v in sf_data.items() if k not in ['model', 'scaler']}\n",
    "        }\n",
    "        joblib.dump(sf_save, f'saved_models/spike_forecast_{horizon}.pkl')\n",
    "        if sf_data.get('model') is not None:\n",
    "            print(f\"\u2713 spike_forecast_{horizon}.pkl (AUC: {sf_data['auc']:.3f}, threshold: {sf_data.get('optimal_threshold', 0.5):.2f})\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f spike_forecast_{horizon}.pkl (no viable model)\")\n",
    "\n",
    "# === Save other models ===\n",
    "default_features = trained_models.get('4h', trained_models.get('1h', {})).get('features', [])\n",
    "joblib.dump(list(default_features), 'saved_models/feature_names.pkl')\n",
    "\n",
    "if 'regime_clf' in dir() and regime_clf is not None:\n",
    "    joblib.dump({'model': regime_clf, 'scaler': regime_scaler, 'accuracy': regime_accuracy}, \n",
    "                'saved_models/regime_detector.pkl')\n",
    "\n",
    "if 'quantile_models' in dir() and quantile_models:\n",
    "    for horizon, (q_models, q_scaler) in quantile_models.items():\n",
    "        quantile_data = {'models': q_models, 'scaler': q_scaler, 'quantiles': [0.1, 0.5, 0.9]}\n",
    "        if 'conformal_residuals' in dir() and horizon in conformal_residuals:\n",
    "            quantile_data['conformal'] = {'interval_width': float(conformal_residuals[horizon]['quantile'])}\n",
    "        if 'uncertainty_scalers' in dir() and horizon in uncertainty_scalers:\n",
    "            quantile_data['uncertainty_scaler'] = uncertainty_scalers[horizon]\n",
    "        if 'time_period_calibration' in dir() and horizon in time_period_calibration:\n",
    "            quantile_data['time_calibration'] = time_period_calibration[horizon]\n",
    "        joblib.dump(quantile_data, f'saved_models/quantile_{horizon}.pkl')\n",
    "\n",
    "# === Save training metadata with all analysis ===\n",
    "def convert_to_python_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_python_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_python_types(v) for v in obj]\n",
    "    elif isinstance(obj, (np.bool_, np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'item'):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "metadata = {\n",
    "    'training_timestamp': datetime.now().isoformat(),\n",
    "    'total_samples': len(df_clean),\n",
    "    'training_samples': len(df_train_val),\n",
    "    'holdout_samples': len(df_holdout) if df_holdout is not None else 0,\n",
    "    'date_range': f\"{df_clean.index.min()} to {df_clean.index.max()}\",\n",
    "    'selection_method': 'holdout-based',\n",
    "    'configuration': {\n",
    "        'target_transform': TARGET_TRANSFORM_USED if 'TARGET_TRANSFORM_USED' in dir() else 'none',\n",
    "        'use_rolling_window': USE_ROLLING_WINDOW if 'USE_ROLLING_WINDOW' in dir() else False,\n",
    "        'rolling_window_days': ROLLING_WINDOW_DAYS if 'ROLLING_WINDOW_DAYS' in dir() else None,\n",
    "        'auto_adapt_on_shift': AUTO_ADAPT_ON_SHIFT if 'AUTO_ADAPT_ON_SHIFT' in dir() else False,\n",
    "        'distribution_shift_detected': DISTRIBUTION_SHIFT_DETECTED if 'DISTRIBUTION_SHIFT_DETECTED' in dir() else False,\n",
    "        'shift_magnitude': SHIFT_MAGNITUDE if 'SHIFT_MAGNITUDE' in dir() else 0,\n",
    "        'feature_pruning_enabled': ENABLE_FEATURE_PRUNING if 'ENABLE_FEATURE_PRUNING' in dir() else False,\n",
    "        'asymmetric_loss_enabled': USE_ASYMMETRIC_LOSS if 'USE_ASYMMETRIC_LOSS' in dir() else False,\n",
    "        'asymmetric_alpha': ASYMMETRIC_ALPHA if 'ASYMMETRIC_ALPHA' in dir() else 0.5\n",
    "    },\n",
    "    'features': {'count': len(default_features), 'list': list(default_features)},\n",
    "    'baselines': BASELINES,\n",
    "    'models': {},\n",
    "    'regime_models': {},\n",
    "    'direction_models': {},\n",
    "    'spike_forecast_models': {},\n",
    "    'error_analysis': {},\n",
    "    'bias_correction': {},\n",
    "    'time_calibration': {},\n",
    "    'regime_calibration': {},\n",
    "    'feature_pruning': {},\n",
    "    'backtest_results': {},\n",
    "    'retraining_recommendations': {}\n",
    "}\n",
    "\n",
    "for horizon, data in trained_models.items():\n",
    "    m = data['metrics']\n",
    "    metadata['models'][horizon] = {\n",
    "        'name': m['name'],\n",
    "        'mae': float(m['mae']),\n",
    "        'improvement_pct': float(m['improvement'] * 100),\n",
    "        'vs_holdout_baseline_pct': float(m['vs_holdout_baseline'] * 100) if m.get('vs_holdout_baseline') else None,\n",
    "        'passed_baseline': bool(m.get('passed_baseline', False)),\n",
    "        'is_fallback': data.get('is_fallback', False),\n",
    "        'has_shap': 'shap_explainer' in data,\n",
    "        'has_dynamic_ensemble': 'dynamic_ensemble' in data,\n",
    "        'n_features': len(data.get('features', []))\n",
    "    }\n",
    "    if 'cv_mae' in m:\n",
    "        metadata['models'][horizon]['cv_mae'] = float(m['cv_mae'])\n",
    "    if 'asymmetric_loss' in m and m['asymmetric_loss'] is not None:\n",
    "        metadata['models'][horizon]['asymmetric_loss'] = float(m['asymmetric_loss'])\n",
    "    if 'calibration' in data:\n",
    "        metadata['models'][horizon]['calibration'] = data['calibration']\n",
    "\n",
    "if 'regime_specific_models' in dir() and regime_specific_models:\n",
    "    for horizon, regime_dict in regime_specific_models.items():\n",
    "        metadata['regime_models'][horizon] = {}\n",
    "        for regime_val, regime_data in regime_dict.items():\n",
    "            metadata['regime_models'][horizon][regime_data['regime_name']] = {\n",
    "                'mae': float(regime_data['metrics']['mae']),\n",
    "                'n_samples': int(regime_data['n_samples']),\n",
    "                'n_features': len(regime_data.get('features', []))\n",
    "            }\n",
    "\n",
    "if 'direction_models' in dir() and direction_models:\n",
    "    for horizon, data in direction_models.items():\n",
    "        metadata['direction_models'][horizon] = {\n",
    "            'accuracy': float(data['accuracy']),\n",
    "            'f1_score': float(data['f1_score']),\n",
    "            'baseline_accuracy': float(data.get('baseline_accuracy', 0)),\n",
    "            'improvement_vs_baseline': float(data.get('improvement_vs_baseline', 0)),\n",
    "            'model_name': data.get('model_name', 'GBM'),\n",
    "            'is_binary': data.get('is_binary', False)\n",
    "        }\n",
    "\n",
    "# NEW: Spike forecast with threshold and percentile\n",
    "if 'spike_forecast_models' in dir() and spike_forecast_models:\n",
    "    for horizon, sf_data in spike_forecast_models.items():\n",
    "        metadata['spike_forecast_models'][horizon] = {\n",
    "            'precision': float(sf_data.get('precision', 0)),\n",
    "            'recall': float(sf_data.get('recall', 0)),\n",
    "            'f1_score': float(sf_data.get('f1_score', 0)),\n",
    "            'auc': float(sf_data.get('auc', 0.5)),\n",
    "            'optimal_threshold': float(sf_data.get('optimal_threshold', 0.5)),\n",
    "            'percentile': sf_data.get('percentile'),\n",
    "            'spike_rate_train': float(sf_data.get('spike_rate_train', 0)),\n",
    "            'spike_rate_test': float(sf_data.get('spike_rate_test', 0)),\n",
    "            'has_model': sf_data.get('model') is not None\n",
    "        }\n",
    "\n",
    "if 'error_analysis' in dir() and error_analysis:\n",
    "    metadata['error_analysis'] = error_analysis\n",
    "\n",
    "# NEW: Bias correction factors\n",
    "if 'bias_correction_factors' in dir() and bias_correction_factors:\n",
    "    metadata['bias_correction'] = bias_correction_factors\n",
    "\n",
    "# NEW: Time-period calibration\n",
    "if 'time_period_calibration' in dir() and time_period_calibration:\n",
    "    metadata['time_calibration'] = time_period_calibration\n",
    "\n",
    "# NEW: Regime calibration\n",
    "if 'regime_calibration' in dir() and regime_calibration:\n",
    "    metadata['regime_calibration'] = regime_calibration\n",
    "\n",
    "# NEW: Feature pruning log\n",
    "if 'pruned_features_log' in dir() and pruned_features_log:\n",
    "    metadata['feature_pruning'] = pruned_features_log\n",
    "\n",
    "if 'backtest_results' in dir() and backtest_results:\n",
    "    metadata['backtest_results'] = backtest_results\n",
    "\n",
    "if 'retraining_recommendations' in dir() and retraining_recommendations:\n",
    "    metadata['retraining_recommendations'] = retraining_recommendations\n",
    "\n",
    "metadata = convert_to_python_types(metadata)\n",
    "\n",
    "with open('saved_models/training_metadata.json', 'w') as f:\n",
    "    json_lib.dump(metadata, f, indent=2)\n",
    "print(f\"\\n\u2713 training_metadata.json\")\n",
    "\n",
    "# === Save feature importance ===\n",
    "if FEATURE_IMPORTANCE:\n",
    "    sorted_importance = dict(sorted(FEATURE_IMPORTANCE.items(), key=lambda x: x[1], reverse=True))\n",
    "    with open('saved_models/feature_importance.json', 'w') as f:\n",
    "        json_lib.dump(convert_to_python_types(sorted_importance), f, indent=2)\n",
    "    print(f\"\u2713 feature_importance.json\")\n",
    "\n",
    "# === Update training history ===\n",
    "history_file = 'saved_models/training_history.json'\n",
    "if os.path.exists(history_file):\n",
    "    with open(history_file) as f:\n",
    "        history = json_lib.load(f)\n",
    "else:\n",
    "    history = []\n",
    "\n",
    "current_run = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'models': {h: {'name': trained_models[h]['metrics']['name'], \n",
    "                   'mae': float(trained_models[h]['metrics']['mae']),\n",
    "                   'vs_holdout_baseline': float(trained_models[h]['metrics'].get('vs_holdout_baseline', 0)),\n",
    "                   'n_features': len(trained_models[h].get('features', []))}\n",
    "               for h in trained_models},\n",
    "    'config': metadata['configuration'],\n",
    "    'has_spike_forecast': bool(spike_forecast_models) if 'spike_forecast_models' in dir() else False,\n",
    "    'has_shap': any('shap_explainer' in trained_models.get(h, {}) for h in ['1h', '4h']),\n",
    "    'has_bias_correction': bool(bias_correction_factors) if 'bias_correction_factors' in dir() else False,\n",
    "    'has_time_calibration': bool(time_period_calibration) if 'time_period_calibration' in dir() else False,\n",
    "    'retraining_needed': any(r['should_retrain'] for r in retraining_recommendations.values()) if 'retraining_recommendations' in dir() else False\n",
    "}\n",
    "\n",
    "history.append(current_run)\n",
    "history = history[-10:]\n",
    "\n",
    "with open(history_file, 'w') as f:\n",
    "    json_lib.dump(history, f, indent=2)\n",
    "\n",
    "# === Model Comparison Report ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL COMPARISON REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(history) >= 2:\n",
    "    prev_run = history[-2]\n",
    "    print(f\"\\nComparing with previous run ({prev_run['timestamp'][:16]}):\")\n",
    "    print(f\"{'Horizon':<8} {'Prev MAE':<12} {'Curr MAE':<12} {'Change':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for horizon in ['1h', '4h', '24h']:\n",
    "        if horizon in current_run['models'] and horizon in prev_run['models']:\n",
    "            prev_mae = prev_run['models'][horizon]['mae']\n",
    "            curr_mae = current_run['models'][horizon]['mae']\n",
    "            change = (curr_mae - prev_mae) / prev_mae * 100\n",
    "            print(f\"{horizon:<8} {prev_mae:<12.4f} {curr_mae:<12.4f} {change:+.1f}%\")\n",
    "\n",
    "# Bias correction summary\n",
    "if 'bias_correction_factors' in dir() and bias_correction_factors:\n",
    "    print(f\"\\nBias Correction Status:\")\n",
    "    for horizon, bcf in bias_correction_factors.items():\n",
    "        status = \"APPLY\" if bcf.get('should_correct', False) else \"OK\"\n",
    "        print(f\"  {horizon}: {status} (bias: {bcf.get('recent', 0):.4f})\")\n",
    "\n",
    "# Retraining recommendation summary\n",
    "if 'retraining_recommendations' in dir() and retraining_recommendations:\n",
    "    print(f\"\\nRetraining Recommendations:\")\n",
    "    for horizon, rec in retraining_recommendations.items():\n",
    "        status = \"\ud83d\udd34 RETRAIN\" if rec['should_retrain'] else \"\ud83d\udfe2 OK\"\n",
    "        urgency = f\" ({rec.get('urgency', 'unknown')})\" if rec['should_retrain'] else \"\"\n",
    "        print(f\"  {horizon}: {status}{urgency}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL MODELS SAVED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final report\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"TRAINING COMPLETE - FINAL REPORT\")\nprint(\"=\"*70)\n\ntotal_days = len(df_clean) / (120 * 24)\n\nprint(f\"\\n",
    "DATA SUMMARY\")\nprint(f\"   Total samples: {len(df_clean):,} ({total_days:.1f} days)\")\nprint(f\"   Training: {len(df_train_val):,} | Holdout: {len(df_holdout) if df_holdout is not None else 0:,}\")\nprint(f\"   Date range: {df_clean.index.min()} to {df_clean.index.max()}\")\nprint(f\"   ETH price: {'Binance 1-min \u2713' if HAS_ETH_PRICE else 'Not available'}\")\nprint(f\"   Features: 1h={len(numeric_features_1h)}, 4h={len(numeric_features_4h)}, 24h={len(numeric_features_24h)}\")\n\nprint(f\"\\n",
    "\" + \"-\"*70)\nprint(f\"{'MODEL PERFORMANCE':^70}\")\nprint(\"-\"*70)\nprint(f\"{'Horizon':<8} {'Model':<15} {'CV MAE':>10} {'Holdout':>10} {'vs Base':>10} {'Status':>12}\")\nprint(\"-\"*70)\n\nfor horizon in ['1h', '4h', '24h']:\n    if horizon in trained_models:\n        data = trained_models[horizon]\n        m = data['metrics']\n        name = m['name'][:14]\n        if data.get('is_fallback'):\n            name = name[:10] + '(fb)'\n        \n        cv_mae = f\"{m['mae']:.4f}\"\n        holdout_mae = f\"{data.get('holdout_mae', 0):.4f}\" if 'holdout_mae' in data else \"N/A\"\n        improvement = f\"{m['improvement']*100:+.1f}%\"\n        status = \"\u2713 PASS\" if m['passed_baseline'] else \"\u2717 FAIL\"\n        \n        print(f\"{horizon:<8} {name:<15} {cv_mae:>10} {holdout_mae:>10} {improvement:>10} {status:>12}\")\n\nprint(\"-\"*70)\n\n# Calibration report\nif any('calibration' in trained_models.get(h, {}) for h in ['1h', '4h']):\n    print(f\"\\n",
    "\" + \"-\"*70)\n    print(f\"{'PREDICTION INTERVAL CALIBRATION':^70}\")\n    print(\"-\"*70)\n    print(f\"{'Horizon':<10} {'Quantile 80%':>15} {'Conformal 80%':>15} {'Width (gwei)':>15}\")\n    print(\"-\"*70)\n    \n    for horizon in ['1h', '4h']:\n        if horizon in trained_models and 'calibration' in trained_models[horizon]:\n            cal = trained_models[horizon]['calibration']\n            q_cov = f\"{cal['quantile_coverage']:.1%}\"\n            c_cov = f\"{cal['conformal_coverage']:.1%}\"\n            width = f\"\u00b1{cal['conformal_width']:.4f}\"\n            print(f\"{horizon:<10} {q_cov:>15} {c_cov:>15} {width:>15}\")\n    \n    print(\"-\"*70)\n\n# Direction models\nif 'direction_models' in dir() and direction_models:\n    print(f\"\\n",
    "\" + \"-\"*70)\n    print(f\"{'DIRECTION PREDICTION':^70}\")\n    print(\"-\"*70)\n    for horizon, data in direction_models.items():\n        print(f\"  {horizon}: Accuracy={data['accuracy']:.1%}, F1={data['f1_score']:.3f}\")\n\n# 24h model status\nprint(f\"\\n",
    "\" + \"-\"*70)\nprint(f\"{'24H MODEL STATUS':^70}\")\nprint(\"-\"*70)\nif '24h' in trained_models:\n    if trained_models['24h'].get('is_fallback'):\n        print(f\"  \u26a0\ufe0f Using 4h model as fallback (need 30+ days of data)\")\n        print(f\"     Current data: {total_days:.1f} days\")\n        print(f\"     Recommendation: Collect {30 - total_days:.0f} more days before training true 24h model\")\n    else:\n        print(f\"  \u2713 True 24h model trained with {total_days:.1f} days of data\")\n\n# Final recommendation\nprint(f\"\\n",
    "\" + \"=\"*70)\nprint(\"RECOMMENDATION\")\nprint(\"=\"*70)\n\nall_passed = all(trained_models.get(h, {}).get('metrics', {}).get('passed_baseline', False) \n                 for h in trained_models if h in trained_models)\n\nif all_passed:\n    print(\"\u2713 All models beat baseline - READY FOR DEPLOYMENT\")\n    print(\"\\n",
    "Next steps:\")\n    print(\"  1. Download saved_models/ folder\")\n    print(\"  2. Copy to backend/models/saved_models/\")\n    print(\"  3. Restart backend\")\nelse:\n    failed = [h for h in trained_models \n              if not trained_models[h]['metrics']['passed_baseline']]\n    print(f\"\u26a0\ufe0f Some models did not pass baseline: {failed}\")\n    print(\"\\n",
    "Recommendations:\")\n    print(\"  - Collect more data\")\n    print(\"  - Review feature engineering\")\n    print(\"  - Only deploy passing models\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualizations - IMPROVED with holdout baseline comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Train vs Holdout Distribution Comparison\n",
    "ax1 = axes[0, 0]\n",
    "train_gas = current_gas.values\n",
    "if HAS_HOLDOUT:\n",
    "    holdout_gas = df_holdout['gas'].values\n",
    "    ax1.hist(train_gas, bins=50, alpha=0.6, color='blue', label=f'Train (mean={train_gas.mean():.2f})', density=True)\n",
    "    ax1.hist(holdout_gas, bins=50, alpha=0.6, color='red', label=f'Holdout (mean={holdout_gas.mean():.2f})', density=True)\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Train vs Holdout Distribution')\n",
    "else:\n",
    "    ax1.hist(train_gas, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    ax1.axvline(train_gas.mean(), color='red', linestyle='--', label=f'Mean: {train_gas.mean():.2f}')\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Gas Price Distribution')\n",
    "ax1.set_xlabel('Gas Price (gwei)')\n",
    "ax1.set_ylabel('Density' if HAS_HOLDOUT else 'Frequency')\n",
    "\n",
    "# 2. Model vs HOLDOUT Baseline (not train baseline!)\n",
    "ax2 = axes[0, 1]\n",
    "horizons = list(trained_models.keys())\n",
    "maes = [trained_models[h]['metrics']['mae'] for h in horizons]\n",
    "\n",
    "# Use holdout baselines if available, otherwise train baselines\n",
    "baselines = []\n",
    "for h in horizons:\n",
    "    h_key = h.replace('24h', '4h')  # 24h uses 4h baseline\n",
    "    if 'holdout_best' in BASELINES.get(h_key, {}):\n",
    "        baselines.append(BASELINES[h_key]['holdout_best'])\n",
    "    else:\n",
    "        baselines.append(BASELINES.get(h_key, BASELINES['4h'])['best'])\n",
    "\n",
    "x = np.arange(len(horizons))\n",
    "width = 0.35\n",
    "bars1 = ax2.bar(x - width/2, maes, width, label='Model MAE', color='steelblue')\n",
    "bars2 = ax2.bar(x + width/2, baselines, width, label='Holdout Baseline', color='coral')\n",
    "ax2.set_xlabel('Horizon')\n",
    "ax2.set_ylabel('MAE (gwei)')\n",
    "ax2.set_title('Model vs Holdout Baseline Performance')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(horizons)\n",
    "ax2.legend()\n",
    "\n",
    "# Add improvement percentages (vs holdout baseline)\n",
    "for i, (h, m, b) in enumerate(zip(horizons, maes, baselines)):\n",
    "    imp = (b - m) / b * 100\n",
    "    color = 'green' if imp > 0 else 'red'\n",
    "    y_pos = max(m, b) + 0.02 * max(max(maes), max(baselines))\n",
    "    ax2.annotate(f'{imp:+.1f}%', xy=(i, y_pos), ha='center', fontsize=10, fontweight='bold', color=color)\n",
    "\n",
    "# 3. Gas price time series with regime markers\n",
    "ax3 = axes[1, 0]\n",
    "sample_size = min(2000, len(df_clean))\n",
    "sample_df = df_clean.iloc[-sample_size:]\n",
    "sample_gas = sample_df['gas']\n",
    "\n",
    "ax3.plot(sample_gas.index, sample_gas.values, linewidth=0.5, alpha=0.8, color='blue')\n",
    "\n",
    "# Mark holdout period\n",
    "if HAS_HOLDOUT:\n",
    "    holdout_start = df_holdout.index[0]\n",
    "    ax3.axvline(holdout_start, color='red', linestyle='--', linewidth=2, label='Holdout start')\n",
    "    ax3.legend()\n",
    "\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Gas Price (gwei)')\n",
    "ax3.set_title(f'Recent Gas Prices (last {sample_size} samples)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Feature importance (top 10)\n",
    "ax4 = axes[1, 1]\n",
    "if FEATURE_IMPORTANCE and any(v != list(FEATURE_IMPORTANCE.values())[0] for v in FEATURE_IMPORTANCE.values()):\n",
    "    # Non-uniform importance\n",
    "    sorted_imp = sorted(FEATURE_IMPORTANCE.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    features_plot = [f[0][:20] for f in sorted_imp]\n",
    "    importances = [f[1] for f in sorted_imp]\n",
    "    \n",
    "    y_pos = np.arange(len(features_plot))\n",
    "    ax4.barh(y_pos, importances, color='teal')\n",
    "    ax4.set_yticks(y_pos)\n",
    "    ax4.set_yticklabels(features_plot)\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.set_xlabel('Importance')\n",
    "    ax4.set_title('Top 10 Feature Importance (Permutation)')\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'Feature importance uniform\\n(Huber model)', ha='center', va='center', fontsize=12)\n",
    "    ax4.set_title('Feature Importance')\n",
    "    ax4.set_xlim(0, 1)\n",
    "    ax4.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('saved_models/training_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved training_results.png\")\n",
    "\n",
    "# === ADDITIONAL: Distribution shift visualization ===\n",
    "if HAS_HOLDOUT and DISTRIBUTION_SHIFT_DETECTED:\n",
    "    fig2, axes2 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    for i, horizon in enumerate(['1h', '4h']):\n",
    "        ax = axes2[i]\n",
    "        train_target = df_train_val[f'target_{horizon}'].dropna()\n",
    "        holdout_target = df_holdout[f'target_{horizon}'].dropna()\n",
    "        \n",
    "        ax.hist(train_target, bins=50, alpha=0.6, color='blue', label='Train', density=True)\n",
    "        ax.hist(holdout_target, bins=50, alpha=0.6, color='red', label='Holdout', density=True)\n",
    "        ax.set_xlabel(f'{horizon} Target (gwei)')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(f'{horizon} Target Distribution')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('saved_models/distribution_shift.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\u2713 Saved distribution_shift.png\")\n",
    ""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for download\n",
    "import shutil\n",
    "\n",
    "shutil.make_archive('gweizy_models', 'zip', 'saved_models')\n",
    "print(\"\\n\u2705 Created gweizy_models.zip\")\n",
    "print(\"\\nDownload this file and extract to: backend/models/saved_models/\")\n",
    "\n",
    "# Auto-download\n",
    "files.download('gweizy_models.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}