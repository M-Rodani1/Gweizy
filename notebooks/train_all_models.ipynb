{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gweizy Model Training Notebook\n",
    "\n",
    "Train all gas prediction models for Gweizy.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload your `gas_data.db` file (from `backend/gas_data.db`)\n",
    "2. Run all cells\n",
    "3. Download the trained models zip file\n",
    "4. Extract to `backend/models/saved_models/` and push to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q scikit-learn pandas numpy joblib lightgbm xgboost matplotlib seaborn optuna"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your gas_data.db file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your gas_data.db file from backend/gas_data.db\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'gas_data.db' in uploaded:\n",
    "    print(f\"\\n\u2705 Uploaded gas_data.db ({len(uploaded['gas_data.db']) / 1024 / 1024:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\u274c Please upload gas_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data from database\n",
    "conn = sqlite3.connect('gas_data.db')\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT timestamp, current_gas as gas, base_fee, priority_fee, \n",
    "           block_number, gas_used, gas_limit, utilization\n",
    "    FROM gas_prices ORDER BY timestamp ASC\n",
    "\"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('timestamp').sort_index()\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "\n",
    "# === IMPROVED: Resample to 30-second intervals (was 1-min, losing too much data) ===\n",
    "print(\"\\nResampling to 30-second intervals (preserves more data)...\")\n",
    "df = df.resample('30s').mean().dropna(subset=['gas'])\n",
    "print(f\"After resample: {len(df):,} records\")\n",
    "\n",
    "# Find segments (gap > 30 min = new segment)\n",
    "df['time_diff'] = df.index.to_series().diff()\n",
    "df['segment'] = (df['time_diff'] > pd.Timedelta(minutes=30)).cumsum()\n",
    "\n",
    "segment_sizes = df.groupby('segment').size()\n",
    "print(f\"\\nSegments found: {len(segment_sizes)}\")\n",
    "print(f\"Segment sizes: {segment_sizes.sort_values(ascending=False).head(10).tolist()}\")\n",
    "\n",
    "# === IMPROVED: Lower threshold from 120 to 30 minutes (keeps more segments) ===\n",
    "MIN_SEGMENT_SIZE = 60  # 30 minutes at 30-sec intervals = 60 records\n",
    "good_segments = segment_sizes[segment_sizes >= MIN_SEGMENT_SIZE].index.tolist()\n",
    "df = df[df['segment'].isin(good_segments)]\n",
    "print(f\"\\nKeeping {len(good_segments)} segments with >= 30 minutes of data\")\n",
    "print(f\"Total usable records: {len(df):,}\")\n",
    "\n",
    "# === DATA SUFFICIENCY CHECK ===\n",
    "MIN_REQUIRED_SAMPLES = 10000\n",
    "if len(df) < MIN_REQUIRED_SAMPLES:\n",
    "    print(f\"\\n\u26a0\ufe0f  WARNING: Only {len(df):,} samples. Recommend at least {MIN_REQUIRED_SAMPLES:,}\")\n",
    "    print(\"   Models may underperform. Consider collecting more data.\")\n",
    "else:\n",
    "    print(f\"\\n\u2713 Data sufficiency check passed: {len(df):,} samples\")\n",
    "\n",
    "RECORDS_PER_HOUR = 120  # 30-sec intervals = 120 records per hour"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Fetch ETH Price Data - IMPROVED with Binance (1-minute data)\nimport requests\n\nprint(\"=\"*60)\nprint(\"FETCHING EXTERNAL DATA\")\nprint(\"=\"*60)\n\ndef fetch_eth_price_binance(start_date, end_date):\n    \"\"\"Fetch ETH price from Binance API (1-minute candles, much better than CoinGecko hourly)\"\"\"\n    try:\n        start_ts = int(start_date.timestamp() * 1000)\n        end_ts = int(end_date.timestamp() * 1000)\n        \n        all_prices = []\n        current_ts = start_ts\n        \n        print(f\"Fetching ETH prices from Binance (1-min candles)...\")\n        \n        while current_ts < end_ts:\n            url = \"https://api.binance.com/api/v3/klines\"\n            params = {\n                'symbol': 'ETHUSDT',\n                'interval': '1m',\n                'startTime': current_ts,\n                'endTime': min(current_ts + 1000 * 60 * 1000, end_ts),  # Max 1000 candles\n                'limit': 1000\n            }\n            \n            response = requests.get(url, params=params, timeout=30)\n            \n            if response.status_code == 200:\n                data = response.json()\n                if not data:\n                    break\n                    \n                for candle in data:\n                    all_prices.append({\n                        'timestamp': pd.to_datetime(candle[0], unit='ms'),\n                        'eth_price': float(candle[4]),  # Close price\n                        'eth_volume': float(candle[5]),  # Volume\n                        'eth_high': float(candle[2]),\n                        'eth_low': float(candle[3])\n                    })\n                \n                current_ts = data[-1][0] + 60000  # Next minute\n                \n                if len(all_prices) % 5000 == 0:\n                    print(f\"  Fetched {len(all_prices):,} candles...\")\n            else:\n                print(f\"  Binance API error: {response.status_code}\")\n                break\n        \n        if all_prices:\n            eth_df = pd.DataFrame(all_prices)\n            eth_df = eth_df.set_index('timestamp')\n            print(f\"  Total: {len(eth_df):,} 1-minute ETH candles\")\n            return eth_df\n        return None\n        \n    except Exception as e:\n        print(f\"  Failed to fetch from Binance: {e}\")\n        return None\n\ndef fetch_eth_price_coingecko(start_date, end_date):\n    \"\"\"Fallback: CoinGecko API (hourly data)\"\"\"\n    try:\n        start_ts = int(start_date.timestamp())\n        end_ts = int(end_date.timestamp())\n        \n        url = \"https://api.coingecko.com/api/v3/coins/ethereum/market_chart/range\"\n        params = {'vs_currency': 'usd', 'from': start_ts, 'to': end_ts}\n        \n        print(f\"Fallback: Fetching from CoinGecko (hourly)...\")\n        response = requests.get(url, params=params, timeout=30)\n        \n        if response.status_code == 200:\n            data = response.json()\n            prices = data.get('prices', [])\n            \n            eth_df = pd.DataFrame(prices, columns=['timestamp', 'eth_price'])\n            eth_df['timestamp'] = pd.to_datetime(eth_df['timestamp'], unit='ms')\n            eth_df = eth_df.set_index('timestamp')\n            eth_df['eth_volume'] = np.nan\n            eth_df['eth_high'] = eth_df['eth_price']\n            eth_df['eth_low'] = eth_df['eth_price']\n            \n            print(f\"  Fetched {len(eth_df)} hourly ETH prices\")\n            return eth_df\n        return None\n    except Exception as e:\n        print(f\"  CoinGecko failed: {e}\")\n        return None\n\n# Try Binance first, fallback to CoinGecko\neth_data = fetch_eth_price_binance(df.index.min(), df.index.max())\nif eth_data is None or len(eth_data) < 100:\n    eth_data = fetch_eth_price_coingecko(df.index.min(), df.index.max())\n\nhas_eth_data = False\nif eth_data is not None and len(eth_data) > 0:\n    # Resample to 30-second intervals\n    eth_data = eth_data.resample('30s').ffill()\n    \n    # Merge with gas data\n    df = df.join(eth_data, how='left')\n    df['eth_price'] = df['eth_price'].ffill().bfill()\n    \n    # Fill other ETH columns\n    for col in ['eth_volume', 'eth_high', 'eth_low']:\n        if col in df.columns:\n            df[col] = df[col].ffill().bfill()\n    \n    eth_coverage = df['eth_price'].notna().mean()\n    print(f\"  ETH price coverage: {eth_coverage:.1%}\")\n    \n    if eth_coverage > 0.5:\n        has_eth_data = True\n        print(\"  \u2713 ETH price data integrated (1-min resolution)\")\nelse:\n    print(\"  \u26a0\ufe0f No ETH price data available\")\n    df['eth_price'] = np.nan\n    df['eth_volume'] = np.nan\n    df['eth_high'] = np.nan\n    df['eth_low'] = np.nan\n\nHAS_ETH_PRICE = has_eth_data"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - IMPROVED v2\n# Additions: Fourier seasonality, GARCH volatility, better ETH features, horizon-specific\n# Fixes: Removed duplicate lag features\n\nprint(\"Engineering IMPROVED feature set...\")\n\ndef engineer_features_for_segment(seg_df, has_eth=False, horizon='all'):\n    \"\"\"Engineer features with improvements for each horizon\"\"\"\n    df = seg_df.copy()\n    rph = 120  # records per hour (30-sec intervals)\n    \n    # === Log transform gas ===\n    df['gas_log'] = np.log1p(df['gas'])\n    \n    # === FOURIER SEASONALITY FEATURES (NEW) ===\n    # Capture daily and weekly patterns\n    hour_of_day = df.index.hour + df.index.minute / 60\n    day_of_week = df.index.dayofweek\n    \n    # Daily seasonality (24-hour cycle)\n    for k in [1, 2, 3]:  # Multiple harmonics\n        df[f'hour_sin_{k}'] = np.sin(2 * np.pi * k * hour_of_day / 24)\n        df[f'hour_cos_{k}'] = np.cos(2 * np.pi * k * hour_of_day / 24)\n    \n    # Weekly seasonality (7-day cycle)\n    df['dow_sin'] = np.sin(2 * np.pi * day_of_week / 7)\n    df['dow_cos'] = np.cos(2 * np.pi * day_of_week / 7)\n    \n    # Time features\n    df['hour'] = df.index.hour\n    df['is_peak_hours'] = ((df['hour'] >= 14) & (df['hour'] <= 22)).astype(int)\n    df['is_weekend'] = (day_of_week >= 5).astype(int)\n    \n    # === IMPROVED ETH FEATURES (with volume and range) ===\n    if has_eth and 'eth_price' in df.columns and df['eth_price'].notna().any():\n        df['eth_log'] = np.log1p(df['eth_price'])\n        \n        # Price momentum\n        for mins in [15, 30, 60]:\n            periods = mins * 2  # 30-sec intervals\n            shift_val = df['eth_price'].shift(periods)\n            df[f'eth_pct_{mins}min'] = np.where(shift_val > 0, \n                (df['eth_price'] - shift_val) / shift_val, 0)\n        \n        # Volatility\n        eth_mean = df['eth_price'].rolling(4*rph).mean()\n        eth_std = df['eth_price'].rolling(4*rph).std()\n        df['eth_zscore'] = np.where(eth_std > 0.01, (df['eth_price'] - eth_mean) / eth_std, 0)\n        \n        # ETH range (high-low) if available\n        if 'eth_high' in df.columns and 'eth_low' in df.columns:\n            df['eth_range'] = (df['eth_high'] - df['eth_low']) / (df['eth_price'] + 1e-8)\n            df['eth_range_1h'] = df['eth_range'].rolling(rph).mean()\n        \n        # Volume features if available\n        if 'eth_volume' in df.columns and df['eth_volume'].notna().any():\n            df['eth_vol_zscore'] = (df['eth_volume'] - df['eth_volume'].rolling(rph).mean()) / \\\n                                   (df['eth_volume'].rolling(rph).std() + 1e-8)\n            df['eth_vol_zscore'] = df['eth_vol_zscore'].clip(-5, 5)\n        \n        # Gas-ETH correlation\n        df['gas_eth_corr'] = df['gas'].rolling(rph).corr(df['eth_price']).fillna(0)\n    \n    # === NETWORK UTILIZATION ===\n    if 'utilization' in df.columns:\n        df['util_mean_1h'] = df['utilization'].rolling(rph, min_periods=rph//2).mean()\n        df['util_std_1h'] = df['utilization'].rolling(rph, min_periods=rph//2).std()\n    \n    # === GAS LAG FEATURES (fixed - no duplicates) ===\n    # Short-term lags (for 1h prediction)\n    for lag_mins in [5, 15, 30]:\n        lag_periods = lag_mins * 2\n        df[f'gas_lag_{lag_mins}min'] = df['gas'].shift(lag_periods)\n    \n    # Hourly lags (for all horizons)\n    for lag_hours in [1, 2, 4]:\n        df[f'gas_lag_{lag_hours}h'] = df['gas'].shift(lag_hours * rph)\n    \n    # Long-term lags (for 24h prediction only)\n    if horizon in ['24h', 'all']:\n        for lag_hours in [6, 12, 24]:\n            df[f'gas_lag_{lag_hours}h'] = df['gas'].shift(lag_hours * rph)\n    \n    # === ROLLING STATS ===\n    # Short windows (1h, 2h)\n    for window_hours in [1, 2]:\n        window = window_hours * rph\n        prefix = f'{window_hours}h'\n        df[f'gas_mean_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).mean()\n        df[f'gas_std_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).std()\n        df[f'gas_median_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).median()\n        mean_val = df[f'gas_mean_{prefix}']\n        df[f'gas_cv_{prefix}'] = np.where(mean_val > 0.01, df[f'gas_std_{prefix}'] / mean_val, 0)\n    \n    # Long windows (for 4h/24h)\n    if horizon in ['4h', '24h', 'all']:\n        for window_hours in [4, 8]:\n            window = window_hours * rph\n            prefix = f'{window_hours}h'\n            df[f'gas_mean_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).mean()\n            df[f'gas_std_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).std()\n    \n    # Very long windows (24h only)\n    if horizon in ['24h', 'all']:\n        for window_hours in [12, 24]:\n            window = window_hours * rph\n            if len(df) > window:\n                prefix = f'{window_hours}h'\n                df[f'gas_mean_{prefix}'] = df['gas'].rolling(window, min_periods=window//2).mean()\n    \n    # === GARCH-STYLE VOLATILITY CLUSTERING (NEW) ===\n    # Squared returns (proxy for volatility)\n    gas_returns = df['gas'].pct_change().fillna(0)\n    df['gas_return_sq'] = gas_returns ** 2\n    \n    # Rolling volatility of volatility\n    df['vol_1h'] = df['gas_return_sq'].rolling(rph).mean()\n    df['vol_4h'] = df['gas_return_sq'].rolling(4*rph).mean()\n    \n    # Volatility ratio (short/long) - high means volatility increasing\n    df['vol_ratio'] = np.where(df['vol_4h'] > 1e-8, df['vol_1h'] / df['vol_4h'], 1.0)\n    df['vol_ratio'] = df['vol_ratio'].clip(0.1, 10)  # Clip extremes\n    \n    # Volatility trend\n    df['vol_trend'] = df['vol_1h'] - df['vol_1h'].shift(rph)\n    \n    # === MOMENTUM ===\n    df['momentum_1h'] = df['gas'] - df['gas'].shift(rph)\n    df['momentum_2h'] = df['gas'] - df['gas'].shift(2*rph)\n    \n    # Momentum percentage (safe division)\n    for hours in [1, 2]:\n        shift_val = df['gas'].shift(hours * rph)\n        df[f'momentum_pct_{hours}h'] = np.where(shift_val > 0.01, \n            (df['gas'] - shift_val) / shift_val, 0)\n    \n    # === TREND ===\n    mean_1h = df['gas_mean_1h']\n    mean_2h = df['gas_mean_2h']\n    df['trend_1h_2h'] = np.where(mean_2h > 0.01, mean_1h / mean_2h, 1.0)\n    \n    if 'gas_mean_4h' in df.columns:\n        mean_4h = df['gas_mean_4h']\n        df['trend_1h_4h'] = np.where(mean_4h > 0.01, mean_1h / mean_4h, 1.0)\n    \n    # === Z-SCORE ===\n    df['gas_zscore_1h'] = np.where(df['gas_std_1h'] > 0.001, \n        (df['gas'] - df['gas_mean_1h']) / df['gas_std_1h'], 0)\n    \n    # === SPIKE/REGIME INDICATORS ===\n    df['is_spike'] = (df['gas'] > df['gas_mean_1h'] + 2 * df['gas_std_1h']).astype(int)\n    df['is_high_gas'] = (df['gas'] > df['gas'].rolling(4*rph).quantile(0.9)).astype(int)\n    \n    # Volatility regime\n    rolling_std = df['gas'].rolling(4*rph).std()\n    overall_std = df['gas'].std()\n    vol_normalized = np.where(overall_std > 0.001, rolling_std / overall_std, 1.0)\n    df['volatility_regime'] = pd.cut(\n        vol_normalized,\n        bins=[0, 0.5, 1.5, float('inf')],\n        labels=['low', 'normal', 'high']\n    )\n    \n    return df\n\n# Process each segment\nprint(\"\\n",
    "Processing segments...\")\nsegments = df['segment'].unique()\nprocessed_segments = []\n\nfor seg_id in segments:\n    seg_df = df[df['segment'] == seg_id].copy()\n    processed = engineer_features_for_segment(seg_df, has_eth=has_eth_data, horizon='all')\n    processed_segments.append(processed)\n\ndf_features = pd.concat(processed_segments, axis=0)\nprint(f\"After feature engineering: {len(df_features):,} records\")\n\n# Create targets\nprint(\"\\n",
    "Creating prediction targets...\")\n\ndef create_targets_for_segment(seg_df):\n    \"\"\"Create target variables - future gas prices\"\"\"\n    df = seg_df.copy()\n    rph = 120\n    \n    # Future prices\n    df['target_1h'] = df['gas'].shift(-rph)\n    df['target_4h'] = df['gas'].shift(-4*rph)\n    df['target_24h'] = df['gas'].shift(-24*rph)\n    \n    # Price changes\n    df['target_diff_1h'] = df['target_1h'] - df['gas']\n    df['target_diff_4h'] = df['target_4h'] - df['gas']\n    \n    # Direction classification\n    threshold = 0.02  # 2% change threshold\n    for horizon in ['1h', '4h']:\n        pct_change = np.where(df['gas'] > 0.001, \n            (df[f'target_{horizon}'] - df['gas']) / df['gas'], 0)\n        df[f'direction_class_{horizon}'] = pd.cut(\n            pct_change,\n            bins=[-float('inf'), -threshold, threshold, float('inf')],\n            labels=['down', 'stable', 'up']\n        )\n    \n    return df\n\nprocessed_with_targets = []\nfor seg_id in df_features['segment'].unique():\n    seg_df = df_features[df_features['segment'] == seg_id].copy()\n    processed = create_targets_for_segment(seg_df)\n    processed_with_targets.append(processed)\n\ndf_features = pd.concat(processed_with_targets, axis=0)\n\n# === CLEAN INF/NAN VALUES ===\nprint(\"\\n",
    "Cleaning inf/nan values...\")\nfor col in df_features.select_dtypes(include=[np.number]).columns:\n    df_features[col] = df_features[col].replace([np.inf, -np.inf], np.nan)\n    if df_features[col].notna().sum() > 0:\n        q_low = df_features[col].quantile(0.001)\n        q_high = df_features[col].quantile(0.999)\n        df_features[col] = df_features[col].clip(q_low, q_high)\n\ndf_features = df_features.ffill().bfill()\n\ninf_count = np.isinf(df_features.select_dtypes(include=[np.number])).sum().sum()\nnan_count = df_features.select_dtypes(include=[np.number]).isna().sum().sum()\nprint(f\"  After cleaning: {inf_count} inf, {nan_count} nan values\")\nprint(f\"Records with targets: {len(df_features):,}\")\n\n# === DEFINE HORIZON-SPECIFIC FEATURE SETS ===\nall_feature_cols = [c for c in df_features.columns if c not in [\n    'gas', 'gas_log', 'base_fee', 'priority_fee', 'block_number',\n    'gas_used', 'gas_limit', 'utilization', 'eth_price', 'eth_volume', \n    'eth_high', 'eth_low', 'segment', 'time_diff', 'gas_return_sq',\n    'target_1h', 'target_4h', 'target_24h', 'target_diff_1h', 'target_diff_4h',\n    'direction_class_1h', 'direction_class_4h', 'volatility_regime'\n]]\n\n# 1h features: focus on short-term, micro features\nfeatures_1h = [c for c in all_feature_cols if not any(x in c for x in ['12h', '24h', '6h', '8h'])]\n\n# 4h features: include medium-term\nfeatures_4h = [c for c in all_feature_cols if not any(x in c for x in ['12h', '24h'])]\n\n# 24h features: include all, especially long-term\nfeatures_24h = all_feature_cols.copy()\n\nprint(f\"\\n",
    "\u2713 Feature sets defined:\")\nprint(f\"  1h model: {len(features_1h)} features\")\nprint(f\"  4h model: {len(features_4h)} features\") \nprint(f\"  24h model: {len(features_24h)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data - with horizon-specific features and out-of-time holdout\nfrom sklearn.preprocessing import RobustScaler\n\n# Only keep numeric columns\nnumeric_features_1h = df_features[features_1h].select_dtypes(include=[np.number]).columns.tolist()\nnumeric_features_4h = df_features[features_4h].select_dtypes(include=[np.number]).columns.tolist()\nnumeric_features_24h = df_features[features_24h].select_dtypes(include=[np.number]).columns.tolist()\n\nprint(f\"Numeric features: 1h={len(numeric_features_1h)}, 4h={len(numeric_features_4h)}, 24h={len(numeric_features_24h)}\")\n\n# Drop rows with NaN\ndf_clean = df_features.dropna()\nprint(f\"Clean samples: {len(df_clean):,}\")\n\n# === OUT-OF-TIME HOLDOUT (last 2 days) ===\nholdout_hours = 48\nrph = 120\nholdout_size = holdout_hours * rph\n\nif len(df_clean) > holdout_size + 5000:\n    df_train_val = df_clean.iloc[:-holdout_size]\n    df_holdout = df_clean.iloc[-holdout_size:]\n    print(f\"\\n",
    "\u2713 Out-of-time holdout: {len(df_holdout):,} samples (last {holdout_hours}h)\")\n    print(f\"  Training/validation: {len(df_train_val):,} samples\")\n    HAS_HOLDOUT = True\nelse:\n    df_train_val = df_clean\n    df_holdout = None\n    print(f\"\\n",
    "\u26a0\ufe0f Not enough data for holdout, using all for training\")\n    HAS_HOLDOUT = False\n\n# Final safety check\nfor col in df_train_val.select_dtypes(include=[np.float64, np.float32, float]).columns:\n    df_train_val[col] = df_train_val[col].replace([np.inf, -np.inf], np.nan)\n    if df_train_val[col].isna().any():\n        df_train_val[col] = df_train_val[col].fillna(df_train_val[col].median())\n\nfloat_cols = df_train_val.select_dtypes(include=[np.float64, np.float32, float]).columns\nhas_inf = any(np.isinf(df_train_val[col]).any() for col in float_cols)\nhas_nan = any(np.isnan(df_train_val[col]).any() for col in float_cols)\nassert not has_inf, \"Data still contains inf!\"\nassert not has_nan, \"Data still contains nan!\"\nprint(\"\u2713 Data validated: no inf/nan values\")\n\n# Prepare feature matrices for each horizon\nX_1h = df_train_val[numeric_features_1h]\nX_4h = df_train_val[numeric_features_4h]\nX_24h = df_train_val[numeric_features_24h]\n\ny_1h = df_train_val['target_1h']\ny_4h = df_train_val['target_4h']\ny_24h = df_train_val['target_24h']\n\ny_diff_1h = df_train_val['target_diff_1h']\ny_diff_4h = df_train_val['target_diff_4h']\n\ny_dir_1h = df_train_val['direction_class_1h']\ny_dir_4h = df_train_val['direction_class_4h']\n\nvolatility_regime = df_train_val['volatility_regime']\ncurrent_gas = df_train_val['gas']\n\n# === BASELINE MODELS ===\nprint(f\"\\n",
    "{'='*60}\")\nprint(\"BASELINE COMPARISONS\")\nprint(\"{'='*60}\")\n\nnaive_mae_1h = np.mean(np.abs(y_1h.values - current_gas.values))\nnaive_mae_4h = np.mean(np.abs(y_4h.values - current_gas.values))\n\nmean_pred = np.full_like(y_1h.values, y_1h.mean())\nmean_mae_1h = np.mean(np.abs(y_1h.values - mean_pred))\nmean_mae_4h = np.mean(np.abs(y_4h.values - mean_pred))\n\nprint(f\"\\n",
    "Baseline MAEs:\")\nprint(f\"  Naive (current price):     MAE_1h={naive_mae_1h:.6f}, MAE_4h={naive_mae_4h:.6f}\")\nprint(f\"  Mean (historical average): MAE_1h={mean_mae_1h:.6f}, MAE_4h={mean_mae_4h:.6f}\")\n\nbest_baseline_1h = min(naive_mae_1h, mean_mae_1h)\nbest_baseline_4h = min(naive_mae_4h, mean_mae_4h)\n\nprint(f\"\\n",
    "  Best baseline 1h: {best_baseline_1h:.6f}\")\nprint(f\"  Best baseline 4h: {best_baseline_4h:.6f}\")\n\nBASELINES = {\n    '1h': {'naive_mae': naive_mae_1h, 'mean_mae': mean_mae_1h, 'best': best_baseline_1h},\n    '4h': {'naive_mae': naive_mae_4h, 'mean_mae': mean_mae_4h, 'best': best_baseline_4h}\n}\n\nFEATURE_IMPORTANCE = {}\n\nprint(f\"\\n",
    "{'='*60}\")\nprint(\"TRAINING DATA SUMMARY\")\nprint(\"{'='*60}\")\nprint(f\"Training samples: {len(df_train_val):,}\")\nprint(f\"Holdout samples: {len(df_holdout) if df_holdout is not None else 0:,}\")\nprint(f\"Features 1h: {len(numeric_features_1h)}\")\nprint(f\"Features 4h: {len(numeric_features_4h)}\")\nprint(f\"Features 24h: {len(numeric_features_24h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training - IMPROVED v2\n# Additions: LightGBM, XGBoost, Stacking Ensemble, Purged Walk-Forward, Regime-Specific\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom sklearn.linear_model import Ridge, HuberRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import TimeSeriesSplit\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Try importing advanced libraries\ntry:\n    import lightgbm as lgb\n    HAS_LIGHTGBM = True\n    print(\"\u2713 LightGBM available\")\nexcept ImportError:\n    HAS_LIGHTGBM = False\n    print(\"\u26a0\ufe0f LightGBM not available, using sklearn alternatives\")\n\ntry:\n    import xgboost as xgb\n    HAS_XGBOOST = True\n    print(\"\u2713 XGBoost available\")\nexcept ImportError:\n    HAS_XGBOOST = False\n    print(\"\u26a0\ufe0f XGBoost not available\")\n\nMINIMUM_IMPROVEMENT = 0.05\n\ndef check_baseline_gate(model_mae, baseline_mae, model_name):\n    \"\"\"Check if model beats baseline by minimum threshold\"\"\"\n    improvement = (baseline_mae - model_mae) / baseline_mae\n    passed = improvement >= MINIMUM_IMPROVEMENT\n    if passed:\n        print(f\"  \u2713 PASSED baseline gate: {improvement*100:.1f}% improvement\")\n    else:\n        print(f\"  \u2717 FAILED baseline gate: {improvement*100:.1f}% (need {MINIMUM_IMPROVEMENT*100:.0f}%+)\")\n    return passed, improvement\n\ndef evaluate_model(y_true, y_pred, baseline_mae):\n    \"\"\"Evaluate model performance\"\"\"\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    improvement = (baseline_mae - mae) / baseline_mae\n    \n    if len(y_true) > 1:\n        actual_dir = np.sign(np.diff(y_true))\n        pred_dir = np.sign(np.diff(y_pred))\n        dir_acc = np.mean(actual_dir == pred_dir)\n    else:\n        dir_acc = 0\n    \n    return {\n        'mae': mae, 'rmse': rmse, 'r2': r2,\n        'improvement': improvement,\n        'vs_baseline': f\"{improvement*100:+.1f}%\",\n        'directional_accuracy': dir_acc\n    }\n\n# === PURGED WALK-FORWARD VALIDATION ===\ndef purged_walk_forward_validate(model_class, model_params, X, y, baseline_mae, \n                                  n_splits=5, purge_gap=120):\n    \"\"\"\n    Walk-forward validation with purge gap to prevent leakage.\n    purge_gap: number of samples to skip between train and test (default 1 hour at 30-sec intervals)\n    \"\"\"\n    n = len(X)\n    fold_size = n // (n_splits + 1)\n    fold_results = []\n    \n    for fold in range(n_splits):\n        train_end = fold_size * (fold + 1)\n        test_start = train_end + purge_gap  # Add gap to prevent leakage\n        test_end = test_start + fold_size\n        \n        if test_end > n:\n            break\n            \n        X_train = X.iloc[:train_end]\n        X_test = X.iloc[test_start:test_end]\n        y_train = y.iloc[:train_end]\n        y_test = y.iloc[test_start:test_end]\n        \n        scaler = RobustScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        model = model_class(**model_params)\n        model.fit(X_train_scaled, y_train)\n        \n        y_pred = model.predict(X_test_scaled)\n        mae = mean_absolute_error(y_test, y_pred)\n        fold_results.append(mae)\n    \n    if not fold_results:\n        return None\n        \n    return {\n        'avg_mae': np.mean(fold_results),\n        'std_mae': np.std(fold_results),\n        'fold_maes': fold_results,\n        'improvement': (baseline_mae - np.mean(fold_results)) / baseline_mae\n    }\n\n# === MODEL DEFINITIONS ===\ndef get_models_to_try():\n    \"\"\"Get list of models to try, including LightGBM and XGBoost if available\"\"\"\n    models = [\n        ('Ridge', Ridge, {'alpha': 1.0, 'random_state': 42}),\n        ('Huber', HuberRegressor, {'epsilon': 1.35, 'alpha': 0.1, 'max_iter': 1000}),\n        ('RF', RandomForestRegressor, {'n_estimators': 100, 'max_depth': 8, 'random_state': 42, 'n_jobs': -1}),\n        ('GBM', GradientBoostingRegressor, {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'random_state': 42}),\n    ]\n    \n    if HAS_LIGHTGBM:\n        models.append(('LightGBM', lgb.LGBMRegressor, {\n            'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05,\n            'num_leaves': 31, 'min_child_samples': 20,\n            'subsample': 0.8, 'colsample_bytree': 0.8,\n            'reg_alpha': 0.1, 'reg_lambda': 0.1,\n            'random_state': 42, 'n_jobs': -1, 'verbose': -1\n        }))\n    \n    if HAS_XGBOOST:\n        models.append(('XGBoost', xgb.XGBRegressor, {\n            'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05,\n            'subsample': 0.8, 'colsample_bytree': 0.8,\n            'reg_alpha': 0.1, 'reg_lambda': 0.1,\n            'random_state': 42, 'n_jobs': -1, 'verbosity': 0\n        }))\n    \n    return models\n\n# === STACKING ENSEMBLE ===\ndef train_stacking_ensemble(X_train, y_train, X_test, y_test, scaler):\n    \"\"\"Train a stacking ensemble\"\"\"\n    print(\"  Training stacking ensemble...\")\n    \n    base_estimators = [\n        ('huber', HuberRegressor(epsilon=1.35, alpha=0.1, max_iter=1000)),\n        ('rf', RandomForestRegressor(n_estimators=50, max_depth=6, random_state=42, n_jobs=-1)),\n    ]\n    \n    if HAS_LIGHTGBM:\n        base_estimators.append(('lgbm', lgb.LGBMRegressor(\n            n_estimators=100, max_depth=5, learning_rate=0.1,\n            random_state=42, n_jobs=-1, verbose=-1\n        )))\n    \n    stacking = StackingRegressor(\n        estimators=base_estimators,\n        final_estimator=Ridge(alpha=1.0, random_state=42),\n        cv=3,\n        n_jobs=-1\n    )\n    \n    stacking.fit(X_train, y_train)\n    y_pred = stacking.predict(X_test)\n    mae = mean_absolute_error(y_test, y_pred)\n    \n    return stacking, mae\n\n# === MAIN TRAINING FUNCTION ===\ndef train_model_advanced(X, y, baseline_mae, horizon_name, feature_names):\n    \"\"\"Train model with advanced methods\"\"\"\n    print(f\"\\n",
    "{'='*60}\")\n    print(f\"Training {horizon_name} model (ADVANCED)\")\n    print(f\"{'='*60}\")\n    print(f\"Samples: {len(X):,}, Features: {X.shape[1]}\")\n    print(f\"Baseline MAE: {baseline_mae:.6f}\")\n    \n    models_to_try = get_models_to_try()\n    results = []\n    \n    # Purged walk-forward validation for each model\n    for name, model_class, params in models_to_try:\n        print(f\"\\n",
    "[{name}] Purged walk-forward validation...\")\n        try:\n            wf_result = purged_walk_forward_validate(model_class, params, X, y, baseline_mae, n_splits=5, purge_gap=120)\n            if wf_result:\n                print(f\"  Avg MAE: {wf_result['avg_mae']:.6f} \u00b1 {wf_result['std_mae']:.6f}\")\n                print(f\"  vs Baseline: {wf_result['improvement']*100:+.1f}%\")\n                results.append({\n                    'name': name, 'model_class': model_class, 'params': params,\n                    'avg_mae': wf_result['avg_mae'], 'std_mae': wf_result['std_mae'],\n                    'improvement': wf_result['improvement']\n                })\n        except Exception as e:\n            print(f\"  Failed: {e}\")\n    \n    if not results:\n        print(\"\\n",
    "\u26a0\ufe0f All models failed!\")\n        return None, None, None, None\n    \n    # Train stacking ensemble\n    split_idx = int(len(X) * 0.8)\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X.iloc[:split_idx])\n    X_test_scaled = scaler.transform(X.iloc[split_idx:])\n    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n    \n    try:\n        stacking_model, stacking_mae = train_stacking_ensemble(\n            X_train_scaled, y_train, X_test_scaled, y_test, scaler\n        )\n        stacking_improvement = (baseline_mae - stacking_mae) / baseline_mae\n        print(f\"  Stacking MAE: {stacking_mae:.6f} ({stacking_improvement*100:+.1f}%)\")\n        results.append({\n            'name': 'Stacking', 'model_class': None, 'params': None,\n            'avg_mae': stacking_mae, 'std_mae': 0,\n            'improvement': stacking_improvement,\n            'pretrained_model': stacking_model\n        })\n    except Exception as e:\n        print(f\"  Stacking failed: {e}\")\n    \n    # Select best model\n    best = min(results, key=lambda x: x['avg_mae'])\n    print(f\"\\n",
    ">>> Best model: {best['name']} (MAE: {best['avg_mae']:.6f})\")\n    \n    # Check baseline gate\n    passed, improvement = check_baseline_gate(best['avg_mae'], baseline_mae, best['name'])\n    \n    # Train final model on all data\n    print(f\"\\n",
    "Training final {best['name']} model on all data...\")\n    scaler = RobustScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    if 'pretrained_model' in best and best['pretrained_model'] is not None:\n        # Use pretrained stacking model\n        final_model = best['pretrained_model']\n    else:\n        final_model = best['model_class'](**best['params'])\n        final_model.fit(X_scaled, y)\n    \n    # Get feature importance if available\n    importance = {}\n    if hasattr(final_model, 'feature_importances_'):\n        importance = dict(zip(feature_names, final_model.feature_importances_))\n    elif hasattr(final_model, 'coef_'):\n        importance = dict(zip(feature_names, np.abs(final_model.coef_)))\n    \n    return final_model, scaler, {\n        'name': best['name'],\n        'mae': best['avg_mae'],\n        'improvement': best['improvement'],\n        'passed_baseline': passed\n    }, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models with horizon-specific features\nprint(\"=\"*70)\nprint(\"TRAINING ALL PREDICTION MODELS\")\nprint(\"=\"*70)\n\ntrained_models = {}\nall_feature_importance = {}\n\n# === 1H MODEL ===\nmodel_1h, scaler_1h, metrics_1h, importance_1h = train_model_advanced(\n    X_1h, y_1h, BASELINES['1h']['best'], '1h', numeric_features_1h\n)\nif model_1h:\n    trained_models['1h'] = {'model': model_1h, 'scaler': scaler_1h, 'metrics': metrics_1h, 'features': numeric_features_1h}\n    if importance_1h:\n        all_feature_importance['1h'] = importance_1h\n\n# === 4H MODEL ===\nmodel_4h, scaler_4h, metrics_4h, importance_4h = train_model_advanced(\n    X_4h, y_4h, BASELINES['4h']['best'], '4h', numeric_features_4h\n)\nif model_4h:\n    trained_models['4h'] = {'model': model_4h, 'scaler': scaler_4h, 'metrics': metrics_4h, 'features': numeric_features_4h}\n    if importance_4h:\n        all_feature_importance['4h'] = importance_4h\n\n# === 24H MODEL - REQUIRES 30+ DAYS OF DATA ===\nprint(f\"\\n",
    "{'='*60}\")\nprint(\"24h Model - Data Sufficiency Check\")\nprint(f\"{'='*60}\")\n\nrph = 120\nmin_24h_samples = 30 * 24 * rph  # 30 days at 30-sec intervals\nvalid_24h_samples = y_24h.notna().sum()\n\n# Calculate actual days of data\ntotal_hours = len(df_clean) / rph\ntotal_days = total_hours / 24\n\nprint(f\"Total data: {total_days:.1f} days ({len(df_clean):,} samples)\")\nprint(f\"Valid 24h samples: {valid_24h_samples:,}\")\nprint(f\"Required for reliable 24h model: {min_24h_samples:,} samples (30 days)\")\n\nif total_days >= 30 and valid_24h_samples >= min_24h_samples // 2:\n    print(\"\\n",
    "\u2713 Sufficient data for 24h model - training...\")\n    \n    # Use only samples with valid 24h targets\n    mask_24h = y_24h.notna()\n    X_24h_valid = X_24h[mask_24h]\n    y_24h_valid = y_24h[mask_24h]\n    \n    model_24h, scaler_24h, metrics_24h, importance_24h = train_model_advanced(\n        X_24h_valid, y_24h_valid, BASELINES['4h']['best'], '24h', numeric_features_24h\n    )\n    if model_24h:\n        trained_models['24h'] = {\n            'model': model_24h, 'scaler': scaler_24h, \n            'metrics': metrics_24h, 'features': numeric_features_24h,\n            'is_fallback': False\n        }\n        if importance_24h:\n            all_feature_importance['24h'] = importance_24h\nelse:\n    print(f\"\\n",
    "\u26a0\ufe0f Insufficient data for reliable 24h model\")\n    print(f\"   Need 30+ days, have {total_days:.1f} days\")\n    print(\"   Using 4h model as fallback (honest about limitations)\")\n    \n    if model_4h:\n        trained_models['24h'] = {\n            'model': model_4h, 'scaler': scaler_4h,\n            'metrics': {\n                'name': metrics_4h['name'] + ' (4h fallback)',\n                'mae': metrics_4h['mae'],\n                'improvement': metrics_4h['improvement'],\n                'passed_baseline': metrics_4h['passed_baseline']\n            },\n            'features': numeric_features_4h,\n            'is_fallback': True\n        }\n\n# === OUT-OF-TIME HOLDOUT EVALUATION ===\nif HAS_HOLDOUT and df_holdout is not None:\n    print(f\"\\n",
    "{'='*60}\")\n    print(\"OUT-OF-TIME HOLDOUT EVALUATION\")\n    print(f\"{'='*60}\")\n    \n    for horizon in ['1h', '4h']:\n        if horizon in trained_models:\n            data = trained_models[horizon]\n            features = data['features']\n            \n            X_holdout = df_holdout[features]\n            y_holdout = df_holdout[f'target_{horizon}']\n            \n            # Remove NaN\n            mask = y_holdout.notna()\n            X_holdout = X_holdout[mask]\n            y_holdout = y_holdout[mask]\n            \n            if len(X_holdout) > 100:\n                X_holdout_scaled = data['scaler'].transform(X_holdout)\n                y_pred = data['model'].predict(X_holdout_scaled)\n                \n                holdout_mae = mean_absolute_error(y_holdout, y_pred)\n                holdout_improvement = (BASELINES[horizon]['best'] - holdout_mae) / BASELINES[horizon]['best']\n                \n                print(f\"\\n",
    "{horizon}: Holdout MAE = {holdout_mae:.6f} ({holdout_improvement*100:+.1f}% vs baseline)\")\n                \n                # Update metrics with holdout performance\n                trained_models[horizon]['holdout_mae'] = holdout_mae\n                trained_models[horizon]['holdout_improvement'] = holdout_improvement\n\n# === SUMMARY ===\nprint(f\"\\n",
    "{'='*70}\")\nprint(\"TRAINING SUMMARY\")\nprint(f\"{'='*70}\")\n\nfor horizon, data in trained_models.items():\n    m = data['metrics']\n    status = \"\u2713 PASSED\" if m['passed_baseline'] else \"\u26a0 BELOW BASELINE\"\n    fallback = \" (fallback)\" if data.get('is_fallback') else \"\"\n    holdout = f\" | Holdout: {data.get('holdout_mae', 'N/A'):.4f}\" if 'holdout_mae' in data else \"\"\n    print(f\"{horizon}: {m['name']}{fallback} | MAE: {m['mae']:.6f} | {m['improvement']*100:+.1f}%{holdout} | {status}\")\n\n# Store combined feature importance\nFEATURE_IMPORTANCE = all_feature_importance.get('4h', all_feature_importance.get('1h', {}))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# PREDICTION INTERVALS - IMPROVED with Conformal Prediction + Calibration\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"TRAINING PREDICTION INTERVALS (Conformal + Quantile)\")\nprint(\"=\"*60)\n\nquantile_models = {}\nconformal_residuals = {}\n\ndef train_conformal_intervals(X, y, model, scaler, horizon, alpha=0.2):\n    \"\"\"\n    Conformal prediction for guaranteed coverage.\n    alpha=0.2 means 80% prediction interval\n    \"\"\"\n    # Split into calibration set\n    cal_size = int(len(X) * 0.2)\n    X_train, X_cal = X.iloc[:-cal_size], X.iloc[-cal_size:]\n    y_train, y_cal = y.iloc[:-cal_size], y.iloc[-cal_size:]\n    \n    # Get predictions on calibration set\n    X_cal_scaled = scaler.transform(X_cal)\n    y_pred_cal = model.predict(X_cal_scaled)\n    \n    # Calculate residuals\n    residuals = np.abs(y_cal.values - y_pred_cal)\n    \n    # Get the (1-alpha) quantile of residuals\n    q = np.quantile(residuals, 1 - alpha)\n    \n    return {\n        'quantile': q,\n        'residuals': residuals,\n        'coverage_target': 1 - alpha\n    }\n\nfor horizon in ['1h', '4h']:\n    if horizon not in trained_models:\n        continue\n        \n    print(f\"\\n",
    "{horizon} prediction intervals...\")\n    \n    data = trained_models[horizon]\n    features = data['features']\n    \n    X_h = df_train_val[features]\n    y_h = df_train_val[f'target_{horizon}']\n    \n    mask = y_h.notna()\n    X_h = X_h[mask]\n    y_h = y_h[mask]\n    \n    if len(X_h) < 1000:\n        print(f\"  \u26a0\ufe0f Insufficient data for {horizon} intervals, skipping\")\n        continue\n    \n    split_idx = int(len(X_h) * 0.8)\n    X_train, X_test = X_h.iloc[:split_idx], X_h.iloc[split_idx:]\n    y_train, y_test = y_h.iloc[:split_idx], y_h.iloc[split_idx:]\n    \n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # === Quantile Regression ===\n    q_models = {}\n    for q in [0.1, 0.5, 0.9]:\n        model = GradientBoostingRegressor(\n            loss='quantile', alpha=q,\n            n_estimators=100, max_depth=5,\n            learning_rate=0.1, random_state=42\n        )\n        model.fit(X_train_scaled, y_train)\n        q_models[q] = model\n    \n    quantile_models[horizon] = (q_models, scaler)\n    print(f\"  \u2713 Quantile models trained (10th, 50th, 90th percentiles)\")\n    \n    # === Conformal Prediction ===\n    conformal = train_conformal_intervals(X_h, y_h, data['model'], data['scaler'], horizon, alpha=0.2)\n    conformal_residuals[horizon] = conformal\n    print(f\"  \u2713 Conformal interval: \u00b1{conformal['quantile']:.4f} gwei (80% coverage)\")\n    \n    # === Calibration Check ===\n    print(f\"  Calibration check...\")\n    \n    # Get predictions with intervals\n    y_pred_test = data['model'].predict(data['scaler'].transform(X_test))\n    \n    # Quantile interval coverage\n    q_low = q_models[0.1].predict(X_test_scaled)\n    q_high = q_models[0.9].predict(X_test_scaled)\n    q_coverage = np.mean((y_test.values >= q_low) & (y_test.values <= q_high))\n    \n    # Conformal interval coverage\n    conf_low = y_pred_test - conformal['quantile']\n    conf_high = y_pred_test + conformal['quantile']\n    conf_coverage = np.mean((y_test.values >= conf_low) & (y_test.values <= conf_high))\n    \n    print(f\"    Quantile 80% interval: actual coverage = {q_coverage:.1%}\")\n    print(f\"    Conformal 80% interval: actual coverage = {conf_coverage:.1%}\")\n    \n    # Store calibration results\n    trained_models[horizon]['calibration'] = {\n        'quantile_coverage': q_coverage,\n        'conformal_coverage': conf_coverage,\n        'conformal_width': conformal['quantile']\n    }\n    \n    # Warning if miscalibrated\n    if abs(q_coverage - 0.8) > 0.1:\n        print(f\"    \u26a0\ufe0f Quantile intervals may be miscalibrated\")\n    if abs(conf_coverage - 0.8) > 0.05:\n        print(f\"    \u26a0\ufe0f Conformal intervals may need recalibration\")\n\n# Copy 4h to 24h if available\nif '4h' in quantile_models:\n    quantile_models['24h'] = quantile_models['4h']\n    print(\"\\n",
    "24h: Using 4h quantile models\")\n\nif '4h' in conformal_residuals:\n    conformal_residuals['24h'] = conformal_residuals['4h']\n\nprint(f\"\\n",
    "\u2713 Prediction intervals ready for: {list(quantile_models.keys())}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Direction Prediction (Classification: Down/Stable/Up)\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"TRAINING DIRECTION MODELS\")\nprint(\"=\"*60)\n\ndirection_models = {}\n\nfor horizon, X_h, y_dir in [('1h', X_1h, y_dir_1h), ('4h', X_4h, y_dir_4h)]:\n    print(f\"\\n",
    "{horizon} direction model...\")\n    \n    # Prepare data\n    mask = y_dir.notna()\n    X_d = X_h[mask]\n    y_d = y_dir[mask]\n    \n    if len(X_d) < 1000:\n        print(f\"  \u26a0\ufe0f Insufficient data for {horizon} direction, skipping\")\n        continue\n    \n    # Train/test split\n    split_idx = int(len(X_d) * 0.8)\n    X_train, X_test = X_d.iloc[:split_idx], X_d.iloc[split_idx:]\n    y_train, y_test = y_d.iloc[:split_idx], y_d.iloc[split_idx:]\n    \n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train classifier\n    clf = GradientBoostingClassifier(\n        n_estimators=50, max_depth=4,\n        learning_rate=0.1, random_state=42\n    )\n    clf.fit(X_train_scaled, y_train)\n    \n    # Evaluate\n    y_pred = clf.predict(X_test_scaled)\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    direction_models[horizon] = {\n        'model': clf,\n        'scaler': scaler,\n        'accuracy': float(acc),\n        'f1_score': float(f1)\n    }\n    \n    print(f\"  Accuracy: {acc:.1%}, F1: {f1:.3f}\")\n\nprint(f\"\\n",
    "\u2713 Direction models trained for: {list(direction_models.keys())}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# REGIME DETECTION\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"TRAINING REGIME DETECTION MODEL\")\nprint(\"=\"*60)\n\n# Create regime labels from volatility\nif 'volatility_regime' in df_train_val.columns:\n    regime_labels = df_train_val['volatility_regime'].map({'low': 0, 'normal': 1, 'high': 2})\n    mask = regime_labels.notna()\n    \n    X_r = X_4h[mask]  # Use 4h features for regime detection\n    y_r = regime_labels[mask]\n    \n    if len(X_r) < 500:\n        print(\"\u26a0\ufe0f Insufficient data for regime detection\")\n        regime_clf = None\n        regime_scaler = None\n        regime_accuracy = 0\n    else:\n        # Train/test split\n        split_idx = int(len(X_r) * 0.8)\n        X_train, X_test = X_r.iloc[:split_idx], X_r.iloc[split_idx:]\n        y_train, y_test = y_r.iloc[:split_idx], y_r.iloc[split_idx:]\n        \n        regime_scaler = RobustScaler()\n        X_train_scaled = regime_scaler.fit_transform(X_train)\n        X_test_scaled = regime_scaler.transform(X_test)\n        \n        # Train classifier\n        regime_clf = RandomForestClassifier(\n            n_estimators=50, max_depth=6,\n            random_state=42, n_jobs=-1\n        )\n        regime_clf.fit(X_train_scaled, y_train)\n        \n        # Evaluate\n        y_pred = regime_clf.predict(X_test_scaled)\n        regime_accuracy = accuracy_score(y_test, y_pred)\n        \n        print(f\"Regime classes: Normal (0), Elevated (1), Spike (2)\")\n        print(f\"Accuracy: {regime_accuracy:.1%}\")\n        \n        if regime_accuracy > 0.95:\n            print(\"\u26a0\ufe0f Warning: Very high accuracy may indicate overfitting\")\nelse:\n    regime_clf = None\n    regime_scaler = None\n    regime_accuracy = 0\n    print(\"\u26a0\ufe0f No volatility regime data available, skipping regime detection\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Spike Detectors\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"TRAINING SPIKE DETECTORS\")\nprint(\"=\"*60)\n\nspike_models = {}\n\nfor horizon, X_h, y_target in [('1h', X_1h, y_1h), ('4h', X_4h, y_4h)]:\n    print(f\"\\n",
    "{horizon} spike detector...\")\n    \n    # Create spike labels (>2 std from mean is a spike)\n    mask = y_target.notna()\n    X_s = X_h[mask]\n    y_s = y_target[mask]\n    current = current_gas[mask]\n    \n    # Define spike threshold\n    price_change = y_s - current\n    threshold = price_change.std() * 2\n    spike_labels = (price_change > threshold).astype(int)\n    \n    spike_rate = spike_labels.mean()\n    print(f\"  Spike rate: {spike_rate:.1%}\")\n    \n    if spike_rate < 0.01 or spike_rate > 0.5:\n        print(f\"  \u26a0\ufe0f Unusual spike rate, skipping\")\n        continue\n    \n    if len(X_s) < 1000:\n        print(f\"  \u26a0\ufe0f Insufficient data, skipping\")\n        continue\n    \n    # Train/test split\n    split_idx = int(len(X_s) * 0.8)\n    X_train, X_test = X_s.iloc[:split_idx], X_s.iloc[split_idx:]\n    y_train, y_test = spike_labels.iloc[:split_idx], spike_labels.iloc[split_idx:]\n    \n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train with class weights\n    clf = GradientBoostingClassifier(\n        n_estimators=50, max_depth=4,\n        learning_rate=0.1, random_state=42\n    )\n    clf.fit(X_train_scaled, y_train)\n    \n    # Evaluate\n    y_pred = clf.predict(X_test_scaled)\n    acc = accuracy_score(y_test, y_pred)\n    \n    spike_models[horizon] = (clf, scaler)\n    print(f\"  Accuracy: {acc:.1%}\")\n\n# Copy 4h to 24h if available\nif '4h' in spike_models:\n    spike_models['24h'] = spike_models['4h']\n    print(\"\\n",
    "24h: Using 4h spike detector (fallback)\")\n\nprint(f\"\\n",
    "\u2713 Spike detectors trained for: {list(spike_models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# DQN AGENT TRAINING (OPTIONAL)\n",
    "# This trains a reinforcement learning agent for transaction timing\n",
    "# Skip if you just need prediction models\n",
    "\n",
    "TRAIN_DQN = False  # Set to True to train DQN agent\n",
    "\n",
    "if not TRAIN_DQN:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DQN TRAINING SKIPPED (set TRAIN_DQN = True to enable)\")\n",
    "    print(\"=\"*60)\n",
    "    DQN_TRAINED = False"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Training Implementation (runs only if TRAIN_DQN = True)\n",
    "\n",
    "if TRAIN_DQN:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING DQN AGENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.optim as optim\n",
    "        from collections import deque\n",
    "        import random\n",
    "        \n",
    "        class DQNNetwork(nn.Module):\n",
    "            def __init__(self, state_dim, action_dim):\n",
    "                super().__init__()\n",
    "                self.net = nn.Sequential(\n",
    "                    nn.Linear(state_dim, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, action_dim)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return self.net(x)\n",
    "        \n",
    "        class DQNAgent:\n",
    "            def __init__(self, state_dim, action_dim):\n",
    "                self.state_dim = state_dim\n",
    "                self.action_dim = action_dim\n",
    "                self.epsilon = 1.0\n",
    "                self.epsilon_min = 0.05\n",
    "                self.epsilon_decay = 0.995\n",
    "                self.gamma = 0.99\n",
    "                self.lr = 0.001\n",
    "                self.memory = deque(maxlen=10000)\n",
    "                self.batch_size = 32\n",
    "                self.training_steps = 0\n",
    "                \n",
    "                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                self.model = DQNNetwork(state_dim, action_dim).to(self.device)\n",
    "                self.target_model = DQNNetwork(state_dim, action_dim).to(self.device)\n",
    "                self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "                self.update_target()\n",
    "            \n",
    "            def update_target(self):\n",
    "                self.target_model.load_state_dict(self.model.state_dict())\n",
    "            \n",
    "            def act(self, state):\n",
    "                if random.random() < self.epsilon:\n",
    "                    return random.randint(0, self.action_dim - 1)\n",
    "                state_t = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    q_values = self.model(state_t)\n",
    "                return q_values.argmax().item()\n",
    "            \n",
    "            def remember(self, state, action, reward, next_state, done):\n",
    "                self.memory.append((state, action, reward, next_state, done))\n",
    "            \n",
    "            def replay(self):\n",
    "                if len(self.memory) < self.batch_size:\n",
    "                    return\n",
    "                \n",
    "                batch = random.sample(self.memory, self.batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                \n",
    "                states = torch.FloatTensor(states).to(self.device)\n",
    "                actions = torch.LongTensor(actions).to(self.device)\n",
    "                rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "                next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "                dones = torch.FloatTensor(dones).to(self.device)\n",
    "                \n",
    "                current_q = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "                next_q = self.target_model(next_states).max(1)[0].detach()\n",
    "                target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "                \n",
    "                loss = nn.MSELoss()(current_q.squeeze(), target_q)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                self.training_steps += 1\n",
    "                if self.training_steps % 100 == 0:\n",
    "                    self.update_target()\n",
    "                \n",
    "                self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "            \n",
    "            def save(self, path):\n",
    "                torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "        # Create simple environment\n",
    "        state_dim = min(30, len(X.columns))  # Limit state size\n",
    "        action_dim = 2  # 0 = wait, 1 = execute\n",
    "        \n",
    "        DQN_AGENT = DQNAgent(state_dim, action_dim)\n",
    "        \n",
    "        # Train for a few episodes\n",
    "        n_episodes = 500\n",
    "        print(f\"Training DQN for {n_episodes} episodes...\")\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            # Simple training loop\n",
    "            for i in range(min(100, len(X) - 1)):\n",
    "                state = X.iloc[i, :state_dim].values\n",
    "                action = DQN_AGENT.act(state)\n",
    "                \n",
    "                # Simple reward: negative gas price change if executing\n",
    "                next_gas = current_gas.iloc[i + 1] if i + 1 < len(current_gas) else current_gas.iloc[i]\n",
    "                reward = -(next_gas - current_gas.iloc[i]) if action == 1 else -0.001  # Small wait penalty\n",
    "                \n",
    "                next_state = X.iloc[i + 1, :state_dim].values if i + 1 < len(X) else state\n",
    "                done = (i >= min(99, len(X) - 2))\n",
    "                \n",
    "                DQN_AGENT.remember(state, action, reward, next_state, done)\n",
    "                DQN_AGENT.replay()\n",
    "            \n",
    "            if (episode + 1) % 100 == 0:\n",
    "                print(f\"  Episode {episode + 1}/{n_episodes}, Epsilon: {DQN_AGENT.epsilon:.3f}\")\n",
    "        \n",
    "        DQN_TRAINED = True\n",
    "        DQN_METRICS = {\n",
    "            'episodes': n_episodes,\n",
    "            'training_steps': DQN_AGENT.training_steps,\n",
    "            'final_epsilon': float(DQN_AGENT.epsilon)\n",
    "        }\n",
    "        print(f\"\\n\u2713 DQN training complete ({DQN_AGENT.training_steps} steps)\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"\u26a0\ufe0f PyTorch not available, skipping DQN training\")\n",
    "        DQN_TRAINED = False\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f DQN training failed: {e}\")\n",
    "        DQN_TRAINED = False\n",
    "else:\n",
    "    DQN_TRAINED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models - IMPROVED with conformal intervals and calibration data\nimport os\nfrom datetime import datetime\nimport json as json_lib\n\nos.makedirs('saved_models', exist_ok=True)\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"SAVING MODELS\")\nprint(\"=\"*60)\n\n# === Save prediction models ===\nfor horizon in ['1h', '4h', '24h']:\n    if horizon not in trained_models:\n        print(f\"\u26a0\ufe0f No {horizon} model to save\")\n        continue\n    \n    data = trained_models[horizon]\n    model = data['model']\n    scaler = data['scaler']\n    metrics = data['metrics']\n    features = data.get('features', [])\n    \n    model_data = {\n        'model': model,\n        'model_name': metrics['name'],\n        'metrics': {\n            'mae': float(metrics['mae']),\n            'improvement': float(metrics['improvement']),\n            'passed_baseline': bool(metrics['passed_baseline']),\n            'is_fallback': data.get('is_fallback', False)\n        },\n        'trained_at': datetime.now().isoformat(),\n        'feature_names': list(features),\n        'feature_scaler': scaler,\n        'scaler_type': 'RobustScaler'\n    }\n    \n    # Add holdout metrics if available\n    if 'holdout_mae' in data:\n        model_data['holdout_metrics'] = {\n            'mae': float(data['holdout_mae']),\n            'improvement': float(data['holdout_improvement'])\n        }\n    \n    # Add calibration data if available\n    if 'calibration' in data:\n        model_data['calibration'] = {\n            'quantile_coverage': float(data['calibration']['quantile_coverage']),\n            'conformal_coverage': float(data['calibration']['conformal_coverage']),\n            'conformal_width': float(data['calibration']['conformal_width'])\n        }\n    \n    # Add conformal interval width\n    if horizon in conformal_residuals:\n        model_data['conformal_interval'] = float(conformal_residuals[horizon]['quantile'])\n    \n    joblib.dump(model_data, f'saved_models/model_{horizon}.pkl')\n    status = \"\u2713\" if metrics['passed_baseline'] else \"\u26a0\"\n    print(f\"{status} Saved model_{horizon}.pkl ({metrics['name']}, MAE={metrics['mae']:.6f})\")\n    \n    joblib.dump(scaler, f'saved_models/scaler_{horizon}.pkl')\n\n# === Save feature names (use 4h as default) ===\ndefault_features = trained_models.get('4h', trained_models.get('1h', {})).get('features', [])\njoblib.dump(list(default_features), 'saved_models/feature_names.pkl')\nprint(f\"\\n",
    "Saved feature_names.pkl ({len(default_features)} features)\")\n\n# === Save spike detectors ===\nif 'spike_models' in dir() and spike_models:\n    for horizon, (clf, scaler) in spike_models.items():\n        spike_data = {'model': clf, 'scaler': scaler, 'trained_at': datetime.now().isoformat()}\n        joblib.dump(spike_data, f'saved_models/spike_detector_{horizon}.pkl')\n        print(f\"Saved spike_detector_{horizon}.pkl\")\n\n# === Save regime detector ===\nif 'regime_clf' in dir() and regime_clf is not None:\n    regime_data = {\n        'model': regime_clf, 'scaler': regime_scaler,\n        'regimes': {0: 'Normal', 1: 'Elevated', 2: 'Spike'},\n        'accuracy': regime_accuracy,\n        'trained_at': datetime.now().isoformat()\n    }\n    joblib.dump(regime_data, 'saved_models/regime_detector.pkl')\n    print(f\"Saved regime_detector.pkl (Accuracy: {regime_accuracy:.1%})\")\n\n# === Save quantile models ===\nif 'quantile_models' in dir() and quantile_models:\n    for horizon, (q_models, q_scaler) in quantile_models.items():\n        quantile_data = {\n            'models': q_models, 'scaler': q_scaler,\n            'quantiles': [0.1, 0.5, 0.9],\n            'trained_at': datetime.now().isoformat()\n        }\n        \n        # Add conformal data if available\n        if horizon in conformal_residuals:\n            quantile_data['conformal'] = {\n                'interval_width': float(conformal_residuals[horizon]['quantile']),\n                'coverage_target': 0.8\n            }\n        \n        joblib.dump(quantile_data, f'saved_models/quantile_{horizon}.pkl')\n        print(f\"Saved quantile_{horizon}.pkl\")\n\n# === Save training metadata ===\ndef convert_to_python_types(obj):\n    if isinstance(obj, dict):\n        return {k: convert_to_python_types(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_to_python_types(v) for v in obj]\n    elif isinstance(obj, (np.bool_, np.integer)):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    else:\n        return obj\n\nmetadata = {\n    'training_timestamp': datetime.now().isoformat(),\n    'total_samples': len(df_clean),\n    'training_samples': len(df_train_val),\n    'holdout_samples': len(df_holdout) if df_holdout is not None else 0,\n    'date_range': f\"{df_clean.index.min()} to {df_clean.index.max()}\",\n    'resampling': '30-second intervals',\n    'data_source': {\n        'eth_price': 'Binance 1-min' if HAS_ETH_PRICE else 'None',\n        'has_holdout': HAS_HOLDOUT\n    },\n    'features': {\n        '1h': len(numeric_features_1h),\n        '4h': len(numeric_features_4h),\n        '24h': len(numeric_features_24h)\n    },\n    'baselines': BASELINES,\n    'models': {},\n    'improvements': [\n        'Binance ETH price (1-min resolution)',\n        'Fourier seasonality features',\n        'GARCH-style volatility clustering',\n        'Horizon-specific feature sets',\n        'LightGBM/XGBoost models',\n        'Stacking ensemble',\n        'Purged walk-forward validation',\n        'Out-of-time holdout (last 48h)',\n        'Conformal prediction intervals',\n        'Interval calibration checks',\n        '24h model requires 30+ days data'\n    ]\n}\n\nfor horizon, data in trained_models.items():\n    m = data['metrics']\n    metadata['models'][horizon] = {\n        'name': m['name'],\n        'mae': float(m['mae']),\n        'improvement_pct': float(m['improvement'] * 100),\n        'passed_baseline': bool(m['passed_baseline']),\n        'is_fallback': data.get('is_fallback', False),\n        'features_count': len(data.get('features', []))\n    }\n    \n    if 'holdout_mae' in data:\n        metadata['models'][horizon]['holdout_mae'] = float(data['holdout_mae'])\n        metadata['models'][horizon]['holdout_improvement_pct'] = float(data['holdout_improvement'] * 100)\n    \n    if 'calibration' in data:\n        metadata['models'][horizon]['calibration'] = data['calibration']\n\nif 'direction_models' in dir() and direction_models:\n    metadata['direction_models'] = {\n        horizon: {'accuracy': data['accuracy'], 'f1_score': data['f1_score']}\n        for horizon, data in direction_models.items()\n    }\n\nmetadata = convert_to_python_types(metadata)\n\nwith open('saved_models/training_metadata.json', 'w') as f:\n    json_lib.dump(metadata, f, indent=2)\nprint(f\"\\n",
    "Saved training_metadata.json\")\n\n# === Save feature importance ===\nif FEATURE_IMPORTANCE:\n    sorted_importance = dict(sorted(FEATURE_IMPORTANCE.items(), key=lambda x: x[1], reverse=True))\n    with open('saved_models/feature_importance.json', 'w') as f:\n        json_lib.dump(convert_to_python_types(sorted_importance), f, indent=2)\n    print(f\"Saved feature_importance.json\")\n\n# === DQN Agent ===\nif 'DQN_TRAINED' in dir() and DQN_TRAINED:\n    os.makedirs('saved_models/rl_agents', exist_ok=True)\n    DQN_AGENT.save('saved_models/rl_agents/dqn_agent.pt')\n    dqn_meta = {\n        'state_dim': DQN_AGENT.state_dim,\n        'action_dim': DQN_AGENT.action_dim,\n        'training_steps': DQN_AGENT.training_steps,\n        'epsilon': float(DQN_AGENT.epsilon),\n        'metrics': DQN_METRICS if 'DQN_METRICS' in dir() else {},\n        'trained_at': datetime.now().isoformat()\n    }\n    with open('saved_models/rl_agents/dqn_metadata.json', 'w') as f:\n        json_lib.dump(dqn_meta, f, indent=2)\n    print(\"Saved DQN agent\")\n\nprint(\"\\n",
    "\" + \"=\"*60)\nprint(\"ALL MODELS SAVED\")\nprint(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final report\nprint(\"\\n",
    "\" + \"=\"*70)\nprint(\"TRAINING COMPLETE - FINAL REPORT\")\nprint(\"=\"*70)\n\ntotal_days = len(df_clean) / (120 * 24)\n\nprint(f\"\\n",
    "DATA SUMMARY\")\nprint(f\"   Total samples: {len(df_clean):,} ({total_days:.1f} days)\")\nprint(f\"   Training: {len(df_train_val):,} | Holdout: {len(df_holdout) if df_holdout is not None else 0:,}\")\nprint(f\"   Date range: {df_clean.index.min()} to {df_clean.index.max()}\")\nprint(f\"   ETH price: {'Binance 1-min \u2713' if HAS_ETH_PRICE else 'Not available'}\")\nprint(f\"   Features: 1h={len(numeric_features_1h)}, 4h={len(numeric_features_4h)}, 24h={len(numeric_features_24h)}\")\n\nprint(f\"\\n",
    "\" + \"-\"*70)\nprint(f\"{'MODEL PERFORMANCE':^70}\")\nprint(\"-\"*70)\nprint(f\"{'Horizon':<8} {'Model':<15} {'CV MAE':>10} {'Holdout':>10} {'vs Base':>10} {'Status':>12}\")\nprint(\"-\"*70)\n\nfor horizon in ['1h', '4h', '24h']:\n    if horizon in trained_models:\n        data = trained_models[horizon]\n        m = data['metrics']\n        name = m['name'][:14]\n        if data.get('is_fallback'):\n            name = name[:10] + '(fb)'\n        \n        cv_mae = f\"{m['mae']:.4f}\"\n        holdout_mae = f\"{data.get('holdout_mae', 0):.4f}\" if 'holdout_mae' in data else \"N/A\"\n        improvement = f\"{m['improvement']*100:+.1f}%\"\n        status = \"\u2713 PASS\" if m['passed_baseline'] else \"\u2717 FAIL\"\n        \n        print(f\"{horizon:<8} {name:<15} {cv_mae:>10} {holdout_mae:>10} {improvement:>10} {status:>12}\")\n\nprint(\"-\"*70)\n\n# Calibration report\nif any('calibration' in trained_models.get(h, {}) for h in ['1h', '4h']):\n    print(f\"\\n",
    "\" + \"-\"*70)\n    print(f\"{'PREDICTION INTERVAL CALIBRATION':^70}\")\n    print(\"-\"*70)\n    print(f\"{'Horizon':<10} {'Quantile 80%':>15} {'Conformal 80%':>15} {'Width (gwei)':>15}\")\n    print(\"-\"*70)\n    \n    for horizon in ['1h', '4h']:\n        if horizon in trained_models and 'calibration' in trained_models[horizon]:\n            cal = trained_models[horizon]['calibration']\n            q_cov = f\"{cal['quantile_coverage']:.1%}\"\n            c_cov = f\"{cal['conformal_coverage']:.1%}\"\n            width = f\"\u00b1{cal['conformal_width']:.4f}\"\n            print(f\"{horizon:<10} {q_cov:>15} {c_cov:>15} {width:>15}\")\n    \n    print(\"-\"*70)\n\n# Direction models\nif 'direction_models' in dir() and direction_models:\n    print(f\"\\n",
    "\" + \"-\"*70)\n    print(f\"{'DIRECTION PREDICTION':^70}\")\n    print(\"-\"*70)\n    for horizon, data in direction_models.items():\n        print(f\"  {horizon}: Accuracy={data['accuracy']:.1%}, F1={data['f1_score']:.3f}\")\n\n# 24h model status\nprint(f\"\\n",
    "\" + \"-\"*70)\nprint(f\"{'24H MODEL STATUS':^70}\")\nprint(\"-\"*70)\nif '24h' in trained_models:\n    if trained_models['24h'].get('is_fallback'):\n        print(f\"  \u26a0\ufe0f Using 4h model as fallback (need 30+ days of data)\")\n        print(f\"     Current data: {total_days:.1f} days\")\n        print(f\"     Recommendation: Collect {30 - total_days:.0f} more days before training true 24h model\")\n    else:\n        print(f\"  \u2713 True 24h model trained with {total_days:.1f} days of data\")\n\n# Final recommendation\nprint(f\"\\n",
    "\" + \"=\"*70)\nprint(\"RECOMMENDATION\")\nprint(\"=\"*70)\n\nall_passed = all(trained_models.get(h, {}).get('metrics', {}).get('passed_baseline', False) \n                 for h in trained_models if h in trained_models)\n\nif all_passed:\n    print(\"\u2713 All models beat baseline - READY FOR DEPLOYMENT\")\n    print(\"\\n",
    "Next steps:\")\n    print(\"  1. Download saved_models/ folder\")\n    print(\"  2. Copy to backend/models/saved_models/\")\n    print(\"  3. Restart backend\")\nelse:\n    failed = [h for h in trained_models \n              if not trained_models[h]['metrics']['passed_baseline']]\n    print(f\"\u26a0\ufe0f Some models did not pass baseline: {failed}\")\n    print(\"\\n",
    "Recommendations:\")\n    print(\"  - Collect more data\")\n    print(\"  - Review feature engineering\")\n    print(\"  - Only deploy passing models\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Training data distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(current_gas.values, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.set_xlabel('Gas Price (gwei)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Gas Price Distribution')\n",
    "ax1.axvline(current_gas.mean(), color='red', linestyle='--', label=f'Mean: {current_gas.mean():.2f}')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Model performance comparison\n",
    "ax2 = axes[0, 1]\n",
    "horizons = list(trained_models.keys())\n",
    "maes = [trained_models[h]['metrics']['mae'] for h in horizons]\n",
    "baselines = [BASELINES.get(h.replace('24h', '4h'), BASELINES['4h'])['best'] for h in horizons]\n",
    "\n",
    "x = np.arange(len(horizons))\n",
    "width = 0.35\n",
    "bars1 = ax2.bar(x - width/2, maes, width, label='Model MAE', color='steelblue')\n",
    "bars2 = ax2.bar(x + width/2, baselines, width, label='Baseline MAE', color='coral')\n",
    "ax2.set_xlabel('Horizon')\n",
    "ax2.set_ylabel('MAE (gwei)')\n",
    "ax2.set_title('Model vs Baseline Performance')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(horizons)\n",
    "ax2.legend()\n",
    "\n",
    "# Add improvement percentages\n",
    "for i, (h, m, b) in enumerate(zip(horizons, maes, baselines)):\n",
    "    imp = (b - m) / b * 100\n",
    "    color = 'green' if imp > 0 else 'red'\n",
    "    ax2.annotate(f'{imp:+.1f}%', xy=(i, max(m, b) + 0.02), ha='center', fontsize=9, color=color)\n",
    "\n",
    "# 3. Gas price time series (sample)\n",
    "ax3 = axes[1, 0]\n",
    "sample_size = min(2000, len(current_gas))\n",
    "sample_gas = current_gas.iloc[-sample_size:]\n",
    "ax3.plot(sample_gas.index, sample_gas.values, linewidth=0.5, alpha=0.8)\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Gas Price (gwei)')\n",
    "ax3.set_title(f'Recent Gas Prices (last {sample_size} samples)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Feature importance (top 10)\n",
    "ax4 = axes[1, 1]\n",
    "if FEATURE_IMPORTANCE:\n",
    "    sorted_imp = sorted(FEATURE_IMPORTANCE.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    features_plot = [f[0][:20] for f in sorted_imp]  # Truncate names\n",
    "    importances = [f[1] for f in sorted_imp]\n",
    "    \n",
    "    y_pos = np.arange(len(features_plot))\n",
    "    ax4.barh(y_pos, importances, color='teal')\n",
    "    ax4.set_yticks(y_pos)\n",
    "    ax4.set_yticklabels(features_plot)\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.set_xlabel('Importance')\n",
    "    ax4.set_title('Top 10 Feature Importance')\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'No feature importance data', ha='center', va='center')\n",
    "    ax4.set_title('Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('saved_models/training_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Saved training_results.png\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for download\n",
    "import shutil\n",
    "\n",
    "shutil.make_archive('gweizy_models', 'zip', 'saved_models')\n",
    "print(\"\\n\u2705 Created gweizy_models.zip\")\n",
    "print(\"\\nDownload this file and extract to: backend/models/saved_models/\")\n",
    "\n",
    "# Auto-download\n",
    "files.download('gweizy_models.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}