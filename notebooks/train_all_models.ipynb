{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gweizy Model Training Notebook\n",
    "\n",
    "Train all gas prediction models for Gweizy.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload your `gas_data.db` file (from `backend/gas_data.db`)\n",
    "2. Run all cells\n",
    "3. Download the trained models zip file\n",
    "4. Extract to `backend/models/saved_models/` and push to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q scikit-learn pandas numpy joblib lightgbm xgboost matplotlib seaborn optuna"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your gas_data.db file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your gas_data.db file from backend/gas_data.db\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'gas_data.db' in uploaded:\n",
    "    print(f\"\\n\u2705 Uploaded gas_data.db ({len(uploaded['gas_data.db']) / 1024 / 1024:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\u274c Please upload gas_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sqlite3\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Load data from database\nconn = sqlite3.connect('gas_data.db')\ndf = pd.read_sql(\"\"\"\n    SELECT timestamp, current_gas as gas, base_fee, priority_fee, \n           block_number, gas_used, gas_limit, utilization\n    FROM gas_prices ORDER BY timestamp ASC\n\"\"\", conn)\nconn.close()\n\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\ndf = df.set_index('timestamp').sort_index()\n\nprint(f\"Total records: {len(df):,}\")\nprint(f\"Date range: {df.index.min()} to {df.index.max()}\")\n\n# Resample to 1-minute (reduces noise, easier to work with)\nprint(\"\\nResampling to 1-minute intervals...\")\ndf = df.resample('1min').mean().dropna(subset=['gas'])\nprint(f\"After resample: {len(df):,} records\")\n\n# Find segments (gap > 30 min = new segment)\ndf['time_diff'] = df.index.to_series().diff()\ndf['segment'] = (df['time_diff'] > pd.Timedelta(minutes=30)).cumsum()\n\nsegment_sizes = df.groupby('segment').size()\nprint(f\"\\nSegments found: {len(segment_sizes)}\")\nprint(f\"Segment sizes: {segment_sizes.sort_values(ascending=False).head(10).tolist()}\")\n\n# Keep segments with at least 120 minutes (2 hours) of data\nMIN_SEGMENT_SIZE = 120\ngood_segments = segment_sizes[segment_sizes >= MIN_SEGMENT_SIZE].index.tolist()\ndf = df[df['segment'].isin(good_segments)]\nprint(f\"\\nKeeping {len(good_segments)} segments with >= {MIN_SEGMENT_SIZE} minutes\")\nprint(f\"Total usable records: {len(df):,}\")\n\nRECORDS_PER_HOUR = 60"
  },
  {
   "cell_type": "code",
   "source": "# Fetch ETH Price Data (External Feature)\nimport requests\nfrom datetime import datetime, timedelta\n\nprint(\"=\"*60)\nprint(\"FETCHING EXTERNAL DATA: ETH PRICE\")\nprint(\"=\"*60)\n\ndef fetch_eth_price_history(start_date, end_date):\n    \"\"\"Fetch ETH price history from CoinGecko API (free, no key needed)\"\"\"\n    try:\n        # Convert to timestamps\n        start_ts = int(start_date.timestamp())\n        end_ts = int(end_date.timestamp())\n        \n        url = f\"https://api.coingecko.com/api/v3/coins/ethereum/market_chart/range\"\n        params = {\n            'vs_currency': 'usd',\n            'from': start_ts,\n            'to': end_ts\n        }\n        \n        print(f\"Fetching ETH prices from {start_date} to {end_date}...\")\n        response = requests.get(url, params=params, timeout=30)\n        \n        if response.status_code == 200:\n            data = response.json()\n            prices = data.get('prices', [])\n            \n            # Convert to DataFrame\n            eth_df = pd.DataFrame(prices, columns=['timestamp', 'eth_price'])\n            eth_df['timestamp'] = pd.to_datetime(eth_df['timestamp'], unit='ms')\n            eth_df = eth_df.set_index('timestamp')\n            \n            print(f\"  Fetched {len(eth_df)} ETH price points\")\n            return eth_df\n        else:\n            print(f\"  API returned status {response.status_code}\")\n            return None\n            \n    except Exception as e:\n        print(f\"  Failed to fetch ETH prices: {e}\")\n        return None\n\n# Get date range from our gas data\nstart_date = df.index.min()\nend_date = df.index.max()\n\n# Fetch ETH prices\neth_prices = fetch_eth_price_history(start_date, end_date)\n\nif eth_prices is not None and len(eth_prices) > 0:\n    # Resample to 1-minute to match gas data\n    eth_prices = eth_prices.resample('1min').ffill()\n    \n    # Merge with gas data\n    df = df.join(eth_prices, how='left')\n    df['eth_price'] = df['eth_price'].ffill().bfill()\n    \n    print(f\"  Merged ETH prices with gas data\")\n    print(f\"  ETH price range: ${df['eth_price'].min():.2f} - ${df['eth_price'].max():.2f}\")\n    \n    HAS_ETH_PRICE = True\nelse:\n    print(\"  Could not fetch ETH prices - will proceed without\")\n    df['eth_price'] = np.nan\n    HAS_ETH_PRICE = False\n\n# Add network utilization features from existing data\nprint(\"\\nAdding network utilization features...\")\nif 'utilization' in df.columns:\n    df['utilization'] = df['utilization'].fillna(df['gas_used'] / (df['gas_limit'] + 1e-8))\n    print(f\"  Utilization range: {df['utilization'].min():.2%} - {df['utilization'].max():.2%}\")\nelse:\n    df['utilization'] = df['gas_used'] / (df['gas_limit'] + 1e-8)\n    print(f\"  Created utilization from gas_used/gas_limit\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature Engineering - IMPROVED with micro-features, ETH price, and utilization\n# Key: Use SHORT windows (max 4h) + MICRO windows (5min, 15min, 30min) for 1h\n\nprint(\"Engineering features with MICRO + SHORT windows + EXTERNAL features...\")\n\ndef engineer_features_for_segment(seg_df, has_eth=False):\n    \"\"\"Engineer features for a single continuous segment\"\"\"\n    df = seg_df.copy()\n    rph = 60  # records per hour (1-min intervals)\n    \n    # === Log transform gas (helps with skewed distribution) ===\n    df['gas_log'] = np.log1p(df['gas'])\n    \n    # === Time features (ENHANCED) ===\n    df['hour'] = df.index.hour\n    df['minute'] = df.index.minute\n    df['day_of_week'] = df.index.dayofweek\n    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n    df['is_business_hours'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)\n    # Peak hours for Ethereum (typically 14:00-22:00 UTC)\n    df['is_peak_hours'] = ((df['hour'] >= 14) & (df['hour'] <= 22)).astype(int)\n    \n    # === DAY-OF-WEEK ONE-HOT ENCODING (NEW) ===\n    for day in range(7):\n        df[f'dow_{day}'] = (df['day_of_week'] == day).astype(int)\n    \n    # === ETH PRICE FEATURES (if available) ===\n    if has_eth and 'eth_price' in df.columns and df['eth_price'].notna().any():\n        df['eth_log'] = np.log1p(df['eth_price'])\n        \n        # ETH momentum (price changes) - ENHANCED with more lags\n        for mins in [15, 30, 60]:\n            df[f'eth_change_{mins}min'] = df['eth_price'].pct_change(mins)\n        \n        # ETH price changes over hours (NEW)\n        for hours in [1, 2, 4]:\n            window = hours * rph\n            df[f'eth_change_{hours}h'] = df['eth_price'].pct_change(window)\n            df[f'eth_momentum_{hours}h'] = df['eth_price'] - df['eth_price'].shift(window)\n        \n        # ETH volatility\n        for hours in [1, 2, 4]:\n            window = hours * rph\n            df[f'eth_std_{hours}h'] = df['eth_price'].rolling(window, min_periods=window//2).std()\n            df[f'eth_volatility_{hours}h'] = df[f'eth_std_{hours}h'] / (df['eth_price'].rolling(window).mean() + 1e-8)\n        \n        # Gas-ETH correlation (rolling)\n        df['gas_eth_corr_1h'] = df['gas'].rolling(60).corr(df['eth_price'])\n        df['gas_eth_corr_4h'] = df['gas'].rolling(240).corr(df['eth_price'])\n        \n        # ETH price position\n        df['eth_zscore_1h'] = (df['eth_price'] - df['eth_price'].rolling(60).mean()) / (df['eth_price'].rolling(60).std() + 1e-8)\n        df['eth_zscore_4h'] = (df['eth_price'] - df['eth_price'].rolling(240).mean()) / (df['eth_price'].rolling(240).std() + 1e-8)\n        \n        # ETH trend indicators (NEW)\n        df['eth_trend_1h_4h'] = df['eth_price'].rolling(60).mean() / (df['eth_price'].rolling(240).mean() + 1e-8)\n    \n    # === NETWORK UTILIZATION FEATURES ===\n    if 'utilization' in df.columns:\n        # Utilization rolling stats\n        for mins in [15, 30]:\n            df[f'util_mean_{mins}min'] = df['utilization'].rolling(mins, min_periods=mins//2).mean()\n        for hours in [1, 2]:\n            window = hours * rph\n            df[f'util_mean_{hours}h'] = df['utilization'].rolling(window, min_periods=window//2).mean()\n            df[f'util_std_{hours}h'] = df['utilization'].rolling(window, min_periods=window//2).std()\n        \n        # High utilization indicator (>90%)\n        df['high_utilization'] = (df['utilization'] > 0.9).astype(int)\n        df['high_util_streak'] = df['high_utilization'].rolling(15).sum()  # How many of last 15 min were high\n    \n    # === MICRO Lag features (for 1h prediction) ===\n    for lag_mins in [5, 10, 15, 30]:\n        df[f'gas_lag_{lag_mins}min'] = df['gas'].shift(lag_mins)\n        df[f'gas_change_{lag_mins}min'] = df['gas'] - df['gas'].shift(lag_mins)\n        df[f'gas_pct_change_{lag_mins}min'] = df['gas'].pct_change(lag_mins)\n    \n    # === MICRO Rolling stats (5min, 15min, 30min windows) ===\n    for window_mins in [5, 15, 30]:\n        df[f'gas_mean_{window_mins}min'] = df['gas'].rolling(window_mins, min_periods=window_mins//2).mean()\n        df[f'gas_std_{window_mins}min'] = df['gas'].rolling(window_mins, min_periods=window_mins//2).std()\n        df[f'gas_min_{window_mins}min'] = df['gas'].rolling(window_mins, min_periods=window_mins//2).min()\n        df[f'gas_max_{window_mins}min'] = df['gas'].rolling(window_mins, min_periods=window_mins//2).max()\n        # Volatility\n        df[f'gas_range_{window_mins}min'] = df[f'gas_max_{window_mins}min'] - df[f'gas_min_{window_mins}min']\n        df[f'gas_cv_{window_mins}min'] = df[f'gas_std_{window_mins}min'] / (df[f'gas_mean_{window_mins}min'] + 1e-8)\n    \n    # === Standard Lag features (hours) ===\n    for lag_hours in [1, 2, 4]:\n        df[f'gas_lag_{lag_hours}h'] = df['gas'].shift(lag_hours * rph)\n        df[f'gas_log_lag_{lag_hours}h'] = df['gas_log'].shift(lag_hours * rph)\n    \n    # === Rolling stats (SHORT windows: 1h, 2h, 4h) ===\n    for window_hours in [1, 2, 4]:\n        window = window_hours * rph\n        df[f'gas_mean_{window_hours}h'] = df['gas'].rolling(window, min_periods=window//2).mean()\n        df[f'gas_std_{window_hours}h'] = df['gas'].rolling(window, min_periods=window//2).std()\n        df[f'gas_min_{window_hours}h'] = df['gas'].rolling(window, min_periods=window//2).min()\n        df[f'gas_max_{window_hours}h'] = df['gas'].rolling(window, min_periods=window//2).max()\n        df[f'gas_median_{window_hours}h'] = df['gas'].rolling(window, min_periods=window//2).median()\n        \n        # EMA (Exponential Moving Average)\n        df[f'gas_ema_{window_hours}h'] = df['gas'].ewm(span=window, min_periods=window//2).mean()\n        \n        # Volatility features\n        df[f'gas_cv_{window_hours}h'] = df[f'gas_std_{window_hours}h'] / (df[f'gas_mean_{window_hours}h'] + 1e-8)\n        df[f'gas_range_{window_hours}h'] = df[f'gas_max_{window_hours}h'] - df[f'gas_min_{window_hours}h']\n        df[f'gas_range_pct_{window_hours}h'] = df[f'gas_range_{window_hours}h'] / (df[f'gas_mean_{window_hours}h'] + 1e-8)\n    \n    # === MICRO Momentum (for 1h) ===\n    for mins in [5, 15, 30]:\n        df[f'momentum_{mins}min'] = df['gas'] - df['gas'].shift(mins)\n        df[f'momentum_pct_{mins}min'] = df['gas'].pct_change(mins)\n        # Acceleration (rate of change of momentum)\n        df[f'acceleration_{mins}min'] = df[f'momentum_{mins}min'] - df[f'momentum_{mins}min'].shift(mins)\n    \n    # === Standard Momentum ===\n    for hours in [1, 2]:\n        periods = hours * rph\n        df[f'momentum_{hours}h'] = df['gas'] - df['gas'].shift(periods)\n        df[f'momentum_pct_{hours}h'] = df['gas'].pct_change(periods)\n        df[f'acceleration_{hours}h'] = df[f'momentum_{hours}h'] - df[f'momentum_{hours}h'].shift(periods)\n        df[f'direction_{hours}h'] = np.sign(df[f'momentum_{hours}h'])\n    \n    # === Z-score ===\n    for hours in [1, 2, 4]:\n        df[f'gas_zscore_{hours}h'] = (df['gas'] - df[f'gas_mean_{hours}h']) / (df[f'gas_std_{hours}h'] + 1e-8)\n    \n    # === Trend indicators ===\n    df['trend_15min_1h'] = df['gas_mean_15min'] / (df['gas_mean_1h'] + 1e-8)\n    df['trend_30min_1h'] = df['gas_mean_30min'] / (df['gas_mean_1h'] + 1e-8)\n    df['trend_1h_2h'] = df['gas_mean_1h'] / (df['gas_mean_2h'] + 1e-8)\n    df['trend_1h_4h'] = df['gas_mean_1h'] / (df['gas_mean_4h'] + 1e-8)\n    df['ema_trend_short'] = df['gas_ema_1h'] / (df['gas_ema_2h'] + 1e-8)\n    df['ema_trend_long'] = df['gas_ema_1h'] / (df['gas_ema_4h'] + 1e-8)\n    \n    # === Price position (where is current price in recent range) ===\n    for window in ['30min', '1h', '2h', '4h']:\n        col_max = f'gas_max_{window}'\n        col_min = f'gas_min_{window}'\n        if col_max in df.columns and col_min in df.columns:\n            range_size = df[col_max] - df[col_min]\n            df[f'price_position_{window}'] = (df['gas'] - df[col_min]) / (range_size + 1e-8)\n    \n    # === REGIME DETECTION FEATURES ===\n    # Volatility regime\n    df['volatility_regime'] = pd.cut(\n        df['gas_cv_1h'], \n        bins=[0, 0.05, 0.15, float('inf')], \n        labels=[0, 1, 2]  # 0=Low, 1=Medium, 2=High\n    ).astype(float)\n    \n    # Activity regime based on gas level and volatility\n    gas_median = df['gas'].median()\n    df['is_high_gas'] = (df['gas'] > gas_median * 1.5).astype(int)\n    df['is_spike'] = (df['gas'] > gas_median * 2).astype(int)\n    \n    # Combined regime: 0=Normal, 1=Elevated, 2=Spike\n    df['activity_regime'] = 0\n    df.loc[df['gas_cv_1h'] > 0.1, 'activity_regime'] = 1  # Elevated volatility\n    df.loc[df['is_spike'] == 1, 'activity_regime'] = 2    # Spike\n    \n    # === Targets (absolute) ===\n    df['target_1h'] = df['gas'].shift(-1 * rph)\n    df['target_4h'] = df['gas'].shift(-4 * rph)\n    df['target_24h'] = df['gas'].shift(-4 * rph)  # Actually 4h (honest labeling)\n    \n    # === Targets (percentage change - for differencing approach) ===\n    df['target_pct_1h'] = (df['target_1h'] - df['gas']) / (df['gas'] + 1e-8)\n    df['target_pct_4h'] = (df['target_4h'] - df['gas']) / (df['gas'] + 1e-8)\n    \n    # === Targets (difference - for target differencing) ===\n    df['target_diff_1h'] = df['target_1h'] - df['gas']\n    df['target_diff_4h'] = df['target_4h'] - df['gas']\n    \n    # === Direction targets (for classification) ===\n    threshold = 0.02  # 2% change threshold\n    \n    def classify_direction(pct_change, threshold):\n        if pct_change < -threshold:\n            return 0  # Down\n        elif pct_change > threshold:\n            return 2  # Up\n        else:\n            return 1  # Stable\n    \n    df['direction_class_1h'] = df['target_pct_1h'].apply(lambda x: classify_direction(x, threshold))\n    df['direction_class_4h'] = df['target_pct_4h'].apply(lambda x: classify_direction(x, threshold))\n    \n    return df\n\n# Process each segment independently\nprint(\"Processing segments independently...\")\nall_features = []\n\nfor seg_id in df['segment'].unique():\n    seg_df = df[df['segment'] == seg_id].drop(columns=['segment', 'time_diff'])\n    if len(seg_df) >= MIN_SEGMENT_SIZE:\n        featured = engineer_features_for_segment(seg_df, has_eth=HAS_ETH_PRICE)\n        all_features.append(featured)\n        print(f\"  Segment {seg_id}: {len(seg_df)} \u2192 {len(featured.dropna())} usable rows\")\n\n# Combine all segments\ndf_features = pd.concat(all_features)\ndf_features = df_features.replace([np.inf, -np.inf], np.nan)\n\nprint(f\"\\nTotal featured samples: {len(df_features):,}\")\nprint(f\"After dropping NaN: {len(df_features.dropna()):,}\")\nprint(f\"ETH features included: {HAS_ETH_PRICE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare training data with feature selection\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Columns to exclude from features\nexclude_cols = ['gas', 'gas_log', 'base_fee', 'priority_fee', 'block_number', \n                'gas_used', 'gas_limit', 'utilization', 'eth_price',\n                'target_1h', 'target_4h', 'target_24h',\n                'target_pct_1h', 'target_pct_4h',\n                'target_diff_1h', 'target_diff_4h',\n                'direction_class_1h', 'direction_class_4h',\n                'volatility_regime']\n\nfeature_cols = [c for c in df_features.columns if c not in exclude_cols]\nprint(f\"Initial feature columns: {len(feature_cols)}\")\n\n# Drop rows with NaN\ndf_clean = df_features.dropna()\nprint(f\"Clean samples: {len(df_clean):,}\")\n\n# === Feature Selection Step 1: Remove highly correlated features (>0.90) ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"FEATURE SELECTION\")\nprint(\"=\"*60)\nprint(\"\\nStep 1: Removing highly correlated features (>0.90)...\")\nX_temp = df_clean[feature_cols]\ncorr_matrix = X_temp.corr().abs()\n\n# Find pairs with correlation > 0.90 (stricter for small dataset)\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\nto_drop_corr = [column for column in upper.columns if any(upper[column] > 0.90)]\nprint(f\"  Dropping {len(to_drop_corr)} highly correlated features\")\n\nfeature_cols = [c for c in feature_cols if c not in to_drop_corr]\nprint(f\"  Features after correlation filter: {len(feature_cols)}\")\n\n# === Feature Selection Step 2: Drop low-importance features ===\nprint(\"\\nStep 2: Identifying low-importance features using RandomForest...\")\n\n# Quick RF to get feature importance\nX_importance = df_clean[feature_cols]\ny_importance = df_clean['target_4h']  # Use 4h target for importance\n\n# Use a subset for speed\nsample_size = min(5000, len(X_importance))\nsample_idx = np.random.choice(len(X_importance), sample_size, replace=False)\nX_sample = X_importance.iloc[sample_idx]\ny_sample = y_importance.iloc[sample_idx]\n\n# Scale and fit RF\nscaler_temp = RobustScaler()\nX_sample_scaled = scaler_temp.fit_transform(X_sample)\n\nrf_importance = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\nrf_importance.fit(X_sample_scaled, y_sample)\n\n# Get importance scores\nimportance_dict = dict(zip(feature_cols, rf_importance.feature_importances_))\nsorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n\n# Show top 20 features\nprint(\"\\n  Top 20 most important features:\")\nfor feat, imp in sorted_importance[:20]:\n    print(f\"    {feat}: {imp:.4f}\")\n\n# Drop bottom 25% of features by importance\nn_to_keep = int(len(feature_cols) * 0.75)\nimportant_features = [f[0] for f in sorted_importance[:n_to_keep]]\ndropped_features = [f[0] for f in sorted_importance[n_to_keep:]]\nprint(f\"\\n  Dropping {len(dropped_features)} low-importance features (bottom 25%)\")\nprint(f\"  Features after importance filter: {len(important_features)}\")\n\n# Update feature_cols\nfeature_cols = important_features\n\n# === Create horizon-specific feature sets ===\n# 1h model benefits from micro-features\nmicro_features = [c for c in feature_cols if 'min' in c or 'micro' in c.lower()]\nhour_features = [c for c in feature_cols if 'h' in c and 'min' not in c]\ntime_features = [c for c in feature_cols if any(t in c for t in ['hour', 'day', 'sin', 'cos', 'weekend', 'business', 'peak', 'dow'])]\ntrend_features = [c for c in feature_cols if 'trend' in c or 'position' in c or 'zscore' in c]\neth_features = [c for c in feature_cols if 'eth' in c.lower()]\n\n# 1h: prioritize micro-features + short-term\nfeatures_1h = list(set(micro_features + time_features + trend_features + eth_features + \n                       [c for c in feature_cols if '1h' in c or '2h' in c]))\nfeatures_1h = [c for c in features_1h if c in feature_cols]\n\n# 4h: use all features but weight longer-term\nfeatures_4h = feature_cols  # Use all for 4h\n\nprint(f\"\\n1h model features: {len(features_1h)}\")\nprint(f\"4h model features: {len(features_4h)}\")\n\n# Prepare data\nX = df_clean[feature_cols]\nX_1h = df_clean[[c for c in features_1h if c in df_clean.columns]]\nX_4h = df_clean[[c for c in features_4h if c in df_clean.columns]]\n\ny_1h = df_clean['target_1h']\ny_4h = df_clean['target_4h']\ny_24h = df_clean['target_24h']\n\n# Percentage targets (for differencing approach)\ny_pct_1h = df_clean['target_pct_1h']\ny_pct_4h = df_clean['target_pct_4h']\n\n# Difference targets (for target differencing)\ny_diff_1h = df_clean['target_diff_1h']\ny_diff_4h = df_clean['target_diff_4h']\n\n# Direction targets for classification\ny_dir_1h = df_clean['direction_class_1h']\ny_dir_4h = df_clean['direction_class_4h']\n\n# Volatility regime for confidence\nvolatility_regime = df_clean['volatility_regime']\n\n# Store current gas for baseline and reconstruction\ncurrent_gas = df_clean['gas']\n\n# === Baseline Models ===\nprint(f\"\\n{'='*60}\")\nprint(\"BASELINE COMPARISONS\")\nprint(\"{'='*60}\")\n\n# Naive baseline: predict last known value\nnaive_pred_1h = current_gas.values\nnaive_mae_1h = np.mean(np.abs(y_1h.values - naive_pred_1h))\nnaive_mae_4h = np.mean(np.abs(y_4h.values - naive_pred_1h))\n\n# Mean baseline: predict historical mean\nmean_pred = np.full_like(y_1h.values, y_1h.mean())\nmean_mae_1h = np.mean(np.abs(y_1h.values - mean_pred))\nmean_mae_4h = np.mean(np.abs(y_4h.values - mean_pred))\n\n# Drift baseline: extrapolate recent trend\ndrift_pred_1h = current_gas.values + df_clean['momentum_1h'].values\ndrift_mae_1h = np.mean(np.abs(y_1h.values - drift_pred_1h))\n\nprint(f\"\\nBaseline MAEs:\")\nprint(f\"  Naive (current price):     MAE_1h={naive_mae_1h:.6f}, MAE_4h={naive_mae_4h:.6f}\")\nprint(f\"  Mean (historical average): MAE_1h={mean_mae_1h:.6f}, MAE_4h={mean_mae_4h:.6f}\")\nprint(f\"  Drift (extrapolate trend): MAE_1h={drift_mae_1h:.6f}\")\n\n# Use best baseline for comparison\nbest_baseline_1h = min(naive_mae_1h, mean_mae_1h, drift_mae_1h)\nbest_baseline_4h = min(naive_mae_4h, mean_mae_4h)\n\nprint(f\"\\n  Best baseline 1h: {best_baseline_1h:.6f}\")\nprint(f\"  Best baseline 4h: {best_baseline_4h:.6f}\")\n\n# Store baselines for comparison\nBASELINES = {\n    '1h': {'naive_mae': naive_mae_1h, 'mean_mae': mean_mae_1h, 'drift_mae': drift_mae_1h, 'best': best_baseline_1h},\n    '4h': {'naive_mae': naive_mae_4h, 'mean_mae': mean_mae_4h, 'best': best_baseline_4h}\n}\n\n# Store feature importance for saving\nFEATURE_IMPORTANCE = importance_dict\n\nprint(f\"\\n{'='*60}\")\nprint(\"TRAINING DATA SUMMARY\")\nprint(\"{'='*60}\")\nprint(f\"Samples: {len(X):,}\")\nprint(f\"Features (all): {len(feature_cols)}\")\nprint(f\"Features (1h specific): {len(features_1h)}\")\nprint(f\"Target 1h range: {y_1h.min():.4f} - {y_1h.max():.4f} gwei\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model Training with Stacking Ensemble, Target Differencing, and Direction Constraints\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom sklearn.linear_model import Ridge, ElasticNet, HuberRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef time_series_cv(model, X, y, n_splits=5):\n    \"\"\"Time-series cross-validation\"\"\"\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    scores = {'mae': [], 'r2': []}\n    \n    for train_idx, val_idx in tscv.split(X):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        scaler = RobustScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_val_scaled = scaler.transform(X_val)\n        \n        model.fit(X_train_scaled, y_train)\n        pred = model.predict(X_val_scaled)\n        \n        scores['mae'].append(mean_absolute_error(y_val, pred))\n        scores['r2'].append(r2_score(y_val, pred))\n    \n    return {\n        'mae_mean': np.mean(scores['mae']),\n        'mae_std': np.std(scores['mae']),\n        'r2_mean': np.mean(scores['r2']),\n        'r2_std': np.std(scores['r2'])\n    }\n\ndef train_1h_model(X, y, y_diff, current_gas, baseline_mae):\n    \"\"\"\n    Train 1h model with SIMPLER models + target differencing.\n    Also tries stacking ensemble for potentially better results.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"Training 1h models (SIMPLER + TARGET DIFFERENCING)\")\n    print(\"='*60}\")\n    print(f\"Baseline MAE (best): {baseline_mae:.6f}\")\n    \n    # Time-series split\n    split_idx = int(len(X) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n    y_diff_train, y_diff_test = y_diff.iloc[:split_idx], y_diff.iloc[split_idx:]\n    gas_test = current_gas.iloc[split_idx:]\n    \n    print(f\"Train: {len(X_train):,}, Test: {len(X_test):,}\")\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    results = []\n    all_preds = []\n    \n    # === 1. Ridge (strong regularization for noisy data) ===\n    print(\"\\n[1/6] Ridge Regression (high regularization)...\")\n    ridge = Ridge(alpha=10.0, random_state=42)\n    ridge.fit(X_train_scaled, y_train)\n    ridge_pred = ridge.predict(X_test_scaled)\n    ridge_metrics = evaluate_model(y_test, ridge_pred, baseline_mae)\n    results.append(('Ridge', ridge, ridge_metrics, scaler))\n    all_preds.append(ridge_pred)\n    print(f\"      MAE: {ridge_metrics['mae']:.6f}, vs Baseline: {ridge_metrics['vs_baseline']}\")\n    \n    # === 2. ElasticNet (L1+L2 regularization) ===\n    print(\"[2/6] ElasticNet...\")\n    elastic = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=5000)\n    elastic.fit(X_train_scaled, y_train)\n    elastic_pred = elastic.predict(X_test_scaled)\n    elastic_metrics = evaluate_model(y_test, elastic_pred, baseline_mae)\n    results.append(('ElasticNet', elastic, elastic_metrics, scaler))\n    all_preds.append(elastic_pred)\n    print(f\"      MAE: {elastic_metrics['mae']:.6f}, vs Baseline: {elastic_metrics['vs_baseline']}\")\n    \n    # === 3. Huber Regressor (robust to outliers) ===\n    print(\"[3/6] Huber Regressor (robust to outliers)...\")\n    huber = HuberRegressor(epsilon=1.35, alpha=1.0, max_iter=1000)\n    huber.fit(X_train_scaled, y_train)\n    huber_pred = huber.predict(X_test_scaled)\n    huber_metrics = evaluate_model(y_test, huber_pred, baseline_mae)\n    results.append(('Huber', huber, huber_metrics, scaler))\n    all_preds.append(huber_pred)\n    print(f\"      MAE: {huber_metrics['mae']:.6f}, vs Baseline: {huber_metrics['vs_baseline']}\")\n    \n    # === 4. Target Differencing (predict change, then reconstruct) ===\n    print(\"[4/6] Target Differencing (predict change)...\")\n    diff_model = Ridge(alpha=5.0, random_state=42)\n    diff_model.fit(X_train_scaled, y_diff_train)\n    diff_pred = diff_model.predict(X_test_scaled)\n    # Reconstruct absolute price from predicted difference\n    diff_absolute_pred = gas_test.values + diff_pred\n    diff_metrics = evaluate_model(y_test, diff_absolute_pred, baseline_mae)\n    results.append(('Differencing', diff_model, diff_metrics, scaler))\n    all_preds.append(diff_absolute_pred)\n    print(f\"      MAE: {diff_metrics['mae']:.6f}, vs Baseline: {diff_metrics['vs_baseline']}\")\n    \n    # === 5. LightGBM with aggressive regularization ===\n    try:\n        import lightgbm as lgb\n        print(\"[5/6] LightGBM (high regularization)...\")\n        \n        val_split = int(len(X_train_scaled) * 0.9)\n        X_tr, X_val = X_train_scaled[:val_split], X_train_scaled[val_split:]\n        y_tr, y_val = y_train.iloc[:val_split], y_train.iloc[val_split:]\n        \n        lgbm = lgb.LGBMRegressor(\n            n_estimators=200, max_depth=4, learning_rate=0.05,\n            num_leaves=15, min_child_samples=30, subsample=0.7,\n            colsample_bytree=0.7, reg_alpha=1.0, reg_lambda=1.0,\n            random_state=42, n_jobs=-1, verbose=-1\n        )\n        lgbm.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n                 callbacks=[lgb.early_stopping(30, verbose=False)])\n        \n        lgbm_pred = lgbm.predict(X_test_scaled)\n        lgbm_metrics = evaluate_model(y_test, lgbm_pred, baseline_mae)\n        results.append(('LightGBM', lgbm, lgbm_metrics, scaler))\n        all_preds.append(lgbm_pred)\n        print(f\"      MAE: {lgbm_metrics['mae']:.6f}, vs Baseline: {lgbm_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[5/6] LightGBM failed: {e}\")\n    \n    # === 6. Stacking Ensemble (NEW) ===\n    print(\"[6/6] Stacking Ensemble (Ridge + Huber + RF -> Ridge meta)...\")\n    try:\n        base_estimators = [\n            ('ridge', Ridge(alpha=10.0, random_state=42)),\n            ('huber', HuberRegressor(epsilon=1.35, alpha=1.0, max_iter=1000)),\n            ('rf', RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1))\n        ]\n        stacking = StackingRegressor(\n            estimators=base_estimators,\n            final_estimator=Ridge(alpha=0.1, random_state=42),\n            cv=3,\n            n_jobs=-1\n        )\n        stacking.fit(X_train_scaled, y_train)\n        stacking_pred = stacking.predict(X_test_scaled)\n        stacking_metrics = evaluate_model(y_test, stacking_pred, baseline_mae)\n        results.append(('Stacking', stacking, stacking_metrics, scaler))\n        all_preds.append(stacking_pred)\n        print(f\"      MAE: {stacking_metrics['mae']:.6f}, vs Baseline: {stacking_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[6/6] Stacking failed: {e}\")\n    \n    # === Weighted Ensemble ===\n    print(\"\\n[Ensemble] Weighted average (favor simpler models)...\")\n    weights = [1/len(all_preds)] * len(all_preds)\n    ensemble_pred = np.average(all_preds, axis=0, weights=weights)\n    ensemble_metrics = evaluate_model(y_test, ensemble_pred, baseline_mae)\n    print(f\"      MAE: {ensemble_metrics['mae']:.6f}, vs Baseline: {ensemble_metrics['vs_baseline']}\")\n    \n    # === Select best ===\n    all_results = results + [('Ensemble', [r[1] for r in results], ensemble_metrics, scaler)]\n    best = max(all_results, key=lambda x: x[2]['improvement'])\n    \n    print(f\"\\n>>> Best 1h model: {best[0]} (MAE: {best[2]['mae']:.6f}, {best[2]['vs_baseline']})\")\n    \n    # Calculate confidence based on volatility\n    confidence_scores = calculate_confidence(X_test, y_test, best[1] if best[0] != 'Ensemble' else results[0][1], scaler)\n    \n    return best, results, list(X.columns), ensemble_pred, y_test, confidence_scores\n\ndef train_4h_model(X, y, y_diff, current_gas, baseline_mae, dir_clf=None, dir_scaler=None):\n    \"\"\"\n    Train 4h model with full model suite + hyperparameter tuning + stacking.\n    Also supports direction-constrained predictions.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"Training 4h models (FULL SUITE + STACKING)\")\n    print(\"='*60}\")\n    print(f\"Baseline MAE (best): {baseline_mae:.6f}\")\n    \n    # Time-series split\n    split_idx = int(len(X) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n    y_diff_train, y_diff_test = y_diff.iloc[:split_idx], y_diff.iloc[split_idx:]\n    gas_test = current_gas.iloc[split_idx:]\n    \n    print(f\"Train: {len(X_train):,}, Test: {len(X_test):,}\")\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    results = []\n    all_preds = []\n    \n    # === 1. Random Forest with tuning ===\n    print(\"\\n[1/6] Random Forest with RandomizedSearchCV...\")\n    rf_params = {\n        'n_estimators': [100, 150, 200],\n        'max_depth': [8, 12, 15],\n        'min_samples_split': [5, 10, 15],\n        'min_samples_leaf': [3, 5, 8]\n    }\n    \n    rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n    tscv = TimeSeriesSplit(n_splits=3)\n    rf_search = RandomizedSearchCV(\n        rf_base, rf_params, n_iter=10, cv=tscv, \n        scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1\n    )\n    rf_search.fit(X_train_scaled, y_train)\n    rf = rf_search.best_estimator_\n    \n    rf_pred = rf.predict(X_test_scaled)\n    rf_metrics = evaluate_model(y_test, rf_pred, baseline_mae)\n    results.append(('RandomForest', rf, rf_metrics, scaler))\n    all_preds.append(rf_pred)\n    print(f\"      Best params: {rf_search.best_params_}\")\n    print(f\"      MAE: {rf_metrics['mae']:.6f}, vs Baseline: {rf_metrics['vs_baseline']}\")\n    \n    # === 2. Gradient Boosting ===\n    print(\"[2/6] Gradient Boosting...\")\n    gb = GradientBoostingRegressor(\n        n_estimators=150, max_depth=6, learning_rate=0.05,\n        min_samples_split=10, subsample=0.8, random_state=42\n    )\n    gb.fit(X_train_scaled, y_train)\n    gb_pred = gb.predict(X_test_scaled)\n    gb_metrics = evaluate_model(y_test, gb_pred, baseline_mae)\n    results.append(('GradientBoosting', gb, gb_metrics, scaler))\n    all_preds.append(gb_pred)\n    print(f\"      MAE: {gb_metrics['mae']:.6f}, vs Baseline: {gb_metrics['vs_baseline']}\")\n    \n    # === 3. LightGBM ===\n    try:\n        import lightgbm as lgb\n        print(\"[3/6] LightGBM with early stopping...\")\n        \n        val_split = int(len(X_train_scaled) * 0.9)\n        X_tr, X_val = X_train_scaled[:val_split], X_train_scaled[val_split:]\n        y_tr, y_val = y_train.iloc[:val_split], y_train.iloc[val_split:]\n        \n        lgbm = lgb.LGBMRegressor(\n            n_estimators=500, max_depth=10, learning_rate=0.03,\n            num_leaves=31, min_child_samples=20, subsample=0.8,\n            colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=0.1,\n            random_state=42, n_jobs=-1, verbose=-1\n        )\n        lgbm.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n                 callbacks=[lgb.early_stopping(50, verbose=False)])\n        \n        lgbm_pred = lgbm.predict(X_test_scaled)\n        lgbm_metrics = evaluate_model(y_test, lgbm_pred, baseline_mae)\n        results.append(('LightGBM', lgbm, lgbm_metrics, scaler))\n        all_preds.append(lgbm_pred)\n        print(f\"      MAE: {lgbm_metrics['mae']:.6f}, vs Baseline: {lgbm_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[3/6] LightGBM failed: {e}\")\n    \n    # === 4. XGBoost ===\n    try:\n        import xgboost as xgb\n        print(\"[4/6] XGBoost with early stopping...\")\n        \n        xgbm = xgb.XGBRegressor(\n            n_estimators=500, max_depth=8, learning_rate=0.03,\n            min_child_weight=5, subsample=0.8, colsample_bytree=0.8,\n            reg_alpha=0.1, reg_lambda=1.0, random_state=42, \n            n_jobs=-1, verbosity=0, early_stopping_rounds=50\n        )\n        xgbm.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n        \n        xgbm_pred = xgbm.predict(X_test_scaled)\n        xgbm_metrics = evaluate_model(y_test, xgbm_pred, baseline_mae)\n        results.append(('XGBoost', xgbm, xgbm_metrics, scaler))\n        all_preds.append(xgbm_pred)\n        print(f\"      MAE: {xgbm_metrics['mae']:.6f}, vs Baseline: {xgbm_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[4/6] XGBoost failed: {e}\")\n    \n    # === 5. Stacking Ensemble (NEW) ===\n    print(\"[5/6] Stacking Ensemble (RF + GB + Ridge -> Ridge meta)...\")\n    try:\n        base_estimators = [\n            ('rf', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),\n            ('gb', GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)),\n            ('ridge', Ridge(alpha=1.0, random_state=42))\n        ]\n        stacking = StackingRegressor(\n            estimators=base_estimators,\n            final_estimator=Ridge(alpha=0.1, random_state=42),\n            cv=3,\n            n_jobs=-1\n        )\n        stacking.fit(X_train_scaled, y_train)\n        stacking_pred = stacking.predict(X_test_scaled)\n        stacking_metrics = evaluate_model(y_test, stacking_pred, baseline_mae)\n        results.append(('Stacking', stacking, stacking_metrics, scaler))\n        all_preds.append(stacking_pred)\n        print(f\"      MAE: {stacking_metrics['mae']:.6f}, vs Baseline: {stacking_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[5/6] Stacking failed: {e}\")\n    \n    # === 6. Target Differencing ===\n    print(\"[6/6] Target Differencing (predict change)...\")\n    try:\n        diff_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n        diff_model.fit(X_train_scaled, y_diff_train)\n        diff_pred = diff_model.predict(X_test_scaled)\n        diff_absolute_pred = gas_test.values + diff_pred\n        diff_metrics = evaluate_model(y_test, diff_absolute_pred, baseline_mae)\n        results.append(('Differencing', diff_model, diff_metrics, scaler))\n        all_preds.append(diff_absolute_pred)\n        print(f\"      MAE: {diff_metrics['mae']:.6f}, vs Baseline: {diff_metrics['vs_baseline']}\")\n    except Exception as e:\n        print(f\"[6/6] Differencing failed: {e}\")\n    \n    # === Ensemble ===\n    print(\"\\n[Ensemble] Average all models...\")\n    ensemble_pred = np.mean(all_preds, axis=0)\n    ensemble_metrics = evaluate_model(y_test, ensemble_pred, baseline_mae)\n    print(f\"      MAE: {ensemble_metrics['mae']:.6f}, vs Baseline: {ensemble_metrics['vs_baseline']}\")\n    \n    # Select best\n    all_results = results + [('Ensemble', [r[1] for r in results], ensemble_metrics, scaler)]\n    best = max(all_results, key=lambda x: x[2]['improvement'])\n    \n    print(f\"\\n>>> Best 4h model: {best[0]} (MAE: {best[2]['mae']:.6f}, {best[2]['vs_baseline']})\")\n    \n    # Calculate confidence\n    confidence_scores = calculate_confidence(X_test, y_test, best[1] if best[0] != 'Ensemble' else results[0][1], scaler)\n    \n    return best, results, list(X.columns), ensemble_pred, y_test, confidence_scores\n\ndef evaluate_model(y_true, y_pred, baseline_mae):\n    \"\"\"Calculate model metrics with baseline comparison\"\"\"\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    \n    # Directional accuracy\n    if len(y_true) > 1:\n        actual_dir = np.sign(np.diff(y_true.values))\n        pred_dir = np.sign(np.diff(y_pred))\n        dir_acc = np.mean(actual_dir == pred_dir)\n    else:\n        dir_acc = 0.0\n    \n    # Compare to baseline\n    improvement = (baseline_mae - mae) / baseline_mae * 100\n    vs_baseline = f\"{improvement:+.1f}%\" if improvement != 0 else \"0%\"\n    \n    return {\n        'mae': mae, 'rmse': rmse, 'r2': r2, \n        'directional_accuracy': dir_acc,\n        'vs_baseline': vs_baseline, 'improvement': improvement\n    }\n\ndef calculate_confidence(X_test, y_test, model, scaler):\n    \"\"\"\n    Calculate prediction confidence based on:\n    1. Model's prediction variance (if ensemble/tree)\n    2. Distance from training distribution\n    3. Recent volatility\n    \"\"\"\n    X_scaled = scaler.transform(X_test) if not isinstance(X_test, np.ndarray) else X_test\n    \n    confidences = []\n    \n    if hasattr(model, 'estimators_'):\n        # For ensemble models, use prediction variance across trees\n        tree_preds = np.array([tree.predict(X_scaled) for tree in model.estimators_])\n        pred_std = np.std(tree_preds, axis=0)\n        # Lower std = higher confidence\n        max_std = np.percentile(pred_std, 95)\n        confidences = 1 - np.clip(pred_std / (max_std + 1e-8), 0, 1)\n    else:\n        # For other models, use uniform medium confidence\n        confidences = np.full(len(X_test), 0.6)\n    \n    return confidences\n\ndef apply_direction_constraint(predictions, current_gas, dir_clf, dir_scaler, X_test):\n    \"\"\"\n    Use direction classifier to constrain regression predictions.\n    If classifier says 'up', don't let regression predict down (and vice versa).\n    \"\"\"\n    X_scaled = dir_scaler.transform(X_test)\n    dir_preds = dir_clf.predict(X_scaled)\n    dir_proba = dir_clf.predict_proba(X_scaled)\n    \n    constrained_preds = predictions.copy()\n    \n    for i in range(len(predictions)):\n        pred = predictions[i]\n        current = current_gas.iloc[i]\n        direction = dir_preds[i]  # 0=Down, 1=Stable, 2=Up\n        confidence = np.max(dir_proba[i])\n        \n        # Only apply constraint if direction classifier is confident (>60%)\n        if confidence > 0.6:\n            if direction == 0:  # Predicted Down\n                # If regression predicts up, cap it at current\n                if pred > current:\n                    constrained_preds[i] = current * 0.99  # Slight down\n            elif direction == 2:  # Predicted Up\n                # If regression predicts down, floor it at current\n                if pred < current:\n                    constrained_preds[i] = current * 1.01  # Slight up\n    \n    return constrained_preds\n\nprint(\"Training functions defined with Stacking + Differencing + Direction Constraints.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train all models with separate strategies for 1h vs 4h\nprint(\"=\"*60)\nprint(\"TRAINING ALL MODELS\")\nprint(\"=\"*60)\n\n# Use 1h-specific features for 1h model (micro-features)\nprint(\"\\n>>> Using micro-features for 1h model\")\nbest_1h, all_1h, features_1h_used, pred_1h, actual_1h, conf_1h = train_1h_model(\n    X_1h, y_1h, y_diff_1h, current_gas, BASELINES['1h']['best']\n)\n\n# Use full features for 4h model\nprint(\"\\n>>> Using full features for 4h model\")\nbest_4h, all_4h, features_4h_used, pred_4h, actual_4h, conf_4h = train_4h_model(\n    X_4h, y_4h, y_diff_4h, current_gas, BASELINES['4h']['best']\n)\n\n# 24h model (actually 4h - honest labeling)\nprint(\"\\n>>> 24h model = 4h model (data limitation)\")\nprint(\"    Note: '24h' predictions are actually 4h ahead due to insufficient continuous data\")\nbest_24h = best_4h  # Same as 4h\nall_24h = all_4h\npred_24h = pred_4h\nactual_24h = actual_4h\nconf_24h = conf_4h\n\n# Store features used for saving\nfeatures = feature_cols  # Use all features for model file"
  },
  {
   "cell_type": "code",
   "source": "# PREDICTION INTERVALS using Quantile Regression\n# Output \"25-35 gwei (80% confidence)\" instead of just \"30 gwei\"\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import QuantileRegressor\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING QUANTILE MODELS (Prediction Intervals)\")\nprint(\"=\"*60)\nprint(\"Predicting 10th, 50th, and 90th percentiles for confidence intervals\")\n\ndef train_quantile_models(X, y, horizon_name, quantiles=[0.1, 0.5, 0.9]):\n    \"\"\"\n    Train quantile regression models for prediction intervals.\n    Returns models for each quantile (10%, 50%, 90%).\n    \"\"\"\n    print(f\"\\n{horizon_name} Quantile Models:\")\n    \n    # Time-series split\n    split_idx = int(len(X) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    quantile_models = {}\n    quantile_preds = {}\n    \n    for q in quantiles:\n        print(f\"  Training quantile {q:.0%}...\")\n        \n        # Use GradientBoostingRegressor with quantile loss\n        model = GradientBoostingRegressor(\n            loss='quantile',\n            alpha=q,\n            n_estimators=100,\n            max_depth=5,\n            learning_rate=0.1,\n            min_samples_split=10,\n            random_state=42\n        )\n        \n        model.fit(X_train_scaled, y_train)\n        pred = model.predict(X_test_scaled)\n        \n        quantile_models[q] = model\n        quantile_preds[q] = pred\n        \n        # Evaluate\n        coverage = np.mean((y_test.values >= quantile_preds.get(0.1, pred)) & \n                          (y_test.values <= quantile_preds.get(0.9, pred))) if q == 0.5 else None\n        \n        mae = np.mean(np.abs(y_test.values - pred))\n        print(f\"      MAE: {mae:.6f}\")\n    \n    # Calculate interval metrics\n    if 0.1 in quantile_preds and 0.9 in quantile_preds:\n        lower = quantile_preds[0.1]\n        upper = quantile_preds[0.9]\n        median = quantile_preds[0.5]\n        \n        # Coverage: how often actual is within interval\n        coverage = np.mean((y_test.values >= lower) & (y_test.values <= upper))\n        \n        # Interval width (narrower is better, but need good coverage)\n        avg_width = np.mean(upper - lower)\n        \n        print(f\"\\n  Interval Statistics:\")\n        print(f\"    80% Interval Coverage: {coverage:.1%} (target: 80%)\")\n        print(f\"    Average Interval Width: {avg_width:.4f} gwei\")\n        print(f\"    Median Prediction MAE: {np.mean(np.abs(y_test.values - median)):.6f}\")\n    \n    return quantile_models, scaler, quantile_preds, y_test\n\n# Train quantile models for 1h\nprint(\"\\n>>> Training 1h Quantile Models\")\nquantile_1h, quantile_scaler_1h, qpreds_1h, qactual_1h = train_quantile_models(\n    X_1h, y_1h, '1h'\n)\n\n# Train quantile models for 4h\nprint(\"\\n>>> Training 4h Quantile Models\")\nquantile_4h, quantile_scaler_4h, qpreds_4h, qactual_4h = train_quantile_models(\n    X_4h, y_4h, '4h'\n)\n\n# Store for later use\nquantile_24h = quantile_4h  # Same as 4h\nquantile_scaler_24h = quantile_scaler_4h\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Quantile models trained - prediction intervals ready!\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Direction Prediction (Classification: Down/Stable/Up) - IMPROVED\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"DIRECTION PREDICTION (Classification)\")\nprint(\"=\"*60)\nprint(\"Classes: 0=Down (>2% drop), 1=Stable (<2% change), 2=Up (>2% rise)\")\n\ndef train_direction_model(X, y_dir, horizon_name, use_class_weights=True):\n    \"\"\"\n    Train direction classifier with:\n    - Class weights to handle imbalance\n    - Multiple model comparison\n    - Probability calibration\n    \"\"\"\n    print(f\"\\n{horizon_name} Direction Classifier:\")\n    \n    # Remove NaN\n    valid_idx = ~y_dir.isna()\n    X_valid = X[valid_idx]\n    y_valid = y_dir[valid_idx].astype(int)\n    \n    # Class distribution\n    class_counts = y_valid.value_counts().sort_index()\n    total = len(y_valid)\n    print(f\"  Class distribution:\")\n    print(f\"    Down (0):   {class_counts.get(0,0):5d} ({class_counts.get(0,0)/total*100:.1f}%)\")\n    print(f\"    Stable (1): {class_counts.get(1,0):5d} ({class_counts.get(1,0)/total*100:.1f}%)\")\n    print(f\"    Up (2):     {class_counts.get(2,0):5d} ({class_counts.get(2,0)/total*100:.1f}%)\")\n    \n    # Calculate class weights (inverse frequency)\n    if use_class_weights:\n        class_weights = {i: total / (3 * count) for i, count in class_counts.items()}\n        print(f\"  Using class weights: {class_weights}\")\n    else:\n        class_weights = None\n    \n    # Split\n    split_idx = int(len(X_valid) * 0.8)\n    X_train, X_test = X_valid.iloc[:split_idx], X_valid.iloc[split_idx:]\n    y_train, y_test = y_valid.iloc[:split_idx], y_valid.iloc[split_idx:]\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    results = []\n    \n    # 1. Random Forest with class weights\n    print(f\"\\n  [1/3] Random Forest...\")\n    rf_clf = RandomForestClassifier(\n        n_estimators=150, max_depth=10, min_samples_split=10,\n        class_weight=class_weights, random_state=42, n_jobs=-1\n    )\n    rf_clf.fit(X_train_scaled, y_train)\n    rf_pred = rf_clf.predict(X_test_scaled)\n    rf_acc = accuracy_score(y_test, rf_pred)\n    rf_f1 = f1_score(y_test, rf_pred, average='weighted')\n    results.append(('RandomForest', rf_clf, rf_acc, rf_f1))\n    print(f\"        Accuracy: {rf_acc:.1%}, F1: {rf_f1:.3f}\")\n    \n    # 2. Gradient Boosting\n    print(f\"  [2/3] Gradient Boosting...\")\n    gb_clf = GradientBoostingClassifier(\n        n_estimators=100, max_depth=5, learning_rate=0.1,\n        random_state=42\n    )\n    gb_clf.fit(X_train_scaled, y_train)\n    gb_pred = gb_clf.predict(X_test_scaled)\n    gb_acc = accuracy_score(y_test, gb_pred)\n    gb_f1 = f1_score(y_test, gb_pred, average='weighted')\n    results.append(('GradientBoosting', gb_clf, gb_acc, gb_f1))\n    print(f\"        Accuracy: {gb_acc:.1%}, F1: {gb_f1:.3f}\")\n    \n    # 3. Logistic Regression (probability calibration)\n    print(f\"  [3/3] Logistic Regression...\")\n    lr_clf = LogisticRegression(\n        class_weight=class_weights, max_iter=1000, random_state=42, n_jobs=-1\n    )\n    lr_clf.fit(X_train_scaled, y_train)\n    lr_pred = lr_clf.predict(X_test_scaled)\n    lr_acc = accuracy_score(y_test, lr_pred)\n    lr_f1 = f1_score(y_test, lr_pred, average='weighted')\n    results.append(('LogisticRegression', lr_clf, lr_acc, lr_f1))\n    print(f\"        Accuracy: {lr_acc:.1%}, F1: {lr_f1:.3f}\")\n    \n    # Baseline: always predict most common class\n    most_common = y_train.mode()[0]\n    baseline_acc = (y_test == most_common).mean()\n    print(f\"\\n  Baseline (always predict {['Down', 'Stable', 'Up'][most_common]}): {baseline_acc:.1%}\")\n    \n    # Select best by F1 score (better for imbalanced classes)\n    best = max(results, key=lambda x: x[3])\n    print(f\"\\n  >>> Best: {best[0]} (Accuracy: {best[2]:.1%}, F1: {best[3]:.3f})\")\n    print(f\"      Improvement over baseline: {(best[2] - baseline_acc)*100:+.1f}%\")\n    \n    # Print classification report for best model\n    best_pred = best[1].predict(X_test_scaled)\n    print(f\"\\n  Classification Report ({best[0]}):\")\n    print(classification_report(y_test, best_pred, target_names=['Down', 'Stable', 'Up']))\n    \n    return best[1], scaler, best[2], best[3]\n\n# Train with class weights\ndir_clf_1h, dir_scaler_1h, dir_acc_1h, dir_f1_1h = train_direction_model(X, y_dir_1h, '1h', use_class_weights=True)\ndir_clf_4h, dir_scaler_4h, dir_acc_4h, dir_f1_4h = train_direction_model(X, y_dir_4h, '4h', use_class_weights=True)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Direction classifiers trained successfully\")\nprint(f\"  1h: Accuracy={dir_acc_1h:.1%}, F1={dir_f1_1h:.3f}\")\nprint(f\"  4h: Accuracy={dir_acc_4h:.1%}, F1={dir_f1_4h:.3f}\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# REGIME DETECTION\n# Detect: Normal, High Activity (NFT mints, DeFi rushes), Spike periods\n# Train model to auto-detect which regime we're in\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING REGIME DETECTION MODEL\")\nprint(\"=\"*60)\nprint(\"Regimes: 0=Normal, 1=Elevated (high activity), 2=Spike\")\n\ndef train_regime_detector(X, df_clean):\n    \"\"\"\n    Train a model to detect market regime:\n    - 0: Normal (low volatility, typical gas levels)\n    - 1: Elevated (high activity, moderately high gas)\n    - 2: Spike (extreme gas prices, likely NFT mint/DeFi event)\n    \"\"\"\n    \n    # Create regime labels based on multiple signals\n    gas_values = df_clean['gas'].values\n    gas_mean = np.mean(gas_values)\n    gas_std = np.std(gas_values)\n    \n    # Get volatility if available\n    if 'gas_cv_1h' in df_clean.columns:\n        volatility = df_clean['gas_cv_1h'].values\n    else:\n        volatility = df_clean['gas'].rolling(60).std() / (df_clean['gas'].rolling(60).mean() + 1e-8)\n        volatility = volatility.values\n    \n    # Define regimes\n    regime = np.zeros(len(gas_values))\n    \n    # Elevated: gas > mean + 0.5*std OR high volatility\n    elevated_mask = (gas_values > gas_mean + 0.5 * gas_std) | (volatility > 0.1)\n    regime[elevated_mask] = 1\n    \n    # Spike: gas > mean + 2*std OR very high volatility\n    spike_mask = (gas_values > gas_mean + 2 * gas_std) | (volatility > 0.25)\n    regime[spike_mask] = 2\n    \n    # Class distribution\n    unique, counts = np.unique(regime, return_counts=True)\n    print(f\"\\nRegime distribution:\")\n    for u, c in zip(unique, counts):\n        regime_name = ['Normal', 'Elevated', 'Spike'][int(u)]\n        print(f\"  {regime_name}: {c} ({c/len(regime)*100:.1f}%)\")\n    \n    # Split\n    split_idx = int(len(X) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    y_train, y_test = regime[:split_idx], regime[split_idx:]\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train Random Forest for regime detection\n    print(\"\\nTraining regime classifier...\")\n    from sklearn.ensemble import RandomForestClassifier\n    \n    clf = RandomForestClassifier(\n        n_estimators=100,\n        max_depth=8,\n        min_samples_split=10,\n        class_weight='balanced',  # Handle imbalanced classes\n        random_state=42,\n        n_jobs=-1\n    )\n    \n    clf.fit(X_train_scaled, y_train)\n    \n    # Evaluate\n    y_pred = clf.predict(X_test_scaled)\n    accuracy = np.mean(y_pred == y_test)\n    \n    print(f\"\\nRegime Detection Results:\")\n    print(f\"  Accuracy: {accuracy:.1%}\")\n    \n    # Per-class accuracy\n    for regime_id, regime_name in enumerate(['Normal', 'Elevated', 'Spike']):\n        mask = y_test == regime_id\n        if mask.sum() > 0:\n            class_acc = np.mean(y_pred[mask] == y_test[mask])\n            print(f\"  {regime_name}: {class_acc:.1%} ({mask.sum()} samples)\")\n    \n    # Feature importance for regime detection\n    feature_imp = dict(zip(X.columns, clf.feature_importances_))\n    top_features = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)[:5]\n    print(f\"\\n  Top regime indicators:\")\n    for feat, imp in top_features:\n        print(f\"    {feat}: {imp:.3f}\")\n    \n    return clf, scaler, accuracy\n\n# Train regime detector\nregime_clf, regime_scaler, regime_accuracy = train_regime_detector(X, df_clean)\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"Regime detector trained - Accuracy: {regime_accuracy:.1%}\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train Spike Detectors\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING SPIKE DETECTORS\")\nprint(\"=\"*60)\n\ndef train_spike_detector(X, y_target, current_gas, horizon_name):\n    \"\"\"Train spike classification model\"\"\"\n    print(f\"\\nTraining {horizon_name} spike detector...\")\n    \n    # Classify based on relative change from current\n    price_change_pct = (y_target - current_gas) / (current_gas + 1e-8)\n    \n    # Normal: < 50% change, Elevated: 50-100%, Spike: > 100%\n    def classify(pct):\n        pct = abs(pct)\n        if pct < 0.5:\n            return 0  # Normal\n        elif pct < 1.0:\n            return 1  # Elevated\n        else:\n            return 2  # Spike\n    \n    y_class = price_change_pct.apply(classify)\n    \n    # Class distribution\n    class_counts = y_class.value_counts().sort_index()\n    print(f\"  Classes: Normal={class_counts.get(0,0)}, Elevated={class_counts.get(1,0)}, Spike={class_counts.get(2,0)}\")\n    \n    # Split (time-series)\n    split_idx = int(len(X) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    y_train, y_test = y_class.iloc[:split_idx], y_class.iloc[split_idx:]\n    \n    # Scale\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train\n    clf = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n    clf.fit(X_train_scaled, y_train)\n    \n    accuracy = clf.score(X_test_scaled, y_test)\n    print(f\"  Accuracy: {accuracy:.1%}\")\n    \n    return clf, scaler\n\nspike_1h, spike_scaler_1h = train_spike_detector(X, y_1h, current_gas, '1h')\nspike_4h, spike_scaler_4h = train_spike_detector(X, y_4h, current_gas, '4h')\nspike_24h, spike_scaler_24h = train_spike_detector(X, y_24h, current_gas, '24h')"
  },
  {
   "cell_type": "code",
   "source": "# DQN AGENT TRAINING\n# Train reinforcement learning agent for optimal transaction timing\n# The agent learns when to WAIT vs EXECUTE based on gas price patterns\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING DQN AGENT (Transaction Timing Optimization)\")\nprint(\"=\"*60)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nfrom collections import deque\n\n# Check if GPU available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# === DQN Network ===\nclass DuelingDQN(nn.Module):\n    \"\"\"Dueling DQN architecture with separate value and advantage streams.\"\"\"\n    \n    def __init__(self, state_dim, action_dim, hidden_dims=[128, 64]):\n        super().__init__()\n        \n        # Shared feature layers\n        layers = []\n        in_dim = state_dim\n        for h_dim in hidden_dims[:-1]:\n            layers.extend([\n                nn.Linear(in_dim, h_dim),\n                nn.ReLU(),\n                nn.Dropout(0.1)\n            ])\n            in_dim = h_dim\n        self.features = nn.Sequential(*layers)\n        \n        # Value stream\n        self.value_stream = nn.Sequential(\n            nn.Linear(in_dim, hidden_dims[-1]),\n            nn.ReLU(),\n            nn.Linear(hidden_dims[-1], 1)\n        )\n        \n        # Advantage stream\n        self.advantage_stream = nn.Sequential(\n            nn.Linear(in_dim, hidden_dims[-1]),\n            nn.ReLU(),\n            nn.Linear(hidden_dims[-1], action_dim)\n        )\n    \n    def forward(self, x):\n        features = self.features(x)\n        value = self.value_stream(features)\n        advantage = self.advantage_stream(features)\n        # Combine: Q(s,a) = V(s) + (A(s,a) - mean(A(s,a)))\n        q_values = value + advantage - advantage.mean(dim=1, keepdim=True)\n        return q_values\n\n# === Prioritized Replay Buffer ===\nclass PrioritizedReplayBuffer:\n    \"\"\"Experience replay with prioritization.\"\"\"\n    \n    def __init__(self, capacity=50000, alpha=0.6):\n        self.capacity = capacity\n        self.alpha = alpha\n        self.buffer = []\n        self.priorities = []\n        self.position = 0\n    \n    def push(self, state, action, reward, next_state, done, td_error=None):\n        priority = (abs(td_error) + 1e-5) ** self.alpha if td_error else 1.0\n        \n        if len(self.buffer) < self.capacity:\n            self.buffer.append((state, action, reward, next_state, done))\n            self.priorities.append(priority)\n        else:\n            self.buffer[self.position] = (state, action, reward, next_state, done)\n            self.priorities[self.position] = priority\n        \n        self.position = (self.position + 1) % self.capacity\n    \n    def sample(self, batch_size, beta=0.4):\n        priorities = np.array(self.priorities)\n        probs = priorities / priorities.sum()\n        \n        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n        samples = [self.buffer[i] for i in indices]\n        \n        # Importance sampling weights\n        weights = (len(self.buffer) * probs[indices]) ** (-beta)\n        weights /= weights.max()\n        \n        return samples, indices, torch.FloatTensor(weights).to(device)\n    \n    def update_priorities(self, indices, td_errors):\n        for idx, td_error in zip(indices, td_errors):\n            self.priorities[idx] = (abs(td_error) + 1e-5) ** self.alpha\n    \n    def __len__(self):\n        return len(self.buffer)\n\n# === DQN Agent ===\nclass DQNAgent:\n    \"\"\"DQN Agent with Double DQN, Dueling architecture, and PER.\"\"\"\n    \n    def __init__(self, state_dim, action_dim, hidden_dims=[128, 64],\n                 lr=0.0003, gamma=0.98, epsilon_start=1.0, epsilon_end=0.05,\n                 epsilon_decay_episodes=5000, buffer_size=50000, batch_size=64,\n                 target_update_freq=200, tau=0.001):\n        \n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.gamma = gamma\n        self.batch_size = batch_size\n        self.target_update_freq = target_update_freq\n        self.tau = tau\n        \n        # Epsilon for exploration\n        self.epsilon = epsilon_start\n        self.epsilon_end = epsilon_end\n        self.epsilon_decay = (epsilon_start - epsilon_end) / epsilon_decay_episodes\n        \n        # Networks\n        self.policy_net = DuelingDQN(state_dim, action_dim, hidden_dims).to(device)\n        self.target_net = DuelingDQN(state_dim, action_dim, hidden_dims).to(device)\n        self.target_net.load_state_dict(self.policy_net.state_dict())\n        \n        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n        self.replay_buffer = PrioritizedReplayBuffer(buffer_size)\n        \n        self.training_steps = 0\n        self.state_mean = None\n        self.state_std = None\n    \n    def fit_state_normalizer(self, states):\n        \"\"\"Fit state normalizer from sample states.\"\"\"\n        self.state_mean = np.mean(states, axis=0)\n        self.state_std = np.std(states, axis=0) + 1e-8\n    \n    def normalize_state(self, state):\n        \"\"\"Normalize state using fitted statistics.\"\"\"\n        if self.state_mean is not None:\n            return (state - self.state_mean) / self.state_std\n        return state\n    \n    def select_action(self, state, training=True):\n        \"\"\"Select action using epsilon-greedy policy.\"\"\"\n        if training and random.random() < self.epsilon:\n            return random.randint(0, self.action_dim - 1)\n        \n        state = self.normalize_state(state)\n        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            q_values = self.policy_net(state_tensor)\n            return q_values.argmax().item()\n    \n    def store_transition(self, state, action, reward, next_state, done, td_error=None):\n        \"\"\"Store transition in replay buffer.\"\"\"\n        state = self.normalize_state(state)\n        next_state = self.normalize_state(next_state)\n        self.replay_buffer.push(state, action, reward, next_state, done, td_error)\n    \n    def train_step(self):\n        \"\"\"Perform one training step.\"\"\"\n        if len(self.replay_buffer) < self.batch_size:\n            return None\n        \n        # Sample from replay buffer\n        beta = min(1.0, 0.4 + self.training_steps * 0.001)\n        samples, indices, weights = self.replay_buffer.sample(self.batch_size, beta)\n        \n        # Unpack samples\n        states, actions, rewards, next_states, dones = zip(*samples)\n        \n        states = torch.FloatTensor(np.array(states)).to(device)\n        actions = torch.LongTensor(actions).to(device)\n        rewards = torch.FloatTensor(rewards).to(device)\n        next_states = torch.FloatTensor(np.array(next_states)).to(device)\n        dones = torch.FloatTensor(dones).to(device)\n        \n        # Current Q values\n        current_q = self.policy_net(states).gather(1, actions.unsqueeze(1))\n        \n        # Double DQN: use policy net to select action, target net to evaluate\n        with torch.no_grad():\n            next_actions = self.policy_net(next_states).argmax(1)\n            next_q = self.target_net(next_states).gather(1, next_actions.unsqueeze(1)).squeeze()\n            target_q = rewards + (1 - dones) * self.gamma * next_q\n        \n        # TD errors for PER\n        td_errors = (current_q.squeeze() - target_q).detach().cpu().numpy()\n        self.replay_buffer.update_priorities(indices, td_errors)\n        \n        # Weighted loss\n        loss = (weights * (current_q.squeeze() - target_q) ** 2).mean()\n        \n        # Optimize\n        self.optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n        self.optimizer.step()\n        \n        # Soft update target network\n        self.training_steps += 1\n        if self.training_steps % self.target_update_freq == 0:\n            for target_param, policy_param in zip(self.target_net.parameters(), \n                                                   self.policy_net.parameters()):\n                target_param.data.copy_(self.tau * policy_param.data + \n                                        (1 - self.tau) * target_param.data)\n        \n        return loss.item()\n    \n    def decay_epsilon(self):\n        \"\"\"Decay exploration rate.\"\"\"\n        self.epsilon = max(self.epsilon_end, self.epsilon - self.epsilon_decay)\n    \n    def get_recommendation(self, state, threshold=0.5):\n        \"\"\"Get action recommendation with confidence.\"\"\"\n        state = self.normalize_state(state)\n        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            q_values = self.policy_net(state_tensor).squeeze()\n            probs = torch.softmax(q_values, dim=0)\n            action = q_values.argmax().item()\n            confidence = probs[action].item()\n        \n        return {\n            'action': 'execute' if action == 1 else 'wait',\n            'confidence': confidence,\n            'q_values': q_values.cpu().numpy()\n        }\n    \n    def save(self, path):\n        \"\"\"Save agent to file.\"\"\"\n        torch.save({\n            'policy_net': self.policy_net.state_dict(),\n            'target_net': self.target_net.state_dict(),\n            'optimizer': self.optimizer.state_dict(),\n            'epsilon': self.epsilon,\n            'training_steps': self.training_steps,\n            'state_mean': self.state_mean,\n            'state_std': self.state_std,\n            'state_dim': self.state_dim,\n            'action_dim': self.action_dim\n        }, path)\n    \n    @classmethod\n    def load(cls, path, device='cpu'):\n        \"\"\"Load agent from file.\"\"\"\n        checkpoint = torch.load(path, map_location=device)\n        agent = cls(checkpoint['state_dim'], checkpoint['action_dim'])\n        agent.policy_net.load_state_dict(checkpoint['policy_net'])\n        agent.target_net.load_state_dict(checkpoint['target_net'])\n        agent.optimizer.load_state_dict(checkpoint['optimizer'])\n        agent.epsilon = checkpoint['epsilon']\n        agent.training_steps = checkpoint['training_steps']\n        agent.state_mean = checkpoint['state_mean']\n        agent.state_std = checkpoint['state_std']\n        return agent\n\nprint(\"DQN Agent classes defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gas Optimization Environment and DQN Training\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SETTING UP GAS OPTIMIZATION ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class GasOptimizationEnv:\n",
    "    \"\"\"\n",
    "    RL Environment for learning optimal transaction timing.\n",
    "    Actions: 0=Wait, 1=Execute\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gas_data, episode_length=48, max_wait_steps=None):\n",
    "        self.gas_data = gas_data\n",
    "        self.episode_length = episode_length\n",
    "        self.max_wait_steps = max_wait_steps or episode_length\n",
    "        \n",
    "        # State: [price_features(24), time_features(4), urgency(1), waiting(1)]\n",
    "        self.state_dim = 30\n",
    "        self.action_dim = 2\n",
    "        \n",
    "        self._current_step = 0\n",
    "        self._episode_data = None\n",
    "        self._urgency = 0.5\n",
    "        self._time_waiting = 0\n",
    "        self._initial_price = 0\n",
    "    \n",
    "    def _get_episodes(self, num_episodes=100):\n",
    "        \"\"\"Generate training episodes from data.\"\"\"\n",
    "        episodes = []\n",
    "        data_len = len(self.gas_data)\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            start_idx = np.random.randint(0, max(1, data_len - self.episode_length))\n",
    "            episode = self.gas_data.iloc[start_idx:start_idx + self.episode_length]\n",
    "            if len(episode) >= self.episode_length:\n",
    "                episodes.append(episode)\n",
    "        \n",
    "        return episodes\n",
    "    \n",
    "    def reset(self, episode_data=None):\n",
    "        \"\"\"Reset environment for new episode.\"\"\"\n",
    "        if episode_data is not None:\n",
    "            self._episode_data = episode_data\n",
    "        else:\n",
    "            episodes = self._get_episodes(1)\n",
    "            if episodes:\n",
    "                self._episode_data = episodes[0]\n",
    "            else:\n",
    "                raise ValueError(\"No data available for episode\")\n",
    "        \n",
    "        self._current_step = 0\n",
    "        self._time_waiting = 0\n",
    "        self._urgency = np.random.uniform(0.1, 0.9)\n",
    "        self._initial_price = self._episode_data['gas'].iloc[0]\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Build state vector.\"\"\"\n",
    "        if self._current_step >= len(self._episode_data):\n",
    "            return np.zeros(self.state_dim)\n",
    "        \n",
    "        prices = self._episode_data['gas'].values\n",
    "        current_price = prices[self._current_step]\n",
    "        \n",
    "        # Price history features (last 24 steps, or pad with current)\n",
    "        history_start = max(0, self._current_step - 24)\n",
    "        price_history = prices[history_start:self._current_step + 1]\n",
    "        if len(price_history) < 24:\n",
    "            price_history = np.pad(price_history, (24 - len(price_history), 0), mode='edge')\n",
    "        price_history = price_history[-24:]\n",
    "        \n",
    "        # Normalize prices\n",
    "        mean_price = np.mean(price_history) + 1e-8\n",
    "        norm_prices = (price_history - mean_price) / mean_price\n",
    "        \n",
    "        # Price statistics\n",
    "        volatility = np.std(price_history) / mean_price\n",
    "        momentum = (price_history[-1] - price_history[0]) / mean_price if len(price_history) > 1 else 0\n",
    "        price_position = (current_price - np.min(price_history)) / (np.max(price_history) - np.min(price_history) + 1e-8)\n",
    "        \n",
    "        # Time features\n",
    "        time_remaining = 1.0 - (self._current_step / self.max_wait_steps)\n",
    "        \n",
    "        # Build state vector\n",
    "        state = np.concatenate([\n",
    "            norm_prices,                    # 24 features\n",
    "            [volatility],                   # 1 feature\n",
    "            [momentum],                     # 1 feature\n",
    "            [price_position],               # 1 feature\n",
    "            [time_remaining],               # 1 feature\n",
    "            [self._urgency],                # 1 feature\n",
    "            [self._time_waiting / self.max_wait_steps]  # 1 feature\n",
    "        ])\n",
    "        \n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take action in environment.\"\"\"\n",
    "        current_price = self._episode_data['gas'].iloc[self._current_step]\n",
    "        \n",
    "        # Check if forced execution at deadline\n",
    "        if self._current_step >= self.max_wait_steps - 1 and action == 0:\n",
    "            action = 1  # Force execute\n",
    "            forced = True\n",
    "        else:\n",
    "            forced = False\n",
    "        \n",
    "        if action == 1:  # Execute\n",
    "            # Reward based on savings vs initial price\n",
    "            savings = (self._initial_price - current_price) / self._initial_price\n",
    "            reward = np.tanh(savings * 10)  # Scale and bound reward\n",
    "            \n",
    "            if forced:\n",
    "                reward -= 0.3  # Penalty for forced execution\n",
    "            \n",
    "            done = True\n",
    "            info = {\n",
    "                'execution_price': current_price,\n",
    "                'initial_price': self._initial_price,\n",
    "                'savings': savings,\n",
    "                'forced': forced,\n",
    "                'wait_time': self._time_waiting\n",
    "            }\n",
    "        else:  # Wait\n",
    "            reward = -0.01 * self._urgency  # Small wait penalty\n",
    "            self._time_waiting += 1\n",
    "            self._current_step += 1\n",
    "            done = self._current_step >= len(self._episode_data) - 1\n",
    "            info = {'action': 'wait'}\n",
    "        \n",
    "        next_state = self._get_state() if not done else np.zeros(self.state_dim)\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "# === DQN Training ===\n",
    "print(\"\\nPreparing training data...\")\n",
    "\n",
    "# Use the clean gas data for RL training\n",
    "rl_data = df_clean[['gas']].copy()\n",
    "print(f\"RL training data: {len(rl_data)} samples\")\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPISODES = 3000  # Reduced for Colab (increase to 10000 for better results)\n",
    "EPISODE_LENGTH = 48\n",
    "MAX_WAIT_STEPS = 48\n",
    "\n",
    "# Create environment\n",
    "env = GasOptimizationEnv(rl_data, episode_length=EPISODE_LENGTH, max_wait_steps=MAX_WAIT_STEPS)\n",
    "\n",
    "# Create agent\n",
    "dqn_agent = DQNAgent(\n",
    "    state_dim=env.state_dim,\n",
    "    action_dim=env.action_dim,\n",
    "    hidden_dims=[128, 64],\n",
    "    lr=0.0003,\n",
    "    gamma=0.98,\n",
    "    epsilon_start=1.0,\n",
    "    epsilon_end=0.05,\n",
    "    epsilon_decay_episodes=NUM_EPISODES,\n",
    "    buffer_size=50000,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Generate diverse training episodes\n",
    "print(\"Generating training episodes...\")\n",
    "train_episodes = env._get_episodes(min(NUM_EPISODES * 2, 500))\n",
    "print(f\"Generated {len(train_episodes)} diverse episodes\")\n",
    "\n",
    "# Fit state normalizer\n",
    "print(\"Fitting state normalizer...\")\n",
    "sample_states = []\n",
    "for ep in train_episodes[:50]:\n",
    "    state = env.reset(episode_data=ep)\n",
    "    sample_states.append(state)\n",
    "    for _ in range(min(10, len(ep) - 1)):\n",
    "        action = np.random.randint(0, 2)\n",
    "        next_state, _, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        sample_states.append(next_state)\n",
    "dqn_agent.fit_state_normalizer(np.array(sample_states))\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\nStarting DQN training ({NUM_EPISODES} episodes)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "episode_rewards = []\n",
    "episode_savings = []\n",
    "losses = []\n",
    "best_avg_savings = float('-inf')\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    # Select episode data\n",
    "    ep_data = train_episodes[episode % len(train_episodes)]\n",
    "    state = env.reset(episode_data=ep_data)\n",
    "    \n",
    "    total_reward = 0\n",
    "    episode_losses = []\n",
    "    \n",
    "    while True:\n",
    "        action = dqn_agent.select_action(state, training=True)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        dqn_agent.store_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        loss = dqn_agent.train_step()\n",
    "        if loss is not None:\n",
    "            episode_losses.append(loss)\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    dqn_agent.decay_epsilon()\n",
    "    episode_rewards.append(total_reward)\n",
    "    \n",
    "    if 'savings' in info:\n",
    "        episode_savings.append(info['savings'])\n",
    "    \n",
    "    if episode_losses:\n",
    "        losses.append(np.mean(episode_losses))\n",
    "    \n",
    "    # Track best model\n",
    "    if len(episode_savings) >= 100:\n",
    "        avg_savings = np.mean(episode_savings[-100:])\n",
    "        if avg_savings > best_avg_savings:\n",
    "            best_avg_savings = avg_savings\n",
    "    \n",
    "    # Progress logging\n",
    "    if (episode + 1) % 500 == 0:\n",
    "        avg_reward = np.mean(episode_rewards[-100:]) if episode_rewards else 0\n",
    "        avg_save = np.mean(episode_savings[-100:]) * 100 if episode_savings else 0\n",
    "        avg_loss = np.mean(losses[-100:]) if losses else 0\n",
    "        \n",
    "        print(f\"Episode {episode + 1}/{NUM_EPISODES}\")\n",
    "        print(f\"  Avg Reward (last 100): {avg_reward:.3f}\")\n",
    "        print(f\"  Avg Savings (last 100): {avg_save:.2f}%\")\n",
    "        print(f\"  Avg Loss: {avg_loss:.4f}\")\n",
    "        print(f\"  Epsilon: {dqn_agent.epsilon:.3f}\")\n",
    "        print(f\"  Buffer Size: {len(dqn_agent.replay_buffer)}\")\n",
    "\n",
    "# Training complete\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DQN TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Episodes: {NUM_EPISODES}\")\n",
    "print(f\"Training Steps: {dqn_agent.training_steps}\")\n",
    "print(f\"Final Epsilon: {dqn_agent.epsilon:.4f}\")\n",
    "if episode_savings:\n",
    "    print(f\"Final Avg Savings (last 100): {np.mean(episode_savings[-100:])*100:.2f}%\")\n",
    "    print(f\"Best Avg Savings: {best_avg_savings*100:.2f}%\")\n",
    "print(f\"Final Buffer Size: {len(dqn_agent.replay_buffer)}\")\n",
    "\n",
    "# Store for saving\n",
    "DQN_TRAINED = True\n",
    "DQN_AGENT = dqn_agent\n",
    "DQN_METRICS = {\n",
    "    'episodes': NUM_EPISODES,\n",
    "    'training_steps': dqn_agent.training_steps,\n",
    "    'final_epsilon': float(dqn_agent.epsilon),\n",
    "    'avg_savings': float(np.mean(episode_savings[-100:])) if episode_savings else 0,\n",
    "    'best_avg_savings': float(best_avg_savings)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models including NEW: Quantile models + Regime detector\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use feature importance from cell 6\n",
    "feature_importance = FEATURE_IMPORTANCE\n",
    "\n",
    "# Save prediction models\n",
    "for horizon, best, features_used in [('1h', best_1h, features_1h_used), \n",
    "                                      ('4h', best_4h, features_4h_used), \n",
    "                                      ('24h', best_24h, features_4h_used)]:\n",
    "    name, model, metrics, scaler = best\n",
    "    \n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'model_name': name,\n",
    "        'metrics': metrics,\n",
    "        'trained_at': datetime.now().isoformat(),\n",
    "        'feature_names': features_used,\n",
    "        'feature_scaler': scaler,\n",
    "        'scaler_type': 'RobustScaler',\n",
    "        'is_ensemble': name == 'Ensemble' or name == 'Stacking',\n",
    "        'training_strategy': 'simpler_regularized_stacking' if horizon == '1h' else 'full_tuned_stacking',\n",
    "        'actual_horizon': '1 hour' if horizon == '1h' else '4 hours',\n",
    "        'confidence_method': 'tree_variance' if hasattr(model, 'estimators_') else 'fixed'\n",
    "    }\n",
    "    \n",
    "    if horizon == '4h' and feature_importance:\n",
    "        model_data['feature_importance'] = feature_importance\n",
    "    \n",
    "    joblib.dump(model_data, f'saved_models/model_{horizon}.pkl')\n",
    "    print(f\"Saved model_{horizon}.pkl ({name}, MAE={metrics['mae']:.6f}, {metrics['vs_baseline']})\")\n",
    "    \n",
    "    joblib.dump(scaler, f'saved_models/scaler_{horizon}.pkl')\n",
    "\n",
    "# === NEW: Save Quantile Models (Prediction Intervals) ===\n",
    "print(\"\\nSaving quantile models for prediction intervals...\")\n",
    "for horizon, q_models, q_scaler in [('1h', quantile_1h, quantile_scaler_1h),\n",
    "                                     ('4h', quantile_4h, quantile_scaler_4h),\n",
    "                                     ('24h', quantile_24h, quantile_scaler_24h)]:\n",
    "    quantile_data = {\n",
    "        'models': q_models,  # Dict with 0.1, 0.5, 0.9 quantiles\n",
    "        'scaler': q_scaler,\n",
    "        'quantiles': [0.1, 0.5, 0.9],\n",
    "        'trained_at': datetime.now().isoformat()\n",
    "    }\n",
    "    joblib.dump(quantile_data, f'saved_models/quantile_{horizon}.pkl')\n",
    "    print(f\"Saved quantile_{horizon}.pkl (10th, 50th, 90th percentiles)\")\n",
    "\n",
    "# === NEW: Save Regime Detector ===\n",
    "print(\"\\nSaving regime detector...\")\n",
    "regime_data = {\n",
    "    'model': regime_clf,\n",
    "    'scaler': regime_scaler,\n",
    "    'regimes': {0: 'Normal', 1: 'Elevated', 2: 'Spike'},\n",
    "    'accuracy': regime_accuracy,\n",
    "    'trained_at': datetime.now().isoformat()\n",
    "}\n",
    "joblib.dump(regime_data, 'saved_models/regime_detector.pkl')\n",
    "print(f\"Saved regime_detector.pkl (Accuracy: {regime_accuracy:.1%})\")\n",
    "\n",
    "# Save spike detectors\n",
    "for horizon, (clf, scaler) in [('1h', (spike_1h, spike_scaler_1h)), \n",
    "                                ('4h', (spike_4h, spike_scaler_4h)),\n",
    "                                ('24h', (spike_24h, spike_scaler_24h))]:\n",
    "    spike_data = {\n",
    "        'model': clf,\n",
    "        'scaler': scaler,\n",
    "        'trained_at': datetime.now().isoformat()\n",
    "    }\n",
    "    joblib.dump(spike_data, f'saved_models/spike_detector_{horizon}.pkl')\n",
    "    print(f\"Saved spike_detector_{horizon}.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(features, 'saved_models/feature_names.pkl')\n",
    "print(f\"Saved feature_names.pkl ({len(features)} features)\")\n",
    "\n",
    "# Save training metadata with full info\n",
    "import json\n",
    "metadata = {\n",
    "    'training_timestamp': datetime.now().isoformat(),\n",
    "    'total_samples': len(df_clean),\n",
    "    'date_range': f\"{df_clean.index.min()} to {df_clean.index.max()}\",\n",
    "    'num_segments_used': len(good_segments),\n",
    "    'has_eth_price': HAS_ETH_PRICE,\n",
    "    'features': {\n",
    "        'total': len(features),\n",
    "        '1h_specific': len(features_1h_used),\n",
    "        '4h_specific': len(features_4h_used)\n",
    "    },\n",
    "    'baselines': BASELINES,\n",
    "    'models': {\n",
    "        '1h': {\n",
    "            'name': best_1h[0], \n",
    "            'r2': float(best_1h[2]['r2']), \n",
    "            'mae': float(best_1h[2]['mae']),\n",
    "            'vs_baseline': best_1h[2]['vs_baseline'],\n",
    "            'improvement_pct': float(best_1h[2]['improvement']),\n",
    "            'actual_horizon': '1 hour',\n",
    "            'training_strategy': 'simpler models with stacking + target differencing',\n",
    "            'directional_accuracy': float(best_1h[2]['directional_accuracy'])\n",
    "        },\n",
    "        '4h': {\n",
    "            'name': best_4h[0], \n",
    "            'r2': float(best_4h[2]['r2']), \n",
    "            'mae': float(best_4h[2]['mae']),\n",
    "            'vs_baseline': best_4h[2]['vs_baseline'],\n",
    "            'improvement_pct': float(best_4h[2]['improvement']),\n",
    "            'actual_horizon': '4 hours',\n",
    "            'training_strategy': 'full model suite with stacking + XGBoost/LightGBM',\n",
    "            'directional_accuracy': float(best_4h[2]['directional_accuracy'])\n",
    "        },\n",
    "        '24h': {\n",
    "            'name': best_24h[0], \n",
    "            'r2': float(best_24h[2]['r2']), \n",
    "            'mae': float(best_24h[2]['mae']),\n",
    "            'vs_baseline': best_24h[2]['vs_baseline'],\n",
    "            'improvement_pct': float(best_24h[2]['improvement']),\n",
    "            'actual_horizon': '4 hours (labeled as 24h due to data limitations)',\n",
    "            'training_strategy': 'same as 4h model',\n",
    "            'directional_accuracy': float(best_24h[2]['directional_accuracy'])\n",
    "        }\n",
    "    },\n",
    "    'direction_models': {\n",
    "        '1h': {'accuracy': float(dir_acc_1h), 'f1_score': float(dir_f1_1h)},\n",
    "        '4h': {'accuracy': float(dir_acc_4h), 'f1_score': float(dir_f1_4h)}\n",
    "    },\n",
    "    'regime_detector': {\n",
    "        'accuracy': float(regime_accuracy),\n",
    "        'regimes': ['Normal', 'Elevated', 'Spike']\n",
    "    },\n",
    "    'prediction_intervals': {\n",
    "        'quantiles': [0.1, 0.5, 0.9],\n",
    "        'description': '80% confidence interval (10th to 90th percentile)'\n",
    "    },\n",
    "    'improvements_applied': [\n",
    "        'ETH price features (momentum, volatility, correlation)',\n",
    "        'Extended ETH lags (1h, 2h, 4h price changes)',\n",
    "        'Network utilization features',\n",
    "        'Day-of-week one-hot encoding',\n",
    "        'Micro-features (5min, 15min, 30min) for 1h prediction',\n",
    "        'Target differencing (predict change, reconstruct price)',\n",
    "        'Stacking ensemble (RF + GB + Ridge -> Ridge meta)',\n",
    "        'XGBoost and LightGBM with early stopping',\n",
    "        'Feature selection by importance (dropped bottom 25%)',\n",
    "        'Quantile regression for prediction intervals',\n",
    "        'Regime detection (Normal/Elevated/Spike)',\n",
    "        'Direction-constrained predictions (optional)',\n",
    "        'Hyperparameter tuning (RandomizedSearchCV)',\n",
    "        'Class-weighted direction classification',\n",
    "        'DQN agent for transaction timing optimization'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('saved_models/training_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Saved training_metadata.json\")\n",
    "\n",
    "# Save feature importance\n",
    "if feature_importance:\n",
    "    with open('saved_models/feature_importance.json', 'w') as f:\n",
    "        sorted_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "        json.dump(sorted_importance, f, indent=2)\n",
    "    print(f\"Saved feature_importance.json\")\n",
    "\n",
    "\n",
    "# === Save DQN Agent ===\n",
    "print(\"\\nSaving DQN agent...\")\n",
    "if 'DQN_TRAINED' in dir() and DQN_TRAINED:\n",
    "    os.makedirs('saved_models/rl_agents', exist_ok=True)\n",
    "    DQN_AGENT.save('saved_models/rl_agents/dqn_agent.pt')\n",
    "    print(f\"Saved dqn_agent.pt (Training steps: {DQN_AGENT.training_steps})\")\n",
    "    \n",
    "    # Save DQN metadata\n",
    "    dqn_meta = {\n",
    "        'state_dim': DQN_AGENT.state_dim,\n",
    "        'action_dim': DQN_AGENT.action_dim,\n",
    "        'training_steps': DQN_AGENT.training_steps,\n",
    "        'epsilon': float(DQN_AGENT.epsilon),\n",
    "        'metrics': DQN_METRICS,\n",
    "        'trained_at': datetime.now().isoformat()\n",
    "    }\n",
    "    with open('saved_models/rl_agents/dqn_metadata.json', 'w') as f:\n",
    "        json.dump(dqn_meta, f, indent=2)\n",
    "    print(\"Saved dqn_metadata.json\")\n",
    "else:\n",
    "    print(\"DQN agent not trained, skipping...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL MODELS SAVED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE - FINAL REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDATA SUMMARY\")\n",
    "print(f\"   Total samples: {len(df_clean):,}\")\n",
    "print(f\"   Segments: {len(good_segments)}\")\n",
    "print(f\"   Features: {len(features)} (1h: {len(features_1h_used)}, 4h: {len(features_4h_used)})\")\n",
    "print(f\"   Date range: {df_clean.index.min()} to {df_clean.index.max()}\")\n",
    "print(f\"   ETH price data: {'Yes' if HAS_ETH_PRICE else 'No'}\")\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(f\"{'PRICE PREDICTION MODELS':^70}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Horizon':<8} {'Model':<18} {'MAE':>10} {'vs Baseline':>13} {'Dir Acc':>8}\")\n",
    "print(\"-\"*70)\n",
    "for horizon, best in [('1h', best_1h), ('4h', best_4h), ('24h*', best_24h)]:\n",
    "    print(f\"{horizon:<8} {best[0]:<18} {best[2]['mae']:>10.6f} {best[2]['vs_baseline']:>13} {best[2]['directional_accuracy']:>7.1%}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(f\"{'PREDICTION INTERVALS (Quantile Regression)':^70}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Output format: '25-35 gwei (80% confidence)'\")\n",
    "print(f\"   Quantiles trained: 10th, 50th (median), 90th percentile\")\n",
    "print(f\"   Coverage target: 80% of actual values within interval\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(f\"{'REGIME DETECTION':^70}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Accuracy: {regime_accuracy:.1%}\")\n",
    "print(f\"   Regimes:\")\n",
    "print(f\"     0 = Normal (typical gas, low volatility)\")\n",
    "print(f\"     1 = Elevated (high activity, NFT mints)\")\n",
    "print(f\"     2 = Spike (extreme prices, DeFi rush)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(f\"{'DIRECTION CLASSIFICATION':^70}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Horizon':<8} {'Accuracy':>10} {'F1 Score':>10}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'1h':<8} {dir_acc_1h:>9.1%} {dir_f1_1h:>10.3f}\")\n",
    "print(f\"{'4h':<8} {dir_acc_4h:>9.1%} {dir_f1_4h:>10.3f}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\nNEW FEATURES ADDED\")\n",
    "print(f\"   1. ETH Price Features\")\n",
    "print(f\"      - ETH momentum (15min, 30min, 60min)\")\n",
    "print(f\"      - ETH volatility (1h, 2h, 4h)\")\n",
    "print(f\"      - Extended ETH lags (1h, 2h, 4h price changes)\")\n",
    "print(f\"      - Gas-ETH correlation\")\n",
    "print(f\"   2. Network Utilization\")\n",
    "print(f\"      - Rolling utilization stats\")\n",
    "print(f\"      - High utilization streaks\")\n",
    "print(f\"   3. Day-of-Week One-Hot Encoding\")\n",
    "print(f\"      - Explicit day indicators (dow_0 to dow_6)\")\n",
    "print(f\"   4. Target Differencing\")\n",
    "print(f\"      - Predict change instead of absolute value\")\n",
    "print(f\"      - Reconstruct final price from difference\")\n",
    "print(f\"   5. Stacking Ensemble\")\n",
    "print(f\"      - RF + GB + Ridge base models\")\n",
    "print(f\"      - Ridge meta-learner for optimal combination\")\n",
    "print(f\"   6. Feature Selection by Importance\")\n",
    "print(f\"      - Dropped bottom 25% of low-importance features\")\n",
    "print(f\"   7. Prediction Intervals\")\n",
    "print(f\"      - 80% confidence bounds (10th-90th percentile)\")\n",
    "print(f\"   8. Regime Detection\")\n",
    "print(f\"      - Auto-detect Normal/Elevated/Spike periods\")\n",
    "\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(f\"{'DQN AGENT (Transaction Timing)':^70}\")\n",
    "print(\"-\"*70)\n",
    "if 'DQN_TRAINED' in dir() and DQN_TRAINED:\n",
    "    print(f\"   Episodes: {DQN_METRICS['episodes']}\")\n",
    "    print(f\"   Training Steps: {DQN_METRICS['training_steps']}\")\n",
    "    print(f\"   Avg Savings: {DQN_METRICS['avg_savings']*100:.2f}%\")\n",
    "    print(f\"   Best Avg Savings: {DQN_METRICS['best_avg_savings']*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"   Not trained\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\nFILES SAVED\")\n",
    "print(f\"   Point predictions:\")\n",
    "print(f\"     - model_1h/4h/24h.pkl, scaler_1h/4h/24h.pkl\")\n",
    "print(f\"   Prediction intervals:\")\n",
    "print(f\"     - quantile_1h/4h/24h.pkl (10th, 50th, 90th percentiles)\")\n",
    "print(f\"   Regime detection:\")\n",
    "print(f\"     - regime_detector.pkl\")\n",
    "print(f\"   Other:\")\n",
    "print(f\"     - spike_detector_*.pkl, feature_names.pkl\")\n",
    "print(f\"   DQN Agent:\")\n",
    "print(f\"     - rl_agents/dqn_agent.pt, dqn_metadata.json\")\n",
    "print(f\"     - training_metadata.json, feature_importance.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Upload to Colab, run all cells, download gweizy_models.zip\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfig.suptitle('Gweizy Model Training Results', fontsize=14, fontweight='bold')\n\n# 1. Actual vs Predicted (1h)\nax1 = axes[0, 0]\nax1.scatter(actual_1h.values, pred_1h, alpha=0.5, s=10)\nax1.plot([actual_1h.min(), actual_1h.max()], [actual_1h.min(), actual_1h.max()], 'r--', label='Perfect')\nax1.set_xlabel('Actual Gas Price')\nax1.set_ylabel('Predicted')\nax1.set_title(f'1h Prediction (R\u00b2={best_1h[2][\"r2\"]:.3f})')\nax1.legend()\n\n# 2. Actual vs Predicted (4h)\nax2 = axes[0, 1]\nax2.scatter(actual_4h.values, pred_4h, alpha=0.5, s=10)\nax2.plot([actual_4h.min(), actual_4h.max()], [actual_4h.min(), actual_4h.max()], 'r--', label='Perfect')\nax2.set_xlabel('Actual Gas Price')\nax2.set_ylabel('Predicted')\nax2.set_title(f'4h Prediction (R\u00b2={best_4h[2][\"r2\"]:.3f})')\nax2.legend()\n\n# 3. Model Comparison (MAE)\nax3 = axes[0, 2]\nmodels_1h = [r[0] for r in all_1h]\nmaes_1h = [r[2]['mae'] for r in all_1h]\ncolors = ['green' if m < BASELINES['1h']['best'] else 'red' for m in maes_1h]\nbars = ax3.barh(models_1h, maes_1h, color=colors, alpha=0.7)\nax3.axvline(BASELINES['1h']['best'], color='blue', linestyle='--', label=f'Baseline: {BASELINES[\"1h\"][\"best\"]:.4f}')\nax3.set_xlabel('MAE')\nax3.set_title('1h Model Comparison')\nax3.legend()\n\n# 4. Residuals Distribution (1h)\nax4 = axes[1, 0]\nresiduals_1h = actual_1h.values - pred_1h\nax4.hist(residuals_1h, bins=50, alpha=0.7, edgecolor='black')\nax4.axvline(0, color='red', linestyle='--')\nax4.set_xlabel('Residual (Actual - Predicted)')\nax4.set_ylabel('Frequency')\nax4.set_title(f'1h Residuals (mean={np.mean(residuals_1h):.4f})')\n\n# 5. Time Series Sample\nax5 = axes[1, 1]\nsample_size = min(200, len(actual_1h))\nax5.plot(range(sample_size), actual_1h.values[:sample_size], label='Actual', alpha=0.8)\nax5.plot(range(sample_size), pred_1h[:sample_size], label='Predicted', alpha=0.8)\nax5.set_xlabel('Time (samples)')\nax5.set_ylabel('Gas Price')\nax5.set_title('1h: Actual vs Predicted (Time Series)')\nax5.legend()\n\n# 6. Feature Importance (top 10)\nax6 = axes[1, 2]\nif feature_importance:\n    sorted_imp = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:10])\n    ax6.barh(list(sorted_imp.keys()), list(sorted_imp.values()), color='steelblue')\n    ax6.set_xlabel('Importance')\n    ax6.set_title('Top 10 Features (4h model)')\nelse:\n    ax6.text(0.5, 0.5, 'Feature importance\\nnot available', ha='center', va='center')\n    ax6.set_title('Feature Importance')\n\nplt.tight_layout()\nplt.savefig('saved_models/training_results.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved training_results.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for download\n",
    "import shutil\n",
    "\n",
    "shutil.make_archive('gweizy_models', 'zip', 'saved_models')\n",
    "print(\"\\n\u2705 Created gweizy_models.zip\")\n",
    "print(\"\\nDownload this file and extract to: backend/models/saved_models/\")\n",
    "\n",
    "# Auto-download\n",
    "files.download('gweizy_models.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}